<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sanjeeva Reddy Dodlapati">
<meta name="dcterms.date" content="2025-10-04">
<meta name="description" content="A comprehensive guide to vector databases covering embeddings, ANN indexes (HNSW, IVF-PQ), distance metrics, hybrid search, and production deployment with working FAISS examples.">

<title>Sanjeev’s AI Research Blog - Vector Databases, Demystified</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Sanjeeva Reddy Dodlapati">
<meta name="keywords" content="AI, machine learning, computational biology, bioinformatics, genomics, data science">
<script src="custom.js" defer=""></script>
<style>
  body { opacity: 0; transition: opacity 0.3s ease; }
  body.loaded { opacity: 1; }
</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Sanjeev’s AI Research Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target=""><i class="bi bi-file-person" role="img">
</i> 
 <span class="menu-text">CV/Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./projects.html" rel="" target=""><i class="bi bi-collection" role="img">
</i> 
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./ml-blog.html" rel="" target=""><i class="bi bi-cpu" role="img">
</i> 
 <span class="menu-text">Machine Learning</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./genomics-blog.html" rel="" target=""><i class="bi bi-dna" role="img">
</i> 
 <span class="menu-text">AI for Genomics</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./chemistry-blog.html" rel="" target=""><i class="bi bi-flask" role="img">
</i> 
 <span class="menu-text">AI for Chemistry</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/SanjeevaRDodlapati" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/dodlapati_reddy" rel="" target=""><i class="bi bi-twitter" role="img" aria-label="Twitter">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
    <a href="./#" title="Toggle Dark Mode" class="quarto-navigation-tool px-1" aria-label="Toggle Dark Mode"><i class="bi bi-moon"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#setup-and-package-verification" id="toc-setup-and-package-verification" class="nav-link active" data-scroll-target="#setup-and-package-verification"><span class="header-section-number">0.1</span> Setup and Package Verification</a></li>
  <li><a href="#what-is-a-vector-database" id="toc-what-is-a-vector-database" class="nav-link" data-scroll-target="#what-is-a-vector-database"><span class="header-section-number">1</span> What is a Vector Database?</a>
  <ul class="collapse">
  <li><a href="#why-vectors" id="toc-why-vectors" class="nav-link" data-scroll-target="#why-vectors"><span class="header-section-number">1.1</span> Why vectors?</a></li>
  </ul></li>
  <li><a href="#end-to-end-flow" id="toc-end-to-end-flow" class="nav-link" data-scroll-target="#end-to-end-flow"><span class="header-section-number">2</span> End-to-End Flow</a>
  <ul class="collapse">
  <li><a href="#vectorization" id="toc-vectorization" class="nav-link" data-scroll-target="#vectorization"><span class="header-section-number">2.1</span> Vectorization</a></li>
  <li><a href="#storage-metadata" id="toc-storage-metadata" class="nav-link" data-scroll-target="#storage-metadata"><span class="header-section-number">2.2</span> Storage &amp; Metadata</a></li>
  <li><a href="#indexing" id="toc-indexing" class="nav-link" data-scroll-target="#indexing"><span class="header-section-number">2.3</span> Indexing</a></li>
  <li><a href="#query" id="toc-query" class="nav-link" data-scroll-target="#query"><span class="header-section-number">2.4</span> Query</a></li>
  <li><a href="#ranking-fusion" id="toc-ranking-fusion" class="nav-link" data-scroll-target="#ranking-fusion"><span class="header-section-number">2.5</span> Ranking &amp; Fusion</a></li>
  </ul></li>
  <li><a href="#distance-metrics-their-gotchas" id="toc-distance-metrics-their-gotchas" class="nav-link" data-scroll-target="#distance-metrics-their-gotchas"><span class="header-section-number">3</span> Distance Metrics &amp; Their Gotchas</a>
  <ul class="collapse">
  <li><a href="#cosine-similarity" id="toc-cosine-similarity" class="nav-link" data-scroll-target="#cosine-similarity"><span class="header-section-number">3.1</span> Cosine Similarity</a></li>
  <li><a href="#euclidean-distance-l2" id="toc-euclidean-distance-l2" class="nav-link" data-scroll-target="#euclidean-distance-l2"><span class="header-section-number">3.2</span> Euclidean Distance (L2)</a></li>
  <li><a href="#inner-product-mips---maximum-inner-product-search" id="toc-inner-product-mips---maximum-inner-product-search" class="nav-link" data-scroll-target="#inner-product-mips---maximum-inner-product-search"><span class="header-section-number">3.3</span> Inner Product (MIPS - Maximum Inner Product Search)</a></li>
  </ul></li>
  <li><a href="#index-families-and-when-to-use-them" id="toc-index-families-and-when-to-use-them" class="nav-link" data-scroll-target="#index-families-and-when-to-use-them"><span class="header-section-number">4</span> Index Families (and When to Use Them)</a>
  <ul class="collapse">
  <li><a href="#graph-based-hnsw---hierarchical-navigable-small-world" id="toc-graph-based-hnsw---hierarchical-navigable-small-world" class="nav-link" data-scroll-target="#graph-based-hnsw---hierarchical-navigable-small-world"><span class="header-section-number">4.1</span> Graph-based (HNSW - Hierarchical Navigable Small World)</a></li>
  <li><a href="#inverted-file-ivf-pqopq" id="toc-inverted-file-ivf-pqopq" class="nav-link" data-scroll-target="#inverted-file-ivf-pqopq"><span class="header-section-number">4.2</span> Inverted File (IVF) + [PQ/OPQ]</a></li>
  <li><a href="#tree-like-annoy" id="toc-tree-like-annoy" class="nav-link" data-scroll-target="#tree-like-annoy"><span class="header-section-number">4.3</span> Tree-like (Annoy)</a></li>
  <li><a href="#specialized-indexes" id="toc-specialized-indexes" class="nav-link" data-scroll-target="#specialized-indexes"><span class="header-section-number">4.4</span> Specialized Indexes</a></li>
  <li><a href="#rule-of-thumb" id="toc-rule-of-thumb" class="nav-link" data-scroll-target="#rule-of-thumb"><span class="header-section-number">4.5</span> Rule of Thumb</a></li>
  </ul></li>
  <li><a href="#deep-dive-how-hnsw-works" id="toc-deep-dive-how-hnsw-works" class="nav-link" data-scroll-target="#deep-dive-how-hnsw-works"><span class="header-section-number">5</span> Deep Dive: How HNSW Works</a>
  <ul class="collapse">
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture"><span class="header-section-number">5.1</span> Architecture</a></li>
  <li><a href="#key-parameters" id="toc-key-parameters" class="nav-link" data-scroll-target="#key-parameters"><span class="header-section-number">5.2</span> Key Parameters</a></li>
  <li><a href="#insertion-process" id="toc-insertion-process" class="nav-link" data-scroll-target="#insertion-process"><span class="header-section-number">5.3</span> Insertion Process</a></li>
  <li><a href="#search-process" id="toc-search-process" class="nav-link" data-scroll-target="#search-process"><span class="header-section-number">5.4</span> Search Process</a></li>
  <li><a href="#intuition" id="toc-intuition" class="nav-link" data-scroll-target="#intuition"><span class="header-section-number">5.5</span> Intuition</a></li>
  <li><a href="#trade-offs" id="toc-trade-offs" class="nav-link" data-scroll-target="#trade-offs"><span class="header-section-number">5.6</span> Trade-offs</a></li>
  </ul></li>
  <li><a href="#beyond-rag-what-else-uses-vector-databases" id="toc-beyond-rag-what-else-uses-vector-databases" class="nav-link" data-scroll-target="#beyond-rag-what-else-uses-vector-databases"><span class="header-section-number">6</span> Beyond RAG: What Else Uses Vector Databases?</a>
  <ul class="collapse">
  <li><a href="#recommendation-personalization" id="toc-recommendation-personalization" class="nav-link" data-scroll-target="#recommendation-personalization"><span class="header-section-number">6.1</span> Recommendation &amp; Personalization</a></li>
  <li><a href="#near-duplicate-plagiarism-detection" id="toc-near-duplicate-plagiarism-detection" class="nav-link" data-scroll-target="#near-duplicate-plagiarism-detection"><span class="header-section-number">6.2</span> Near-Duplicate &amp; Plagiarism Detection</a></li>
  <li><a href="#anomalyoutlier-detection" id="toc-anomalyoutlier-detection" class="nav-link" data-scroll-target="#anomalyoutlier-detection"><span class="header-section-number">6.3</span> Anomaly/Outlier Detection</a></li>
  <li><a href="#semantic-monitoring-alerting" id="toc-semantic-monitoring-alerting" class="nav-link" data-scroll-target="#semantic-monitoring-alerting"><span class="header-section-number">6.4</span> Semantic Monitoring &amp; Alerting</a></li>
  <li><a href="#multimodal-search" id="toc-multimodal-search" class="nav-link" data-scroll-target="#multimodal-search"><span class="header-section-number">6.5</span> Multimodal Search</a></li>
  <li><a href="#code-intelligence" id="toc-code-intelligence" class="nav-link" data-scroll-target="#code-intelligence"><span class="header-section-number">6.6</span> Code Intelligence</a></li>
  <li><a href="#biochem-applications" id="toc-biochem-applications" class="nav-link" data-scroll-target="#biochem-applications"><span class="header-section-number">6.7</span> Bio/Chem Applications</a></li>
  <li><a href="#roboticsslam-mapping" id="toc-roboticsslam-mapping" class="nav-link" data-scroll-target="#roboticsslam-mapping"><span class="header-section-number">6.8</span> Robotics/SLAM &amp; Mapping</a></li>
  <li><a href="#legal-e-discovery" id="toc-legal-e-discovery" class="nav-link" data-scroll-target="#legal-e-discovery"><span class="header-section-number">6.9</span> Legal &amp; E-discovery</a></li>
  <li><a href="#content-moderation" id="toc-content-moderation" class="nav-link" data-scroll-target="#content-moderation"><span class="header-section-number">6.10</span> Content Moderation</a></li>
  </ul></li>
  <li><a href="#hybrid-search-filters-real-world-must-haves" id="toc-hybrid-search-filters-real-world-must-haves" class="nav-link" data-scroll-target="#hybrid-search-filters-real-world-must-haves"><span class="header-section-number">7</span> Hybrid Search &amp; Filters (Real-World Must-Haves)</a>
  <ul class="collapse">
  <li><a href="#metadata-filters-at-retrieval-time" id="toc-metadata-filters-at-retrieval-time" class="nav-link" data-scroll-target="#metadata-filters-at-retrieval-time"><span class="header-section-number">7.1</span> Metadata Filters at Retrieval Time</a></li>
  <li><a href="#hybrid-fusion-strategies" id="toc-hybrid-fusion-strategies" class="nav-link" data-scroll-target="#hybrid-fusion-strategies"><span class="header-section-number">7.2</span> Hybrid Fusion Strategies</a>
  <ul class="collapse">
  <li><a href="#a.-rank-fusion-rrf---reciprocal-rank-fusion" id="toc-a.-rank-fusion-rrf---reciprocal-rank-fusion" class="nav-link" data-scroll-target="#a.-rank-fusion-rrf---reciprocal-rank-fusion"><span class="header-section-number">7.2.1</span> A. Rank Fusion (RRF - Reciprocal Rank Fusion)</a></li>
  <li><a href="#b.-score-fusion" id="toc-b.-score-fusion" class="nav-link" data-scroll-target="#b.-score-fusion"><span class="header-section-number">7.2.2</span> B. Score Fusion</a></li>
  <li><a href="#c.-neural-re-rankers" id="toc-c.-neural-re-rankers" class="nav-link" data-scroll-target="#c.-neural-re-rankers"><span class="header-section-number">7.2.3</span> C. Neural Re-rankers</a></li>
  </ul></li>
  <li><a href="#implementation-considerations" id="toc-implementation-considerations" class="nav-link" data-scroll-target="#implementation-considerations"><span class="header-section-number">7.3</span> Implementation Considerations</a></li>
  <li><a href="#when-to-use-what" id="toc-when-to-use-what" class="nav-link" data-scroll-target="#when-to-use-what"><span class="header-section-number">7.4</span> When to Use What</a></li>
  </ul></li>
  <li><a href="#data-model-concerns" id="toc-data-model-concerns" class="nav-link" data-scroll-target="#data-model-concerns"><span class="header-section-number">8</span> Data &amp; Model Concerns</a>
  <ul class="collapse">
  <li><a href="#embedding-model-selection" id="toc-embedding-model-selection" class="nav-link" data-scroll-target="#embedding-model-selection"><span class="header-section-number">8.1</span> Embedding Model Selection</a></li>
  <li><a href="#normalization-consistency" id="toc-normalization-consistency" class="nav-link" data-scroll-target="#normalization-consistency"><span class="header-section-number">8.2</span> Normalization Consistency</a></li>
  <li><a href="#drift-versioning" id="toc-drift-versioning" class="nav-link" data-scroll-target="#drift-versioning"><span class="header-section-number">8.3</span> Drift &amp; Versioning</a></li>
  <li><a href="#chunking-for-text" id="toc-chunking-for-text" class="nav-link" data-scroll-target="#chunking-for-text"><span class="header-section-number">8.4</span> Chunking for Text</a></li>
  <li><a href="#deduplication-collapse" id="toc-deduplication-collapse" class="nav-link" data-scroll-target="#deduplication-collapse"><span class="header-section-number">8.5</span> Deduplication &amp; Collapse</a></li>
  </ul></li>
  <li><a href="#evaluation-quantify-good" id="toc-evaluation-quantify-good" class="nav-link" data-scroll-target="#evaluation-quantify-good"><span class="header-section-number">9</span> Evaluation: Quantify “Good”</a>
  <ul class="collapse">
  <li><a href="#retrieval-quality-metrics" id="toc-retrieval-quality-metrics" class="nav-link" data-scroll-target="#retrieval-quality-metrics"><span class="header-section-number">9.1</span> Retrieval Quality Metrics</a>
  <ul class="collapse">
  <li><a href="#recallk" id="toc-recallk" class="nav-link" data-scroll-target="#recallk"><span class="header-section-number">9.1.1</span> Recall@k</a></li>
  <li><a href="#ndcg-normalized-discounted-cumulative-gain" id="toc-ndcg-normalized-discounted-cumulative-gain" class="nav-link" data-scroll-target="#ndcg-normalized-discounted-cumulative-gain"><span class="header-section-number">9.1.2</span> NDCG (Normalized Discounted Cumulative Gain)</a></li>
  <li><a href="#mrr-mean-reciprocal-rank" id="toc-mrr-mean-reciprocal-rank" class="nav-link" data-scroll-target="#mrr-mean-reciprocal-rank"><span class="header-section-number">9.1.3</span> MRR (Mean Reciprocal Rank)</a></li>
  </ul></li>
  <li><a href="#performance-metrics" id="toc-performance-metrics" class="nav-link" data-scroll-target="#performance-metrics"><span class="header-section-number">9.2</span> Performance Metrics</a></li>
  <li><a href="#cost-metrics" id="toc-cost-metrics" class="nav-link" data-scroll-target="#cost-metrics"><span class="header-section-number">9.3</span> Cost Metrics</a></li>
  <li><a href="#business-metrics-ab-testing" id="toc-business-metrics-ab-testing" class="nav-link" data-scroll-target="#business-metrics-ab-testing"><span class="header-section-number">9.4</span> Business Metrics (A/B Testing)</a></li>
  <li><a href="#evaluation-best-practices" id="toc-evaluation-best-practices" class="nav-link" data-scroll-target="#evaluation-best-practices"><span class="header-section-number">9.5</span> Evaluation Best Practices</a></li>
  </ul></li>
  <li><a href="#operating-at-scale" id="toc-operating-at-scale" class="nav-link" data-scroll-target="#operating-at-scale"><span class="header-section-number">10</span> Operating at Scale</a>
  <ul class="collapse">
  <li><a href="#index-build-updates" id="toc-index-build-updates" class="nav-link" data-scroll-target="#index-build-updates"><span class="header-section-number">10.1</span> Index Build &amp; Updates</a></li>
  <li><a href="#sharding-strategies" id="toc-sharding-strategies" class="nav-link" data-scroll-target="#sharding-strategies"><span class="header-section-number">10.2</span> Sharding Strategies</a></li>
  <li><a href="#caching-strategies" id="toc-caching-strategies" class="nav-link" data-scroll-target="#caching-strategies"><span class="header-section-number">10.3</span> Caching Strategies</a></li>
  <li><a href="#hardware-considerations" id="toc-hardware-considerations" class="nav-link" data-scroll-target="#hardware-considerations"><span class="header-section-number">10.4</span> Hardware Considerations</a></li>
  <li><a href="#security-compliance" id="toc-security-compliance" class="nav-link" data-scroll-target="#security-compliance"><span class="header-section-number">10.5</span> Security &amp; Compliance</a></li>
  </ul></li>
  <li><a href="#challenges-how-to-handle-them" id="toc-challenges-how-to-handle-them" class="nav-link" data-scroll-target="#challenges-how-to-handle-them"><span class="header-section-number">11</span> Challenges &amp; How to Handle Them</a></li>
  <li><a href="#practical-sizing-tuning-cheatsheet" id="toc-practical-sizing-tuning-cheatsheet" class="nav-link" data-scroll-target="#practical-sizing-tuning-cheatsheet"><span class="header-section-number">12</span> Practical Sizing &amp; Tuning Cheatsheet</a>
  <ul class="collapse">
  <li><a href="#initial-setup-checklist" id="toc-initial-setup-checklist" class="nav-link" data-scroll-target="#initial-setup-checklist"><span class="header-section-number">12.1</span> Initial Setup Checklist</a></li>
  <li><a href="#tuning-for-latency-slo" id="toc-tuning-for-latency-slo" class="nav-link" data-scroll-target="#tuning-for-latency-slo"><span class="header-section-number">12.2</span> Tuning for Latency SLO</a></li>
  <li><a href="#hybrid-search-setup" id="toc-hybrid-search-setup" class="nav-link" data-scroll-target="#hybrid-search-setup"><span class="header-section-number">12.3</span> Hybrid Search Setup</a></li>
  <li><a href="#filter-configuration" id="toc-filter-configuration" class="nav-link" data-scroll-target="#filter-configuration"><span class="header-section-number">12.4</span> Filter Configuration</a></li>
  <li><a href="#operational-monitoring" id="toc-operational-monitoring" class="nav-link" data-scroll-target="#operational-monitoring"><span class="header-section-number">12.5</span> Operational Monitoring</a></li>
  <li><a href="#blue-green-deployment" id="toc-blue-green-deployment" class="nav-link" data-scroll-target="#blue-green-deployment"><span class="header-section-number">12.6</span> Blue-Green Deployment</a></li>
  </ul></li>
  <li><a href="#minimal-example-with-faiss" id="toc-minimal-example-with-faiss" class="nav-link" data-scroll-target="#minimal-example-with-faiss"><span class="header-section-number">13</span> Minimal Example with FAISS</a>
  <ul class="collapse">
  <li><a href="#installation" id="toc-installation" class="nav-link" data-scroll-target="#installation"><span class="header-section-number">13.1</span> Installation</a></li>
  <li><a href="#complete-ivf-pq-implementation" id="toc-complete-ivf-pq-implementation" class="nav-link" data-scroll-target="#complete-ivf-pq-implementation"><span class="header-section-number">13.2</span> Complete IVF-PQ Implementation</a></li>
  <li><a href="#notes-on-production-usage" id="toc-notes-on-production-usage" class="nav-link" data-scroll-target="#notes-on-production-usage"><span class="header-section-number">13.3</span> Notes on Production Usage</a></li>
  </ul></li>
  <li><a href="#frequently-asked-questions-faq" id="toc-frequently-asked-questions-faq" class="nav-link" data-scroll-target="#frequently-asked-questions-faq"><span class="header-section-number">14</span> Frequently Asked Questions (FAQ)</a>
  <ul class="collapse">
  <li><a href="#q1-do-i-always-need-a-vector-database" id="toc-q1-do-i-always-need-a-vector-database" class="nav-link" data-scroll-target="#q1-do-i-always-need-a-vector-database"><span class="header-section-number">14.1</span> Q1: Do I always need a vector database?</a></li>
  <li><a href="#q2-cosine-vs-inner-product-vs-l2-which-should-i-use" id="toc-q2-cosine-vs-inner-product-vs-l2-which-should-i-use" class="nav-link" data-scroll-target="#q2-cosine-vs-inner-product-vs-l2-which-should-i-use"><span class="header-section-number">14.2</span> Q2: Cosine vs Inner Product vs L2 — which should I use?</a></li>
  <li><a href="#q3-can-i-mix-different-embedding-models-in-one-index" id="toc-q3-can-i-mix-different-embedding-models-in-one-index" class="nav-link" data-scroll-target="#q3-can-i-mix-different-embedding-models-in-one-index"><span class="header-section-number">14.3</span> Q3: Can I mix different embedding models in one index?</a></li>
  <li><a href="#q4-how-big-should-text-chunks-be" id="toc-q4-how-big-should-text-chunks-be" class="nav-link" data-scroll-target="#q4-how-big-should-text-chunks-be"><span class="header-section-number">14.4</span> Q4: How big should text chunks be?</a></li>
  <li><a href="#q5-what-about-gpu-vs-cpu-for-vector-search" id="toc-q5-what-about-gpu-vs-cpu-for-vector-search" class="nav-link" data-scroll-target="#q5-what-about-gpu-vs-cpu-for-vector-search"><span class="header-section-number">14.5</span> Q5: What about GPU vs CPU for vector search?</a></li>
  <li><a href="#q6-how-do-i-handle-real-time-updates" id="toc-q6-how-do-i-handle-real-time-updates" class="nav-link" data-scroll-target="#q6-how-do-i-handle-real-time-updates"><span class="header-section-number">14.6</span> Q6: How do I handle real-time updates?</a></li>
  <li><a href="#q7-whats-the-best-open-source-vector-database" id="toc-q7-whats-the-best-open-source-vector-database" class="nav-link" data-scroll-target="#q7-whats-the-best-open-source-vector-database"><span class="header-section-number">14.7</span> Q7: What’s the best open-source vector database?</a></li>
  <li><a href="#q8-how-do-i-debug-poor-recall" id="toc-q8-how-do-i-debug-poor-recall" class="nav-link" data-scroll-target="#q8-how-do-i-debug-poor-recall"><span class="header-section-number">14.8</span> Q8: How do I debug poor recall?</a></li>
  </ul></li>
  <li><a href="#tldr---key-takeaways" id="toc-tldr---key-takeaways" class="nav-link" data-scroll-target="#tldr---key-takeaways"><span class="header-section-number">15</span> TL;DR - Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#core-concepts" id="toc-core-concepts" class="nav-link" data-scroll-target="#core-concepts"><span class="header-section-number">15.1</span> 🎯 Core Concepts</a></li>
  <li><a href="#index-selection" id="toc-index-selection" class="nav-link" data-scroll-target="#index-selection"><span class="header-section-number">15.2</span> 🏗️ Index Selection</a></li>
  <li><a href="#production-essentials" id="toc-production-essentials" class="nav-link" data-scroll-target="#production-essentials"><span class="header-section-number">15.3</span> ⚙️ Production Essentials</a></li>
  <li><a href="#evaluation-framework" id="toc-evaluation-framework" class="nav-link" data-scroll-target="#evaluation-framework"><span class="header-section-number">15.4</span> 🔍 Evaluation Framework</a></li>
  <li><a href="#getting-started" id="toc-getting-started" class="nav-link" data-scroll-target="#getting-started"><span class="header-section-number">15.5</span> 🚀 Getting Started</a></li>
  <li><a href="#common-pitfalls-to-avoid" id="toc-common-pitfalls-to-avoid" class="nav-link" data-scroll-target="#common-pitfalls-to-avoid"><span class="header-section-number">15.6</span> 💡 Common Pitfalls to Avoid</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">15.7</span> 📚 Further Reading</a></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts"><span class="header-section-number">15.8</span> 🎓 Final Thoughts</a></li>
  <li><a href="#questions-or-feedback" id="toc-questions-or-feedback" class="nav-link" data-scroll-target="#questions-or-feedback"><span class="header-section-number">15.9</span> 📬 Questions or Feedback?</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Vector Databases, Demystified</h1>
<p class="subtitle lead">From Embeddings to Production-Grade Search</p>
  <div class="quarto-categories">
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">AI</div>
    <div class="quarto-category">Vector Search</div>
    <div class="quarto-category">Database Systems</div>
    <div class="quarto-category">Production ML</div>
  </div>
  </div>

<div>
  <div class="description">
    A comprehensive guide to vector databases covering embeddings, ANN indexes (HNSW, IVF-PQ), distance metrics, hybrid search, and production deployment with working FAISS examples.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sanjeeva Reddy Dodlapati </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 4, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="setup-and-package-verification" class="level2" data-number="0.1">
<h2 data-number="0.1" class="anchored" data-anchor-id="setup-and-package-verification"><span class="header-section-number">0.1</span> Setup and Package Verification</h2>
<p>Before we begin, let’s verify that all required packages are installed and working properly.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Package verification and imports</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Python version: </span><span class="sc">{</span>sys<span class="sc">.</span>version<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Python executable: </span><span class="sc">{</span>sys<span class="sc">.</span>executable<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Checking required packages..."</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>required_packages <span class="op">=</span> {</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'numpy'</span>: <span class="st">'numerical computing'</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pandas'</span>: <span class="st">'data manipulation'</span>,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'matplotlib'</span>: <span class="st">'plotting and visualization'</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'sklearn'</span>: <span class="st">'machine learning utilities'</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>optional_packages <span class="op">=</span> {</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'faiss'</span>: <span class="st">'vector search (optional but recommended)'</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Check required packages</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>all_good <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> package, description <span class="kw">in</span> required_packages.items():</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        mod <span class="op">=</span> <span class="bu">__import__</span>(package)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        version <span class="op">=</span> <span class="bu">getattr</span>(mod, <span class="st">'__version__'</span>, <span class="st">'unknown'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"✅ </span><span class="sc">{</span>package<span class="sc">:15s}</span><span class="ss"> </span><span class="sc">{</span>version<span class="sc">:15s}</span><span class="ss"> - </span><span class="sc">{</span>description<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"❌ </span><span class="sc">{</span>package<span class="sc">:15s}</span><span class="ss"> NOT FOUND - </span><span class="sc">{</span>description<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        all_good <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Check optional packages</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> package, description <span class="kw">in</span> optional_packages.items():</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        mod <span class="op">=</span> <span class="bu">__import__</span>(package)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        version <span class="op">=</span> <span class="bu">getattr</span>(mod, <span class="st">'__version__'</span>, <span class="st">'unknown'</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"✅ </span><span class="sc">{</span>package<span class="sc">:15s}</span><span class="ss"> </span><span class="sc">{</span>version<span class="sc">:15s}</span><span class="ss"> - </span><span class="sc">{</span>description<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"⚠️  </span><span class="sc">{</span>package<span class="sc">:15s}</span><span class="ss"> NOT FOUND - </span><span class="sc">{</span>description<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"   Install with: conda install -c conda-forge faiss-cpu"</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> all_good:</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✅ All required packages are installed! Ready to proceed."</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"❌ Some required packages are missing. Please install them first."</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Python version: 3.10.11 (main, May 15 2023, 19:29:30) [Clang 14.0.6 ]
Python executable: /Users/sanjeev/miniconda3/bin/python

======================================================================
Checking required packages...
======================================================================

✅ numpy           1.24.3          - numerical computing
✅ numpy           1.24.3          - numerical computing
✅ pandas          1.5.3           - data manipulation
✅ matplotlib      3.10.0          - plotting and visualization
✅ pandas          1.5.3           - data manipulation
✅ matplotlib      3.10.0          - plotting and visualization
✅ sklearn         1.1.3           - machine learning utilities

✅ sklearn         1.1.3           - machine learning utilities

✅ faiss           1.9.0           - vector search (optional but recommended)

======================================================================
✅ All required packages are installed! Ready to proceed.
======================================================================
✅ faiss           1.9.0           - vector search (optional but recommended)

======================================================================
✅ All required packages are installed! Ready to proceed.
======================================================================</code></pre>
</div>
</div>
<p><strong>Last updated:</strong> October 2025 • <strong>Reading time:</strong> ~15 minutes</p>
<hr>
<p>Vector databases power the “semantic” layer of modern AI systems. Instead of matching exact strings, they compare embeddings—high-dimensional vectors that capture meaning from text, images, audio, code, molecules, and more. This post explains how vector DBs work, when to use them, what can go wrong, and how to build &amp; operate them in production.</p>
</section>
<section id="what-is-a-vector-database" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> What is a Vector Database?</h1>
<p>A <strong>vector database</strong> stores and indexes embeddings—dense vectors (e.g., 384–4096 dimensions) produced by models such as: - Sentence transformers - CLIP (vision-language models) - Whisper (audio) - Multimodal foundation models - Domain-specific encoders</p>
<p>The core task is <strong>nearest neighbor search</strong>: given a query vector, return the most similar stored vectors under a metric (cosine, L2, inner product).</p>
<section id="why-vectors" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="why-vectors"><span class="header-section-number">1.1</span> Why vectors?</h2>
<p>Because similar concepts map to nearby points in embedding space. “puppy on grass” and “dog on lawn” sit close even if they share few keywords.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Creating simple embeddings to demonstrate vector similarity</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated embeddings for demonstration (in reality, these come from models)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> {</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"puppy on grass"</span>: np.array([<span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>]),</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"dog on lawn"</span>: np.array([<span class="fl">0.75</span>, <span class="fl">0.65</span>, <span class="fl">0.35</span>, <span class="fl">0.52</span>]),</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cat in house"</span>: np.array([<span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.9</span>, <span class="fl">0.1</span>]),</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"car on road"</span>: np.array([<span class="fl">0.1</span>, <span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.95</span>])</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate similarity between "puppy on grass" and other phrases</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> embeddings[<span class="st">"puppy on grass"</span>].reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Similarity scores to 'puppy on grass':</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> phrase, vec <span class="kw">in</span> embeddings.items():</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> phrase <span class="op">!=</span> <span class="st">"puppy on grass"</span>:</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        similarity <span class="op">=</span> cosine_similarity(query, vec.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>phrase<span class="sc">:20s}</span><span class="ss">: </span><span class="sc">{</span>similarity<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Similarity scores to 'puppy on grass':

dog on lawn         : 0.9972
cat in house        : 0.6027
car on road         : 0.6168</code></pre>
</div>
</div>
</section>
</section>
<section id="end-to-end-flow" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> End-to-End Flow</h1>
<p>The vector database workflow consists of five key stages:</p>
<section id="vectorization" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="vectorization"><span class="header-section-number">2.1</span> Vectorization</h2>
<p>Unstructured data → embedding model → vector <span class="math inline">\(\mathbf{x} \in \mathbb{R}^d\)</span>.</p>
<p>Often you also normalize: <span class="math inline">\(\mathbf{x} \leftarrow \frac{\mathbf{x}}{\|\mathbf{x}\|}\)</span> if using cosine similarity.</p>
</section>
<section id="storage-metadata" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="storage-metadata"><span class="header-section-number">2.2</span> Storage &amp; Metadata</h2>
<p>Store <code>{id, vector, metadata, payload}</code>. Metadata enables filters (e.g., <code>country=US</code>, <code>doc_type=blog</code>) and post-retrieval ranking.</p>
</section>
<section id="indexing" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="indexing"><span class="header-section-number">2.3</span> Indexing</h2>
<p>Build an <strong>ANN (Approximate Nearest Neighbor)</strong> index so queries don’t scan every vector. Trade speed for a controlled loss vs exact search.</p>
</section>
<section id="query" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="query"><span class="header-section-number">2.4</span> Query</h2>
<p>Query text/image → query vector <span class="math inline">\(\mathbf{q}\)</span>. Perform ANN search with optional metadata filters and hybrid fusion (keyword + vector).</p>
</section>
<section id="ranking-fusion" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="ranking-fusion"><span class="header-section-number">2.5</span> Ranking &amp; Fusion</h2>
<p>Compute similarity scores, apply re-ranking (e.g., LTR, cross-encoder), dedupe near-duplicates, then return references/snippets.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: End-to-end vector database flow simulation</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> normalize</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Vectorization (simulated embeddings)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> [</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Machine learning with neural networks"</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Deep learning for computer vision"</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Natural language processing with transformers"</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Database systems and indexing"</span>,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Vector search and embeddings"</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate embedding generation (in practice, use real models like sentence-transformers)</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>doc_embeddings <span class="op">=</span> np.random.randn(<span class="bu">len</span>(documents), dim).astype(<span class="st">'float32'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Normalize for cosine similarity</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>doc_embeddings <span class="op">=</span> normalize(doc_embeddings, norm<span class="op">=</span><span class="st">'l2'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Store with metadata</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>metadata <span class="op">=</span> [</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"doc_id"</span>: i, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"year"</span>: <span class="dv">2024</span>} </span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(documents))</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Stored </span><span class="sc">{</span><span class="bu">len</span>(documents)<span class="sc">}</span><span class="ss"> documents with </span><span class="sc">{</span>dim<span class="sc">}</span><span class="ss">-dimensional embeddings"</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Embedding shape: </span><span class="sc">{</span>doc_embeddings<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample embedding (first 10 dims): </span><span class="sc">{</span>doc_embeddings[<span class="dv">0</span>][:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stored 5 documents with 128-dimensional embeddings
Embedding shape: (5, 128)
Sample embedding (first 10 dims): [ 0.04642567 -0.01292295  0.06053658  0.14235085 -0.02188528 -0.02188374
  0.14760202  0.07172872 -0.04387969  0.05071068]</code></pre>
</div>
</div>
</section>
</section>
<section id="distance-metrics-their-gotchas" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Distance Metrics &amp; Their Gotchas</h1>
<p>Choosing the right distance metric is crucial for vector search performance.</p>
<section id="cosine-similarity" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="cosine-similarity"><span class="header-section-number">3.1</span> Cosine Similarity</h2>
<p><span class="math display">\[s(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\| \|\mathbf{y}\|}\]</span></p>
<p><strong>Properties:</strong> - Invariant to magnitude - Great for text embeddings - Normalize vectors for fast dot-product equivalence</p>
</section>
<section id="euclidean-distance-l2" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="euclidean-distance-l2"><span class="header-section-number">3.2</span> Euclidean Distance (L2)</h2>
<p><span class="math display">\[d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{\sum_{i=1}^{d} (x_i - y_i)^2}\]</span></p>
<p><strong>Properties:</strong> - Sensitive to magnitude - Useful when norms carry signal (e.g., certain vision or embedding regimes)</p>
</section>
<section id="inner-product-mips---maximum-inner-product-search" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="inner-product-mips---maximum-inner-product-search"><span class="header-section-number">3.3</span> Inner Product (MIPS - Maximum Inner Product Search)</h2>
<p><span class="math display">\[\text{MIPS}(\mathbf{x}, \mathbf{y}) = \mathbf{x} \cdot \mathbf{y}\]</span></p>
<p><strong>Properties:</strong> - Equivalent to cosine if vectors are normalized - If not normalized, may use transform tricks (e.g., add a norm-dependent extra dimension) to reuse L2 engines</p>
<p><strong>💡 Tip:</strong> Decide metric before index build; many indexes are metric-specific.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing different distance metrics</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity, euclidean_distances</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create two sample vectors</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>]])</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> np.array([[<span class="fl">2.0</span>, <span class="fl">4.0</span>, <span class="fl">6.0</span>]])  <span class="co"># Same direction, different magnitude</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>vec3 <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="op">-</span><span class="fl">3.0</span>]]) <span class="co"># Different direction</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize vectors for cosine</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>vec1_norm <span class="op">=</span> vec1 <span class="op">/</span> np.linalg.norm(vec1)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>vec2_norm <span class="op">=</span> vec2 <span class="op">/</span> np.linalg.norm(vec2)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>vec3_norm <span class="op">=</span> vec3 <span class="op">/</span> np.linalg.norm(vec3)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Distance Metrics Comparison:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Cosine similarity</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>cos_sim_12 <span class="op">=</span> cosine_similarity(vec1, vec2)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>cos_sim_13 <span class="op">=</span> cosine_similarity(vec1, vec3)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cosine Similarity:"</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec2 (same direction): </span><span class="sc">{</span>cos_sim_12<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec3 (diff direction): </span><span class="sc">{</span>cos_sim_13<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Euclidean distance</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>l2_dist_12 <span class="op">=</span> euclidean_distances(vec1, vec2)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>l2_dist_13 <span class="op">=</span> euclidean_distances(vec1, vec3)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Euclidean Distance (L2):"</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec2: </span><span class="sc">{</span>l2_dist_12<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec3: </span><span class="sc">{</span>l2_dist_13<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Inner product</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>inner_12 <span class="op">=</span> np.dot(vec1, vec2.T)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>inner_13 <span class="op">=</span> np.dot(vec1, vec3.T)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Inner Product:"</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec2: </span><span class="sc">{</span>inner_12<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec3: </span><span class="sc">{</span>inner_13<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Notice: Cosine sees vec1 and vec2 as identical (both 1.0)"</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   because they point in the same direction, despite magnitude difference!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Distance Metrics Comparison:

============================================================
Cosine Similarity:
  vec1 vs vec2 (same direction): 1.0000
  vec1 vs vec3 (diff direction): -0.2857

Euclidean Distance (L2):
  vec1 vs vec2: 3.7417
  vec1 vs vec3: 6.0000

Inner Product:
  vec1 vs vec2: 28.0000
  vec1 vs vec3: -4.0000

============================================================

💡 Notice: Cosine sees vec1 and vec2 as identical (both 1.0)
   because they point in the same direction, despite magnitude difference!</code></pre>
</div>
</div>
</section>
</section>
<section id="index-families-and-when-to-use-them" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Index Families (and When to Use Them)</h1>
<p>Different indexing strategies optimize for various trade-offs between speed, accuracy, and memory.</p>
<section id="graph-based-hnsw---hierarchical-navigable-small-world" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="graph-based-hnsw---hierarchical-navigable-small-world"><span class="header-section-number">4.1</span> Graph-based (HNSW - Hierarchical Navigable Small World)</h2>
<p><strong>Pros:</strong> - Excellent recall/speed trade-off - Dynamic insert capabilities - Strong default for ≤ few hundred million points in RAM</p>
<p><strong>Cons:</strong> - Memory-heavy (stores graph structure) - Deletions are lazy or complicated - Filtering can be non-trivial</p>
</section>
<section id="inverted-file-ivf-pqopq" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="inverted-file-ivf-pqopq"><span class="header-section-number">4.2</span> Inverted File (IVF) + [PQ/OPQ]</h2>
<p>Cluster vectors into <code>nlist</code> centroids (coarse quantizer), search only a few lists (<code>nprobe</code>). Optional <strong>Product Quantization (PQ)</strong> to compress.</p>
<p><strong>Pros:</strong> - Scales well to billions of vectors - Great for GPU acceleration (e.g., FAISS) - Good recall/latency trade-off - Compresses memory usage</p>
<p><strong>Cons:</strong> - Build time can be significant - Requires tuning <code>nlist</code>, <code>nprobe</code>, and PQ bits - Recall loss under heavy compression</p>
</section>
<section id="tree-like-annoy" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="tree-like-annoy"><span class="header-section-number">4.3</span> Tree-like (Annoy)</h2>
<p><strong>Pros:</strong> - Simple implementation - Memory-mapped for efficient disk usage - Good for read-mostly workloads</p>
<p><strong>Cons:</strong> - Slower writes - Less optimal for dynamic updates</p>
</section>
<section id="specialized-indexes" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="specialized-indexes"><span class="header-section-number">4.4</span> Specialized Indexes</h2>
<ul>
<li><strong>ScaNN:</strong> Anisotropic quantization for better compression</li>
<li><strong>DiskANN:</strong> I/O-aware for large-scale cloud disk storage</li>
<li><strong>Flat/Brute-force:</strong> Exact search, costly but useful for small collections or re-ranking</li>
</ul>
</section>
<section id="rule-of-thumb" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="rule-of-thumb"><span class="header-section-number">4.5</span> Rule of Thumb</h2>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th>Scale</th>
<th>Recommendation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Up to tens of millions in RAM</td>
<td><strong>HNSW</strong></td>
</tr>
<tr class="even">
<td>Hundreds of millions / GPU</td>
<td><strong>IVF-PQ</strong> with FAISS or vendor GPU index</td>
</tr>
<tr class="odd">
<td>On disk at web scale</td>
<td><strong>DiskANN</strong>-style or sharded IVF-PQ + caching</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing index performance characteristics</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated performance characteristics</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>index_types <span class="op">=</span> [<span class="st">'HNSW'</span>, <span class="st">'IVF-PQ'</span>, <span class="st">'Annoy'</span>, <span class="st">'Flat'</span>]</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> [<span class="fl">0.95</span>, <span class="fl">0.92</span>, <span class="fl">0.88</span>, <span class="fl">1.0</span>]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>speed <span class="op">=</span> [<span class="fl">0.85</span>, <span class="fl">0.90</span>, <span class="fl">0.75</span>, <span class="fl">0.20</span>]  <span class="co"># queries per second (normalized)</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>memory <span class="op">=</span> [<span class="fl">0.70</span>, <span class="fl">0.85</span>, <span class="fl">0.80</span>, <span class="fl">0.30</span>]  <span class="co"># memory efficiency (lower is better for memory)</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>))</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Recall comparison</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].bar(index_types, recall, color<span class="op">=</span>[<span class="st">'#2ecc71'</span>, <span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>, <span class="st">'#95a5a6'</span>])</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Recall@10'</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Recall Performance'</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axhline(y<span class="op">=</span><span class="fl">0.95</span>, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Target: 0.95'</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Speed comparison</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].bar(index_types, speed, color<span class="op">=</span>[<span class="st">'#2ecc71'</span>, <span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>, <span class="st">'#95a5a6'</span>])</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Relative Speed'</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Query Speed (Higher is Better)'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Memory efficiency</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].bar(index_types, memory, color<span class="op">=</span>[<span class="st">'#2ecc71'</span>, <span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>, <span class="st">'#95a5a6'</span>])</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Memory Usage'</span>)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Memory Footprint (Lower is Better)'</span>)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'index_comparison.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Index Performance Summary:"</span>)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(index_types):</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>idx<span class="sc">:10s}</span><span class="ss"> | Recall: </span><span class="sc">{</span>recall[i]<span class="sc">:.2f}</span><span class="ss"> | Speed: </span><span class="sc">{</span>speed[i]<span class="sc">:.2f}</span><span class="ss"> | Memory: </span><span class="sc">{</span>memory[i]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
📊 Index Performance Summary:
============================================================
HNSW       | Recall: 0.95 | Speed: 0.85 | Memory: 0.70
IVF-PQ     | Recall: 0.92 | Speed: 0.90 | Memory: 0.85
Annoy      | Recall: 0.88 | Speed: 0.75 | Memory: 0.80
Flat       | Recall: 1.00 | Speed: 0.20 | Memory: 0.30
============================================================</code></pre>
</div>
</div>
</section>
</section>
<section id="deep-dive-how-hnsw-works" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Deep Dive: How HNSW Works</h1>
<p><strong>Hierarchical Navigable Small World (HNSW)</strong> builds a multi-layer graph for efficient approximate nearest neighbor search.</p>
<section id="architecture" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="architecture"><span class="header-section-number">5.1</span> Architecture</h2>
<ul>
<li>Each vector is a node</li>
<li>At the <strong>top layers</strong>, only a few nodes exist (sparse)</li>
<li>At the <strong>bottom layer</strong>, all nodes exist (dense)</li>
<li>Multiple layers create a hierarchical structure for fast navigation</li>
</ul>
</section>
<section id="key-parameters" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="key-parameters"><span class="header-section-number">5.2</span> Key Parameters</h2>
<table class="table">
<colgroup>
<col style="width: 34%">
<col style="width: 40%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>M</strong></td>
<td>Max neighbors per node</td>
<td>Controls graph degree, recall, memory</td>
</tr>
<tr class="even">
<td><strong>efConstruction</strong></td>
<td>Candidate list during build</td>
<td>Higher = better recall, slower build, more memory</td>
</tr>
<tr class="odd">
<td><strong>efSearch</strong></td>
<td>Candidate list during query</td>
<td>Higher = better recall, higher latency</td>
</tr>
</tbody>
</table>
</section>
<section id="insertion-process" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="insertion-process"><span class="header-section-number">5.3</span> Insertion Process</h2>
<ol type="1">
<li><strong>Assign layer</strong>: Random maximum layer to the new node (geometric distribution)</li>
<li><strong>Start descent</strong>: Begin from entry point in the top layer</li>
<li><strong>Greedy descent</strong>: At each layer, move to neighbors closer to the new vector</li>
<li><strong>Link nodes</strong>: At target layer, link the node to its nearest neighbors using diversification heuristic (prune overly redundant edges)</li>
<li><strong>Repeat down</strong>: Continue process down through all layers</li>
</ol>
</section>
<section id="search-process" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="search-process"><span class="header-section-number">5.4</span> Search Process</h2>
<ol type="1">
<li><strong>Start at top</strong>: Begin at the top entry point</li>
<li><strong>Greedy search per layer</strong>: Move to the neighbor closest to query <span class="math inline">\(\mathbf{q}\)</span> until no improvement</li>
<li><strong>Descend</strong>: Move down one layer</li>
<li><strong>Refine at bottom</strong>: At the bottom layer, perform best-first search with bounded candidate set size <code>efSearch</code></li>
<li><strong>Return top-k</strong>: Return the k nearest neighbors</li>
</ol>
</section>
<section id="intuition" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="intuition"><span class="header-section-number">5.5</span> Intuition</h2>
<ul>
<li><strong>Upper layers</strong> “teleport” you near the right region (coarse navigation)</li>
<li><strong>Bottom layer</strong> refines the search (fine-grained precision)</li>
</ul>
</section>
<section id="trade-offs" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="trade-offs"><span class="header-section-number">5.6</span> Trade-offs</h2>
<ul>
<li>Larger <code>M</code>, <code>efConstruction</code>, <code>efSearch</code> → <strong>higher recall &amp; memory/latency</strong></li>
<li><strong>Complexity</strong>: Near log-like behavior empirically</li>
<li><strong>Memory</strong>: <span class="math inline">\(\approx O(N \times M)\)</span> edges + vectors</li>
</ul>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing HNSW layer structure</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> mpatches</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define layers</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>layers <span class="op">=</span> [</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Layer 2 (Top)"</span>, <span class="st">"y"</span>: <span class="dv">7</span>, <span class="st">"nodes"</span>: <span class="dv">3</span>, <span class="st">"color"</span>: <span class="st">"#e74c3c"</span>},</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Layer 1"</span>, <span class="st">"y"</span>: <span class="fl">4.5</span>, <span class="st">"nodes"</span>: <span class="dv">10</span>, <span class="st">"color"</span>: <span class="st">"#3498db"</span>},</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Layer 0 (Bottom)"</span>, <span class="st">"y"</span>: <span class="dv">2</span>, <span class="st">"nodes"</span>: <span class="dv">25</span>, <span class="st">"color"</span>: <span class="st">"#2ecc71"</span>}</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw layers</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> layers:</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw nodes</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    x_positions <span class="op">=</span> np.linspace(<span class="dv">1</span>, <span class="dv">11</span>, layer[<span class="st">"nodes"</span>])</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    y_pos <span class="op">=</span> layer[<span class="st">"y"</span>]</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x <span class="kw">in</span> x_positions:</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        circle <span class="op">=</span> plt.Circle((x, y_pos), <span class="fl">0.15</span>, color<span class="op">=</span>layer[<span class="st">"color"</span>], alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        ax.add_patch(circle)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw some connections (simplified)</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> layer[<span class="st">"nodes"</span>] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x_positions) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> <span class="bu">len</span>(x_positions):</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>                ax.plot([x_positions[i], x_positions[i<span class="op">+</span><span class="dv">1</span>]], [y_pos, y_pos], </span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>                       <span class="st">'k-'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Label layer</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="op">-</span><span class="fl">0.5</span>, y_pos, layer[<span class="st">"name"</span>], fontsize<span class="op">=</span><span class="dv">11</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, </span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>            va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw vertical connections between layers</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>ax.annotate(<span class="st">''</span>, xy<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">4.5</span>), xytext<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">7</span>),</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>            arrowprops<span class="op">=</span><span class="bu">dict</span>(arrowstyle<span class="op">=</span><span class="st">'-&gt;'</span>, color<span class="op">=</span><span class="st">'gray'</span>, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>ax.annotate(<span class="st">''</span>, xy<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">2</span>), xytext<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">4.5</span>),</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>            arrowprops<span class="op">=</span><span class="bu">dict</span>(arrowstyle<span class="op">=</span><span class="st">'-&gt;'</span>, color<span class="op">=</span><span class="st">'gray'</span>, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Add annotations</span></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="dv">6</span>, <span class="fl">8.5</span>, <span class="st">'Sparse Layer</span><span class="ch">\n</span><span class="st">(Fast Navigation)'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">'round'</span>, facecolor<span class="op">=</span><span class="st">'wheat'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="dv">6</span>, <span class="fl">0.5</span>, <span class="st">'Dense Layer</span><span class="ch">\n</span><span class="st">(Precise Search)'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>        bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">'round'</span>, facecolor<span class="op">=</span><span class="st">'lightblue'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Add search path illustration</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>search_path_x <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">5.5</span>, <span class="dv">6</span>, <span class="fl">6.2</span>]</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>search_path_y <span class="op">=</span> [<span class="dv">7</span>, <span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>ax.plot(search_path_x, search_path_y, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'Example Search Path'</span>)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="op">-</span><span class="dv">1</span>, <span class="dv">12</span>)</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="dv">9</span>)</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">'off'</span>)</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'upper right'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'HNSW Hierarchical Structure'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'hnsw_structure.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🏗️ HNSW Structure Explained:"</span>)</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Top layers: Few nodes, long-distance hops (coarse search)"</span>)</span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Bottom layer: All nodes, short hops (fine-grained search)"</span>)</span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Search starts at top and descends layer by layer"</span>)</span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Each layer acts as a 'highway' to quickly reach the target region"</span>)</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
🏗️ HNSW Structure Explained:
============================================================
• Top layers: Few nodes, long-distance hops (coarse search)
• Bottom layer: All nodes, short hops (fine-grained search)
• Search starts at top and descends layer by layer
• Each layer acts as a 'highway' to quickly reach the target region
============================================================</code></pre>
</div>
</div>
</section>
</section>
<section id="beyond-rag-what-else-uses-vector-databases" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Beyond RAG: What Else Uses Vector Databases?</h1>
<p>Vector databases power far more than just Retrieval-Augmented Generation. Here are key application areas:</p>
<section id="recommendation-personalization" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="recommendation-personalization"><span class="header-section-number">6.1</span> Recommendation &amp; Personalization</h2>
<p>Retrieve similar users/items, complementing traditional collaborative filtering approaches.</p>
</section>
<section id="near-duplicate-plagiarism-detection" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="near-duplicate-plagiarism-detection"><span class="header-section-number">6.2</span> Near-Duplicate &amp; Plagiarism Detection</h2>
<p>Deduplicate large corpora (news articles, code repositories, scientific preprints).</p>
</section>
<section id="anomalyoutlier-detection" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="anomalyoutlier-detection"><span class="header-section-number">6.3</span> Anomaly/Outlier Detection</h2>
<p>“Distance from manifold” heuristics for fraud detection, abuse prevention, or quality control.</p>
</section>
<section id="semantic-monitoring-alerting" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="semantic-monitoring-alerting"><span class="header-section-number">6.4</span> Semantic Monitoring &amp; Alerting</h2>
<p>Watch streams (logs, support tickets) for semantically similar incidents to trigger alerts.</p>
</section>
<section id="multimodal-search" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="multimodal-search"><span class="header-section-number">6.5</span> Multimodal Search</h2>
<ul>
<li>Image ↔︎ Text (CLIP-based)</li>
<li>Audio snippet search</li>
<li>Video moment retrieval</li>
</ul>
</section>
<section id="code-intelligence" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="code-intelligence"><span class="header-section-number">6.6</span> Code Intelligence</h2>
<ul>
<li>Similar function lookup</li>
<li>Cross-repository code search</li>
<li>Code clone detection</li>
</ul>
</section>
<section id="biochem-applications" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="biochem-applications"><span class="header-section-number">6.7</span> Bio/Chem Applications</h2>
<ul>
<li>Protein/compound embeddings for virtual screening</li>
<li>Scaffold hopping in drug discovery</li>
<li>Molecular similarity search</li>
</ul>
</section>
<section id="roboticsslam-mapping" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="roboticsslam-mapping"><span class="header-section-number">6.8</span> Robotics/SLAM &amp; Mapping</h2>
<p>Place recognition via local feature embeddings for autonomous navigation.</p>
</section>
<section id="legal-e-discovery" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="legal-e-discovery"><span class="header-section-number">6.9</span> Legal &amp; E-discovery</h2>
<p>Concept clustering and semantic curation of legal documents.</p>
</section>
<section id="content-moderation" class="level2" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="content-moderation"><span class="header-section-number">6.10</span> Content Moderation</h2>
<p>Identify similar policy-violating content across platforms.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Anomaly detection using vector distances</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> normalize</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate normal data (cluster)</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>normal_data <span class="op">=</span> np.random.randn(<span class="dv">200</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.5</span> <span class="op">+</span> np.array([<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate anomalies (outliers)</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> np.array([</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">5</span>],</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">5</span>],</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">0</span>],</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate distances from cluster center</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>center <span class="op">=</span> np.mean(normal_data, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>distances_normal <span class="op">=</span> np.linalg.norm(normal_data <span class="op">-</span> center, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>distances_anomaly <span class="op">=</span> np.linalg.norm(anomalies <span class="op">-</span> center, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Set threshold (e.g., 95th percentile of normal distances)</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> np.percentile(distances_normal, <span class="dv">95</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Scatter plot</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>ax1.scatter(normal_data[:, <span class="dv">0</span>], normal_data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, </span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'Normal'</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>ax1.scatter(anomalies[:, <span class="dv">0</span>], anomalies[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'Anomalies'</span>, marker<span class="op">=</span><span class="st">'X'</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>ax1.scatter(center[<span class="dv">0</span>], center[<span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, s<span class="op">=</span><span class="dv">200</span>, marker<span class="op">=</span><span class="st">'*'</span>, </span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'Cluster Center'</span>)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>circle <span class="op">=</span> plt.Circle(center, threshold, color<span class="op">=</span><span class="st">'orange'</span>, fill<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>                   linewidth<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Threshold (</span><span class="sc">{</span>threshold<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>ax1.add_patch(circle)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Dimension 1'</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Dimension 2'</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Anomaly Detection via Vector Distance'</span>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Distance distribution</span></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>ax2.hist(distances_normal, bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Normal Data'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>ax2.axvline(threshold, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Threshold (95th %ile)'</span>)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>ax2.scatter(distances_anomaly, [<span class="dv">5</span>]<span class="op">*</span><span class="bu">len</span>(distances_anomaly), c<span class="op">=</span><span class="st">'red'</span>, </span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>           s<span class="op">=</span><span class="dv">100</span>, marker<span class="op">=</span><span class="st">'X'</span>, label<span class="op">=</span><span class="st">'Anomalies'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Distance from Center'</span>)</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Distance Distribution'</span>)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'anomaly_detection.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔍 Anomaly Detection Results:"</span>)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cluster center: </span><span class="sc">{</span>center<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance threshold: </span><span class="sc">{</span>threshold<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Normal data distances (mean ± std): </span><span class="sc">{</span>distances_normal<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss"> ± </span><span class="sc">{</span>distances_normal<span class="sc">.</span>std()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Anomaly distances: </span><span class="sc">{</span>distances_anomaly<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Detected </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(distances_anomaly <span class="op">&gt;</span> threshold)<span class="sc">}</span><span class="ss"> anomalies out of </span><span class="sc">{</span><span class="bu">len</span>(distances_anomaly)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔍 Anomaly Detection Results:
============================================================
Cluster center: [2.00317112 2.01937749]
Distance threshold: 1.1167

Normal data distances (mean ± std): 0.5999 ± 0.3162
Anomaly distances: [4.22671195 3.5912122  3.61370569 4.25860038]

Detected 4 anomalies out of 4
============================================================</code></pre>
</div>
</div>
</section>
</section>
<section id="hybrid-search-filters-real-world-must-haves" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Hybrid Search &amp; Filters (Real-World Must-Haves)</h1>
<p>Pure vector scores are powerful, but structured filters and keywords are essential for production systems.</p>
<section id="metadata-filters-at-retrieval-time" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="metadata-filters-at-retrieval-time"><span class="header-section-number">7.1</span> Metadata Filters at Retrieval Time</h2>
<p>Filter results based on structured attributes:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>filters <span class="op">=</span> {</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lang"</span>: <span class="st">"en"</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"published_after"</span>: <span class="st">"2024-01-01"</span>,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"category"</span>: [<span class="st">"ML"</span>, <span class="st">"AI"</span>],</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"verified"</span>: <span class="va">True</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="hybrid-fusion-strategies" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="hybrid-fusion-strategies"><span class="header-section-number">7.2</span> Hybrid Fusion Strategies</h2>
<section id="a.-rank-fusion-rrf---reciprocal-rank-fusion" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="a.-rank-fusion-rrf---reciprocal-rank-fusion"><span class="header-section-number">7.2.1</span> A. Rank Fusion (RRF - Reciprocal Rank Fusion)</h3>
<p>Combine BM25 (keyword) and vector top-k lists:</p>
<p><span class="math display">\[\text{RRF}(d) = \sum_{r \in R} \frac{1}{k + r(d)}\]</span></p>
<p>where <span class="math inline">\(r(d)\)</span> is the rank of document <span class="math inline">\(d\)</span> in ranking <span class="math inline">\(r\)</span>, and <span class="math inline">\(k\)</span> is typically 60.</p>
</section>
<section id="b.-score-fusion" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="b.-score-fusion"><span class="header-section-number">7.2.2</span> B. Score Fusion</h3>
<p>Weighted sum after re-scaling:</p>
<p><span class="math display">\[\text{score}_{\text{final}} = \alpha \cdot \text{score}_{\text{vector}} + (1 - \alpha) \cdot \text{score}_{\text{keyword}}\]</span></p>
</section>
<section id="c.-neural-re-rankers" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="c.-neural-re-rankers"><span class="header-section-number">7.2.3</span> C. Neural Re-rankers</h3>
<p>Cross-encoders (e.g., MS MARCO–style) on the top 100 to boost precision@k.</p>
</section>
</section>
<section id="implementation-considerations" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="implementation-considerations"><span class="header-section-number">7.3</span> Implementation Considerations</h2>
<p><strong>Caveat:</strong> Some ANN structures don’t natively support filters. Common approaches:</p>
<ul>
<li><strong>Pre-filtering:</strong> Filter candidates before ANN search (may reduce recall)</li>
<li><strong>Post-filtering:</strong> Search larger candidate set, then filter (increases latency)</li>
<li><strong>Filter-aware IVF lists:</strong> Maintain per-segment indexes</li>
<li><strong>Partitioned indexes:</strong> Separate indexes per common filter values</li>
</ul>
</section>
<section id="when-to-use-what" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="when-to-use-what"><span class="header-section-number">7.4</span> When to Use What</h2>
<table class="table">
<thead>
<tr class="header">
<th>Use Case</th>
<th>Strategy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Few filters, high selectivity</td>
<td>Pre-filtering</td>
</tr>
<tr class="even">
<td>Many filters, low selectivity</td>
<td>Post-filtering with larger k</td>
</tr>
<tr class="odd">
<td>Common filter patterns</td>
<td>Partitioned indexes</td>
</tr>
<tr class="even">
<td>Strict latency requirements</td>
<td>Filter-aware indexes + caching</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Reciprocal Rank Fusion (RRF)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reciprocal_rank_fusion(rankings_list, k<span class="op">=</span><span class="dv">60</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Combine multiple rankings using Reciprocal Rank Fusion.</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">        rankings_list: List of rankings, where each ranking is a list of doc IDs</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">        k: Constant (typically 60)</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Combined ranking with RRF scores</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> {}</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ranking <span class="kw">in</span> rankings_list:</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rank, doc_id <span class="kw">in</span> <span class="bu">enumerate</span>(ranking, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> doc_id <span class="kw">not</span> <span class="kw">in</span> scores:</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                scores[doc_id] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>            scores[doc_id] <span class="op">+=</span> <span class="dv">1</span> <span class="op">/</span> (k <span class="op">+</span> rank)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort by score descending</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>    sorted_docs <span class="op">=</span> <span class="bu">sorted</span>(scores.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sorted_docs</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate two different ranking systems</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="co"># BM25 (keyword-based) ranking</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>bm25_ranking <span class="op">=</span> [<span class="st">'doc3'</span>, <span class="st">'doc1'</span>, <span class="st">'doc5'</span>, <span class="st">'doc2'</span>, <span class="st">'doc7'</span>, <span class="st">'doc4'</span>, <span class="st">'doc6'</span>]</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector similarity ranking</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>vector_ranking <span class="op">=</span> [<span class="st">'doc1'</span>, <span class="st">'doc2'</span>, <span class="st">'doc3'</span>, <span class="st">'doc4'</span>, <span class="st">'doc5'</span>, <span class="st">'doc8'</span>, <span class="st">'doc9'</span>]</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply RRF</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>fused_results <span class="op">=</span> reciprocal_rank_fusion([bm25_ranking, vector_ranking], k<span class="op">=</span><span class="dv">60</span>)</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔍 Hybrid Search: Reciprocal Rank Fusion</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">BM25 Ranking (Keyword-based):"</span>)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(bm25_ranking)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Vector Ranking (Semantic):"</span>)</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(vector_ranking)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Fused Ranking (RRF):</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a nice table</span></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(fused_results, columns<span class="op">=</span>[<span class="st">'Document'</span>, <span class="st">'RRF Score'</span>])</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>results_df.index <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(results_df) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>results_df[<span class="st">'RRF Score'</span>] <span class="op">=</span> results_df[<span class="st">'RRF Score'</span>].<span class="bu">round</span>(<span class="dv">6</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df.to_string())</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Notice how documents appearing in both rankings get boosted!"</span>)</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   doc1, doc2, doc3 all rank higher in the fused results."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔍 Hybrid Search: Reciprocal Rank Fusion

======================================================================

BM25 Ranking (Keyword-based):
  doc3, doc1, doc5, doc2, doc7, doc4, doc6

Vector Ranking (Semantic):
  doc1, doc2, doc3, doc4, doc5, doc8, doc9

======================================================================

Fused Ranking (RRF):

  Document  RRF Score
1     doc1   0.032522
2     doc3   0.032266
3     doc2   0.031754
4     doc5   0.031258
5     doc4   0.030777
6     doc7   0.015385
7     doc8   0.015152
8     doc6   0.014925
9     doc9   0.014925

======================================================================

💡 Notice how documents appearing in both rankings get boosted!
   doc1, doc2, doc3 all rank higher in the fused results.</code></pre>
</div>
</div>
</section>
</section>
<section id="data-model-concerns" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Data &amp; Model Concerns</h1>
<p>Getting embeddings right is crucial for vector database performance.</p>
<section id="embedding-model-selection" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="embedding-model-selection"><span class="header-section-number">8.1</span> Embedding Model Selection</h2>
<p><strong>Domain-specific encoders beat generic models:</strong> - Scientific papers: SciBERT, PubMedBERT - Code: CodeBERT, GraphCodeBERT - Legal: LegalBERT - Multilingual: mBERT, XLM-RoBERTa</p>
</section>
<section id="normalization-consistency" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="normalization-consistency"><span class="header-section-number">8.2</span> Normalization Consistency</h2>
<p><strong>Critical:</strong> Be consistent across index &amp; query - Cosine similarity requires normalized vectors - MIPS equivalence depends on normalization - Mixing normalized and unnormalized vectors breaks retrieval</p>
</section>
<section id="drift-versioning" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="drift-versioning"><span class="header-section-number">8.3</span> Drift &amp; Versioning</h2>
<p><strong>Challenge:</strong> New models produce incompatible embeddings</p>
<p><strong>Solutions:</strong> - Keep vector schema version metadata - Maintain multiple indexes during transition - Re-index incrementally (dual-write pattern) - A/B test new embeddings before full rollout</p>
</section>
<section id="chunking-for-text" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="chunking-for-text"><span class="header-section-number">8.4</span> Chunking for Text</h2>
<p><strong>Key considerations:</strong> - <strong>Window size:</strong> 256–1024 tokens common - <strong>Stride/Overlap:</strong> 20–30% overlap prevents information loss at boundaries - <strong>Chunk re-assembly:</strong> Maintain document relationships - <strong>Context preservation:</strong> Include surrounding context in metadata</p>
</section>
<section id="deduplication-collapse" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="deduplication-collapse"><span class="header-section-number">8.5</span> Deduplication &amp; Collapse</h2>
<p><strong>Prevent duplicate retrieval:</strong> - Store fingerprints (SimHash/MinHash) - Cluster near-duplicates - Post-process to remove redundant results - Maintain canonical document IDs</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Text chunking strategies</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chunk_text_with_overlap(text, chunk_size<span class="op">=</span><span class="dv">100</span>, overlap<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Split text into overlapping chunks.</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">        text: Input text string</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">        chunk_size: Size of each chunk in characters</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">        overlap: Overlap between consecutive chunks</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">        List of text chunks</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    chunks <span class="op">=</span> []</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> start <span class="op">&lt;</span> <span class="bu">len</span>(text):</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        end <span class="op">=</span> start <span class="op">+</span> chunk_size</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        chunk <span class="op">=</span> text[start:end]</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        chunks.append({</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">'chunk_id'</span>: <span class="bu">len</span>(chunks),</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text'</span>: chunk,</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">'start_pos'</span>: start,</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>            <span class="st">'end_pos'</span>: <span class="bu">min</span>(end, <span class="bu">len</span>(text)),</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>            <span class="st">'length'</span>: <span class="bu">len</span>(chunk)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        start <span class="op">+=</span> (chunk_size <span class="op">-</span> overlap)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> chunks</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Example text</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> <span class="st">"""Vector databases are specialized systems designed to store and query </span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="st">high-dimensional vectors efficiently. These vectors, or embeddings, are dense numerical </span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="st">representations of data such as text, images, or audio. The key advantage of vector </span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="st">databases is their ability to perform semantic search, finding similar items based on </span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="st">meaning rather than exact keyword matches. This makes them essential for modern AI </span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="st">applications including recommendation systems, similarity search, and retrieval-augmented </span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="st">generation (RAG) systems."""</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Create chunks with different strategies</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>chunks_no_overlap <span class="op">=</span> chunk_text_with_overlap(sample_text, chunk_size<span class="op">=</span><span class="dv">100</span>, overlap<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>chunks_with_overlap <span class="op">=</span> chunk_text_with_overlap(sample_text, chunk_size<span class="op">=</span><span class="dv">100</span>, overlap<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📄 Text Chunking Strategies</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original text length: </span><span class="sc">{</span><span class="bu">len</span>(sample_text)<span class="sc">}</span><span class="ss"> characters</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Strategy 1: No Overlap"</span>)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  → </span><span class="sc">{</span><span class="bu">len</span>(chunks_no_overlap)<span class="sc">}</span><span class="ss"> chunks created"</span>)</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, chunk <span class="kw">in</span> <span class="bu">enumerate</span>(chunks_no_overlap[:<span class="dv">3</span>], <span class="dv">1</span>):</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Chunk </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (chars </span><span class="sc">{</span>chunk[<span class="st">'start_pos'</span>]<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>chunk[<span class="st">'end_pos'</span>]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>chunk[<span class="st">'text'</span>][:<span class="dv">50</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">Strategy 2: With 20% Overlap"</span>)</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  → </span><span class="sc">{</span><span class="bu">len</span>(chunks_with_overlap)<span class="sc">}</span><span class="ss"> chunks created"</span>)</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, chunk <span class="kw">in</span> <span class="bu">enumerate</span>(chunks_with_overlap[:<span class="dv">3</span>], <span class="dv">1</span>):</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Chunk </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (chars </span><span class="sc">{</span>chunk[<span class="st">'start_pos'</span>]<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>chunk[<span class="st">'end_pos'</span>]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>chunk[<span class="st">'text'</span>][:<span class="dv">50</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Benefits of overlap:"</span>)</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Prevents information loss at chunk boundaries"</span>)</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Maintains context across chunks"</span>)</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Improves retrieval recall for cross-boundary concepts"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
📄 Text Chunking Strategies

======================================================================

Original text length: 531 characters

Strategy 1: No Overlap
  → 6 chunks created

Chunk 1 (chars 0-100):
  Vector databases are specialized systems designed ...

Chunk 2 (chars 100-200):
  iently. These vectors, or embeddings, are dense nu...

Chunk 3 (chars 200-300):
  ges, or audio. The key advantage of vector 
databa...

----------------------------------------------------------------------


Strategy 2: With 20% Overlap
  → 7 chunks created

Chunk 1 (chars 0-100):
  Vector databases are specialized systems designed ...

Chunk 2 (chars 80-180):
  sional vectors efficiently. These vectors, or embe...

Chunk 3 (chars 160-260):
  epresentations of data such as text, images, or au...

======================================================================

💡 Benefits of overlap:
  • Prevents information loss at chunk boundaries
  • Maintains context across chunks
  • Improves retrieval recall for cross-boundary concepts</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluation-quantify-good" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Evaluation: Quantify “Good”</h1>
<p>Measuring vector database performance requires multiple metrics across different dimensions.</p>
<section id="retrieval-quality-metrics" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="retrieval-quality-metrics"><span class="header-section-number">9.1</span> Retrieval Quality Metrics</h2>
<section id="recallk" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="recallk"><span class="header-section-number">9.1.1</span> Recall@k</h3>
<p><span class="math display">\[\text{Recall@k} = \frac{\text{# relevant items in top-k}}{\text{total # relevant items}}\]</span></p>
<p>Measures what fraction of relevant items are retrieved in top-k results. Compare against exact search or high-ef baseline.</p>
</section>
<section id="ndcg-normalized-discounted-cumulative-gain" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="ndcg-normalized-discounted-cumulative-gain"><span class="header-section-number">9.1.2</span> NDCG (Normalized Discounted Cumulative Gain)</h3>
<p><span class="math display">\[\text{NDCG@k} = \frac{\text{DCG@k}}{\text{IDCG@k}}\]</span></p>
<p>where <span class="math inline">\(\text{DCG@k} = \sum_{i=1}^{k} \frac{2^{rel_i} - 1}{\log_2(i + 1)}\)</span></p>
<p>Accounts for position and relevance grades (not just binary relevant/irrelevant).</p>
</section>
<section id="mrr-mean-reciprocal-rank" class="level3" data-number="9.1.3">
<h3 data-number="9.1.3" class="anchored" data-anchor-id="mrr-mean-reciprocal-rank"><span class="header-section-number">9.1.3</span> MRR (Mean Reciprocal Rank)</h3>
<p><span class="math display">\[\text{MRR} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\text{rank}_i}\]</span></p>
<p>Measures the average inverse rank of the first relevant result.</p>
</section>
</section>
<section id="performance-metrics" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="performance-metrics"><span class="header-section-number">9.2</span> Performance Metrics</h2>
<ul>
<li><strong>Latency:</strong> P50/P95/P99 under production load</li>
<li><strong>QPS (Queries Per Second):</strong> Throughput capacity</li>
<li><strong>Index build time:</strong> Time to build/rebuild indexes</li>
<li><strong>Memory footprint:</strong> RAM/GPU per million vectors</li>
</ul>
</section>
<section id="cost-metrics" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="cost-metrics"><span class="header-section-number">9.3</span> Cost Metrics</h2>
<ul>
<li><strong>Infrastructure cost:</strong> $/query or $/million vectors</li>
<li><strong>Operational overhead:</strong> Maintenance, monitoring, updates</li>
<li><strong>Storage cost:</strong> Disk, RAM, GPU requirements</li>
</ul>
</section>
<section id="business-metrics-ab-testing" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="business-metrics-ab-testing"><span class="header-section-number">9.4</span> Business Metrics (A/B Testing)</h2>
<ul>
<li><strong>Click-through rate (CTR):</strong> User engagement with results</li>
<li><strong>Success rate:</strong> Task completion percentage</li>
<li><strong>Dwell time:</strong> Time spent with retrieved content</li>
<li><strong>User satisfaction:</strong> Direct feedback or NPS scores</li>
</ul>
</section>
<section id="evaluation-best-practices" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="evaluation-best-practices"><span class="header-section-number">9.5</span> Evaluation Best Practices</h2>
<ol type="1">
<li><strong>Establish baselines:</strong> Always compare against exact search</li>
<li><strong>Use holdout sets:</strong> Avoid overfitting to test queries</li>
<li><strong>Monitor in production:</strong> Online metrics often differ from offline</li>
<li><strong>Track over time:</strong> Detect drift and degradation</li>
<li><strong>Segment analysis:</strong> Different query types may have different performance</li>
</ol>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Computing evaluation metrics</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> recall_at_k(retrieved, relevant, k):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate Recall@k"""</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    retrieved_k <span class="op">=</span> <span class="bu">set</span>(retrieved[:k])</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    relevant_set <span class="op">=</span> <span class="bu">set</span>(relevant)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(retrieved_k <span class="op">&amp;</span> relevant_set) <span class="op">/</span> <span class="bu">len</span>(relevant_set) <span class="cf">if</span> relevant_set <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dcg_at_k(relevance_scores, k):</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate DCG@k"""</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    relevance_scores <span class="op">=</span> np.array(relevance_scores[:k])</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    gains <span class="op">=</span> <span class="dv">2</span><span class="op">**</span>relevance_scores <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    discounts <span class="op">=</span> np.log2(np.arange(<span class="dv">2</span>, <span class="bu">len</span>(relevance_scores) <span class="op">+</span> <span class="dv">2</span>))</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(gains <span class="op">/</span> discounts)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ndcg_at_k(retrieved_relevance, ideal_relevance, k):</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate NDCG@k"""</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    dcg <span class="op">=</span> dcg_at_k(retrieved_relevance, k)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    idcg <span class="op">=</span> dcg_at_k(<span class="bu">sorted</span>(ideal_relevance, reverse<span class="op">=</span><span class="va">True</span>), k)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dcg <span class="op">/</span> idcg <span class="cf">if</span> idcg <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mrr(retrieved_lists, relevant_lists):</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate Mean Reciprocal Rank"""</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    reciprocal_ranks <span class="op">=</span> []</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> retrieved, relevant <span class="kw">in</span> <span class="bu">zip</span>(retrieved_lists, relevant_lists):</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>        relevant_set <span class="op">=</span> <span class="bu">set</span>(relevant)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rank, item <span class="kw">in</span> <span class="bu">enumerate</span>(retrieved, <span class="dv">1</span>):</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> item <span class="kw">in</span> relevant_set:</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>                reciprocal_ranks.append(<span class="dv">1</span> <span class="op">/</span> rank)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>            reciprocal_ranks.append(<span class="dv">0</span>)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(reciprocal_ranks)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Example data</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Query 1</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>retrieved_1 <span class="op">=</span> [<span class="st">'doc3'</span>, <span class="st">'doc1'</span>, <span class="st">'doc5'</span>, <span class="st">'doc2'</span>, <span class="st">'doc7'</span>, <span class="st">'doc4'</span>]</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>relevant_1 <span class="op">=</span> [<span class="st">'doc1'</span>, <span class="st">'doc2'</span>, <span class="st">'doc4'</span>]</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>relevance_scores_1 <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>]  <span class="co"># Graded relevance (0-3 scale)</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Query 2</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>retrieved_2 <span class="op">=</span> [<span class="st">'doc8'</span>, <span class="st">'doc6'</span>, <span class="st">'doc9'</span>, <span class="st">'doc2'</span>, <span class="st">'doc1'</span>]</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>relevant_2 <span class="op">=</span> [<span class="st">'doc1'</span>, <span class="st">'doc2'</span>]</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>relevance_scores_2 <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Evaluation Metrics Examples</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics for Query 1</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Query 1:"</span>)</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Retrieved: </span><span class="sc">{</span>retrieved_1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Relevant:  </span><span class="sc">{</span>relevant_1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@3:  </span><span class="sc">{</span>recall_at_k(retrieved_1, relevant_1, <span class="dv">3</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@5:  </span><span class="sc">{</span>recall_at_k(retrieved_1, relevant_1, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  NDCG@5:    </span><span class="sc">{</span>ndcg_at_k(relevance_scores_1, relevance_scores_1, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Query 2:"</span>)</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Retrieved: </span><span class="sc">{</span>retrieved_2<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Relevant:  </span><span class="sc">{</span>relevant_2<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@3:  </span><span class="sc">{</span>recall_at_k(retrieved_2, relevant_2, <span class="dv">3</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@5:  </span><span class="sc">{</span>recall_at_k(retrieved_2, relevant_2, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  NDCG@5:    </span><span class="sc">{</span>ndcg_at_k(relevance_scores_2, relevance_scores_2, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a><span class="co"># MRR across both queries</span></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>mrr_score <span class="op">=</span> mrr([retrieved_1, retrieved_2], [relevant_1, relevant_2])</span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Mean Reciprocal Rank (MRR): </span><span class="sc">{</span>mrr_score<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize recall@k</span></span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>recall_1 <span class="op">=</span> [recall_at_k(retrieved_1, relevant_1, k) <span class="cf">for</span> k <span class="kw">in</span> k_values]</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>recall_2 <span class="op">=</span> [recall_at_k(retrieved_2, relevant_2, k) <span class="cf">for</span> k <span class="kw">in</span> k_values]</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, recall_1, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Query 1'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, recall_2, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Query 2'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'k (number of results)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Recall@k'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Recall@k for Two Sample Queries'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a>plt.xticks(k_values)</span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'recall_at_k.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
📊 Evaluation Metrics Examples

======================================================================

Query 1:
  Retrieved: ['doc3', 'doc1', 'doc5', 'doc2', 'doc7', 'doc4']
  Relevant:  ['doc1', 'doc2', 'doc4']
  Recall@3:  0.3333
  Recall@5:  0.6667
  NDCG@5:    0.6078

Query 2:
  Retrieved: ['doc8', 'doc6', 'doc9', 'doc2', 'doc1']
  Relevant:  ['doc1', 'doc2']
  Recall@3:  0.0000
  Recall@5:  1.0000
  NDCG@5:    0.4695

Mean Reciprocal Rank (MRR): 0.3750

======================================================================</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-11-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="operating-at-scale" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Operating at Scale</h1>
<p>Production vector databases require careful operational planning.</p>
<section id="index-build-updates" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="index-build-updates"><span class="header-section-number">10.1</span> Index Build &amp; Updates</h2>
<p><strong>Batch Operations:</strong> - Offline batch build for major changes - Schedule during low-traffic periods - Use distributed build for large datasets</p>
<p><strong>Streaming Updates:</strong> - Real-time upserts for freshness requirements - Balance throughput vs consistency - Monitor lag between write and searchability</p>
<p><strong>Delete Handling:</strong> - Lazy deletes with tombstone markers - Background consolidation/compaction - Plan for periodic full rebuilds</p>
<p><strong>Deployment Strategy:</strong> - Keep read replicas for zero-downtime updates - Blue/green deployment for index version changes - Gradual rollout with traffic splitting</p>
</section>
<section id="sharding-strategies" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="sharding-strategies"><span class="header-section-number">10.2</span> Sharding Strategies</h2>
<p><strong>Hash Sharding:</strong> - Uniform distribution by document ID - Simple routing logic - Good for load balancing</p>
<p><strong>Semantic Sharding:</strong> - Partition by domain/topic/category - Improves cache locality - Enables targeted search</p>
<p><strong>Query Routing:</strong> - Coarse hash for uniform shards - Routing model for semantic shards - Fan-out to multiple shards when needed</p>
</section>
<section id="caching-strategies" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="caching-strategies"><span class="header-section-number">10.3</span> Caching Strategies</h2>
<p><strong>Query Vector Cache:</strong> - Cache embeddings for popular queries - LRU eviction policy - Shared across replicas</p>
<p><strong>Result Cache:</strong> - Cache complete search results - Short TTL for dynamic data - Invalidate on updates</p>
<p><strong>Precomputation:</strong> - Pre-embed frequent query patterns - Materialize popular aggregations - Scheduled refresh</p>
</section>
<section id="hardware-considerations" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="hardware-considerations"><span class="header-section-number">10.4</span> Hardware Considerations</h2>
<p><strong>GPU vs CPU:</strong> - <strong>GPU:</strong> Excellent for IVF-PQ, flat re-rank, large batch queries - <strong>CPU:</strong> Fine for HNSW, lower QPS, memory-optimized workloads</p>
<p><strong>Memory Architecture:</strong> - Watch NUMA placement for multi-socket systems - Leverage SIMD instructions (AVX-512, NEON) - Monitor memory bandwidth bottlenecks</p>
<p><strong>Storage Tiers:</strong> - Hot data in RAM/GPU memory - Warm data on NVMe SSD - Cold data on HDD or object storage</p>
</section>
<section id="security-compliance" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="security-compliance"><span class="header-section-number">10.5</span> Security &amp; Compliance</h2>
<p><strong>Data Protection:</strong> - Encryption at rest and in transit - Field-level encryption for sensitive data - Secure key management</p>
<p><strong>Access Control:</strong> - Row-level ACLs for multi-tenancy - Attribute-based access control (ABAC) - API key rotation policies</p>
<p><strong>Compliance:</strong> - Right-to-be-forgotten requires true deletion - Audit logs for all access - Data residency requirements - GDPR, CCPA, HIPAA considerations</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Simulating sharding strategies</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hashlib</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hash_shard(doc_id, num_shards):</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Hash-based sharding"""</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    hash_val <span class="op">=</span> <span class="bu">int</span>(hashlib.md5(doc_id.encode()).hexdigest(), <span class="dv">16</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hash_val <span class="op">%</span> num_shards</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> semantic_shard(doc_category, category_to_shard):</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Semantic/category-based sharding"""</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> category_to_shard.get(doc_category, <span class="dv">0</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample documents</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> [</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc1"</span>, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"title"</span>: <span class="st">"Neural Networks"</span>},</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc2"</span>, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"title"</span>: <span class="st">"Deep Learning"</span>},</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc3"</span>, <span class="st">"category"</span>: <span class="st">"DB"</span>, <span class="st">"title"</span>: <span class="st">"Vector Databases"</span>},</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc4"</span>, <span class="st">"category"</span>: <span class="st">"DB"</span>, <span class="st">"title"</span>: <span class="st">"Indexing Strategies"</span>},</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc5"</span>, <span class="st">"category"</span>: <span class="st">"NLP"</span>, <span class="st">"title"</span>: <span class="st">"Transformers"</span>},</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc6"</span>, <span class="st">"category"</span>: <span class="st">"NLP"</span>, <span class="st">"title"</span>: <span class="st">"Text Embeddings"</span>},</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc7"</span>, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"title"</span>: <span class="st">"CNNs"</span>},</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc8"</span>, <span class="st">"category"</span>: <span class="st">"DB"</span>, <span class="st">"title"</span>: <span class="st">"Query Optimization"</span>},</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>num_shards <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>category_to_shard <span class="op">=</span> {<span class="st">"ML"</span>: <span class="dv">0</span>, <span class="st">"DB"</span>: <span class="dv">1</span>, <span class="st">"NLP"</span>: <span class="dv">2</span>}</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔀 Sharding Strategies Comparison</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Hash sharding</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Hash-based Sharding:"</span>)</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>hash_shards <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)}</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> documents:</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>    shard <span class="op">=</span> hash_shard(doc[<span class="st">"id"</span>], num_shards)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>    hash_shards[shard].append(doc[<span class="st">"id"</span>])</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> shard_id, docs <span class="kw">in</span> hash_shards.items():</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Shard </span><span class="sc">{</span>shard_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>docs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Semantic sharding</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Semantic Sharding (by category):"</span>)</span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>semantic_shards <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)}</span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> documents:</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>    shard <span class="op">=</span> semantic_shard(doc[<span class="st">"category"</span>], category_to_shard)</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>    semantic_shards[shard].append(<span class="ss">f"</span><span class="sc">{</span>doc[<span class="st">'id'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>doc[<span class="st">'category'</span>]<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> shard_id, docs <span class="kw">in</span> semantic_shards.items():</span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>    categories <span class="op">=</span> [<span class="st">"ML"</span>, <span class="st">"DB"</span>, <span class="st">"NLP"</span>]</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Shard </span><span class="sc">{</span>shard_id<span class="sc">}</span><span class="ss"> [</span><span class="sc">{</span>categories[shard_id]<span class="sc">}</span><span class="ss">]: </span><span class="sc">{</span>docs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Trade-offs:"</span>)</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Hash sharding: Uniform load, requires fan-out for category queries"</span>)</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Semantic sharding: Targeted queries, but potential load imbalance"</span>)</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Hybrid: Use semantic for common patterns, hash for others"</span>)</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize distribution</span></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Hash sharding distribution</span></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>hash_counts <span class="op">=</span> [<span class="bu">len</span>(hash_shards[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)]</span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a>ax1.bar(<span class="bu">range</span>(num_shards), hash_counts, color<span class="op">=</span><span class="st">'steelblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Shard ID'</span>)</span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Number of Documents'</span>)</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Hash-based Sharding</span><span class="ch">\n</span><span class="st">(Uniform Distribution)'</span>)</span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>ax1.set_xticks(<span class="bu">range</span>(num_shards))</span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Semantic sharding distribution</span></span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a>semantic_counts <span class="op">=</span> [<span class="bu">len</span>(semantic_shards[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)]</span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'#e74c3c'</span>, <span class="st">'#3498db'</span>, <span class="st">'#2ecc71'</span>]</span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a>ax2.bar(<span class="bu">range</span>(num_shards), semantic_counts, color<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Shard ID'</span>)</span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Number of Documents'</span>)</span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Semantic Sharding</span><span class="ch">\n</span><span class="st">(Category-based)'</span>)</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a>ax2.set_xticks(<span class="bu">range</span>(num_shards))</span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a>ax2.set_xticklabels([<span class="st">'ML'</span>, <span class="st">'DB'</span>, <span class="st">'NLP'</span>])</span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'sharding_strategies.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔀 Sharding Strategies Comparison

======================================================================

Hash-based Sharding:
  Shard 0: ['doc5', 'doc6', 'doc7']
  Shard 1: ['doc2', 'doc4']
  Shard 2: ['doc1', 'doc3', 'doc8']

Semantic Sharding (by category):
  Shard 0 [ML]: ['doc1 (ML)', 'doc2 (ML)', 'doc7 (ML)']
  Shard 1 [DB]: ['doc3 (DB)', 'doc4 (DB)', 'doc8 (DB)']
  Shard 2 [NLP]: ['doc5 (NLP)', 'doc6 (NLP)']

======================================================================

💡 Trade-offs:
  • Hash sharding: Uniform load, requires fan-out for category queries
  • Semantic sharding: Targeted queries, but potential load imbalance
  • Hybrid: Use semantic for common patterns, hash for others</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="challenges-how-to-handle-them" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Challenges &amp; How to Handle Them</h1>
<table class="table">
<colgroup>
<col style="width: 29%">
<col style="width: 37%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Challenge</th>
<th>Why it hurts</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Recall–latency trade-off</strong></td>
<td>Higher efSearch/nprobe → slower queries</td>
<td>Tune per route (mobile vs internal tool); two-stage ranking with fast first-pass</td>
</tr>
<tr class="even">
<td><strong>Filters with ANN</strong></td>
<td>Index isn’t filter-aware, breaks assumptions</td>
<td>Pre-partition by key filters; maintain per-segment indexes; post-filter with larger candidate lists</td>
</tr>
<tr class="odd">
<td><strong>Drift / re-embeddings</strong></td>
<td>Embedding versions incompatible, breaks search</td>
<td>Versioned vector fields; dual-write during transition; gradual cutover with monitoring</td>
</tr>
<tr class="even">
<td><strong>Quantization error</strong></td>
<td>PQ shrinks vectors, may lose nuance</td>
<td>Use OPQ (learned rotation); mixed precision (PQ for recall@100, float for re-rank)</td>
</tr>
<tr class="odd">
<td><strong>Deletions</strong></td>
<td>HNSW lazy deletes leave “ghost” nodes</td>
<td>Periodic rebuild/compaction; tombstone pruning; maintain delete bitmap</td>
</tr>
</tbody>
</table>
</section>
<section id="practical-sizing-tuning-cheatsheet" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Practical Sizing &amp; Tuning Cheatsheet</h1>
<p>A quick reference guide for getting started with vector database configuration.</p>
<section id="initial-setup-checklist" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="initial-setup-checklist"><span class="header-section-number">12.1</span> Initial Setup Checklist</h2>
<p>✅ <strong>Pick metric early</strong> (cosine vs L2 vs MIPS) - Cosine: Most common for text/semantic search - L2: When magnitude matters - MIPS: For asymmetric similarity tasks</p>
<p>✅ <strong>Choose index based on scale:</strong></p>
<p><strong>≤ 50M vectors, RAM-based:</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HNSW configuration</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> HNSWIndex(</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">768</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    M<span class="op">=</span><span class="dv">16</span>,                    <span class="co"># Start with 16-32</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    efConstruction<span class="op">=</span><span class="dv">200</span>,      <span class="co"># 200-400 for good recall</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    efSearch<span class="op">=</span><span class="dv">64</span>,             <span class="co"># Tune based on latency SLO</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">'cosine'</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>50M–1B vectors or GPU:</strong></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># IVF-PQ configuration</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>nlist <span class="op">=</span> <span class="bu">int</span>(np.sqrt(n_vectors))  <span class="co"># e.g., 31,623 for 1B vectors</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> IVFPQIndex(</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">768</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    nlist<span class="op">=</span>nlist,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    nprobe<span class="op">=</span><span class="dv">16</span>,               <span class="co"># Start with 8-64</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    m<span class="op">=</span><span class="dv">64</span>,                    <span class="co"># PQ subvectors</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    nbits<span class="op">=</span><span class="dv">8</span>,                 <span class="co"># bits per subvector</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">'cosine'</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="tuning-for-latency-slo" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="tuning-for-latency-slo"><span class="header-section-number">12.2</span> Tuning for Latency SLO</h2>
<p><strong>Target: 95% recall@k with P95 latency &lt; threshold</strong></p>
<ol type="1">
<li><strong>Baseline:</strong> Start with conservative params</li>
<li><strong>Measure:</strong> Run benchmark queries, measure recall &amp; latency</li>
<li><strong>Iterate:</strong> Gradually increase efSearch/nprobe</li>
<li><strong>Monitor:</strong> Stop when latency SLO is met or recall plateaus</li>
</ol>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example tuning loop</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">512</span>]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ef <span class="kw">in</span> params:</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    index.efSearch <span class="op">=</span> ef</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    recall, p95_latency <span class="op">=</span> benchmark(index, test_queries)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"ef=</span><span class="sc">{</span>ef<span class="sc">}</span><span class="ss">: recall=</span><span class="sc">{</span>recall<span class="sc">:.3f}</span><span class="ss">, P95=</span><span class="sc">{</span>p95_latency<span class="sc">:.1f}</span><span class="ss">ms"</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> recall <span class="op">&gt;=</span> <span class="fl">0.95</span> <span class="kw">and</span> p95_latency <span class="op">&lt;=</span> target_latency:</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="hybrid-search-setup" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="hybrid-search-setup"><span class="header-section-number">12.3</span> Hybrid Search Setup</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Enable both vector and keyword search</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vector_search'</span>: {</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'enabled'</span>: <span class="va">True</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'weight'</span>: <span class="fl">0.7</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'keyword_search'</span>: {</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'enabled'</span>: <span class="va">True</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'algorithm'</span>: <span class="st">'BM25'</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'weight'</span>: <span class="fl">0.3</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fusion_method'</span>: <span class="st">'RRF'</span>,  <span class="co"># or 'weighted_sum'</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reranker'</span>: {</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'model'</span>: <span class="st">'cross-encoder/ms-marco-MiniLM-L-6-v2'</span>,</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'top_k'</span>: <span class="dv">100</span>  <span class="co"># Re-rank top 100 from fusion</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="filter-configuration" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="filter-configuration"><span class="header-section-number">12.4</span> Filter Configuration</h2>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Segment by common filters</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>filter_strategy <span class="op">=</span> {</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tenant_id'</span>: <span class="st">'pre_partition'</span>,     <span class="co"># High cardinality</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'language'</span>: <span class="st">'segment_index'</span>,      <span class="co"># Low cardinality (10-20 values)</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'publish_date'</span>: <span class="st">'post_filter'</span>,    <span class="co"># Range filter</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'category'</span>: <span class="st">'segment_index'</span>       <span class="co"># Common query pattern</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="operational-monitoring" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="operational-monitoring"><span class="header-section-number">12.5</span> Operational Monitoring</h2>
<p><strong>Key metrics to track:</strong></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> {</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Quality</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'recall_at_10'</span>: target <span class="op">&gt;=</span> <span class="fl">0.95</span>,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ndcg_at_10'</span>: target <span class="op">&gt;=</span> <span class="fl">0.85</span>,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Performance</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p50_latency_ms'</span>: target <span class="op">&lt;=</span> <span class="dv">20</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p95_latency_ms'</span>: target <span class="op">&lt;=</span> <span class="dv">50</span>,</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p99_latency_ms'</span>: target <span class="op">&lt;=</span> <span class="dv">100</span>,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'qps'</span>: target <span class="op">&gt;=</span> <span class="dv">1000</span>,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resource</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'memory_per_million_vectors_gb'</span>: monitor,</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gpu_utilization_%'</span>: target <span class="op">&gt;=</span> <span class="dv">70</span>,</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'cache_hit_rate_%'</span>: target <span class="op">&gt;=</span> <span class="dv">80</span>,</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Operations</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'index_freshness_lag_seconds'</span>: target <span class="op">&lt;=</span> <span class="dv">300</span>,</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'failed_query_rate_%'</span>: target <span class="op">&lt;=</span> <span class="fl">0.1</span>,</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="blue-green-deployment" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="blue-green-deployment"><span class="header-section-number">12.6</span> Blue-Green Deployment</h2>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Version transition workflow</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>deployment <span class="op">=</span> {</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_1_dual_write'</span>: {</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'duration'</span>: <span class="st">'1 week'</span>,</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'write_to'</span>: [<span class="st">'index_v1'</span>, <span class="st">'index_v2'</span>],</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'read_from'</span>: <span class="st">'index_v1'</span>,</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">100</span>, <span class="st">'v2'</span>: <span class="dv">0</span>}</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_2_canary'</span>: {</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'duration'</span>: <span class="st">'3 days'</span>,</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">95</span>, <span class="st">'v2'</span>: <span class="dv">5</span>},</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'monitor'</span>: [<span class="st">'recall'</span>, <span class="st">'latency'</span>, <span class="st">'error_rate'</span>]</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_3_ramp'</span>: {</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'duration'</span>: <span class="st">'1 week'</span>,</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">50</span>, <span class="st">'v2'</span>: <span class="dv">50</span>},</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_4_cutover'</span>: {</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">0</span>, <span class="st">'v2'</span>: <span class="dv">100</span>},</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'deprecate'</span>: <span class="st">'index_v1'</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="minimal-example-with-faiss" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> Minimal Example with FAISS</h1>
<p>Let’s build a complete working example using FAISS, one of the most popular vector search libraries.</p>
<section id="installation" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="installation"><span class="header-section-number">13.1</span> Installation</h2>
<div class="sourceCode" id="cb31"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CPU version</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install faiss-cpu</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># GPU version (if CUDA is available)</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install faiss-gpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="complete-ivf-pq-implementation" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="complete-ivf-pq-implementation"><span class="header-section-number">13.2</span> Complete IVF-PQ Implementation</h2>
<p>Below is a production-style implementation using FAISS with IVF-PQ indexing.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Complete FAISS example with IVF-PQ indexing</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: Install faiss-cpu first: pip install faiss-cpu numpy</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># For visualization</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vector Database with FAISS: Complete Example"</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Generate synthetic embeddings</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Step 1: Generating synthetic embeddings..."</span>)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">768</span>  <span class="co"># embedding dimension (typical for sentence transformers)</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> <span class="dv">100000</span>  <span class="co"># number of vectors in the database</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>nq <span class="op">=</span> <span class="dv">100</span>  <span class="co"># number of queries</span></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic embeddings (in practice, use real embedding models)</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>xb <span class="op">=</span> np.random.randn(nb, d).astype(<span class="st">'float32'</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>xq <span class="op">=</span> np.random.randn(nq, d).astype(<span class="st">'float32'</span>)</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize for cosine similarity (important!)</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>xb <span class="op">=</span> xb <span class="op">/</span> np.linalg.norm(xb, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>xq <span class="op">=</span> xq <span class="op">/</span> np.linalg.norm(xq, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Created </span><span class="sc">{</span>nb<span class="sc">:,}</span><span class="ss"> database vectors"</span>)</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Created </span><span class="sc">{</span>nq<span class="sc">:,}</span><span class="ss"> query vectors"</span>)</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Dimension: </span><span class="sc">{</span>d<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Memory footprint: </span><span class="sc">{</span>xb<span class="sc">.</span>nbytes <span class="op">/</span> <span class="dv">1024</span><span class="op">**</span><span class="dv">2</span><span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Build the index</span></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🏗️  Step 2: Building IVF-PQ index..."</span>)</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> faiss</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># IVF-PQ parameters</span></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>    nlist <span class="op">=</span> <span class="dv">256</span>  <span class="co"># number of clusters (cells)</span></span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> <span class="dv">64</span>       <span class="co"># number of subquantizers (must divide d evenly)</span></span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>    nbits <span class="op">=</span> <span class="dv">8</span>    <span class="co"># bits per subquantizer</span></span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create quantizer (for coarse search)</span></span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>    quantizer <span class="op">=</span> faiss.IndexFlatIP(d)  <span class="co"># Inner Product = cosine for normalized vectors</span></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create IVF-PQ index</span></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> faiss.IndexIVFPQ(quantizer, d, nlist, m, nbits)</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train the index (k-means + PQ training)</span></span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Training index with nlist=</span><span class="sc">{</span>nlist<span class="sc">}</span><span class="ss">, m=</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">, nbits=</span><span class="sc">{</span>nbits<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>    index.train(xb)</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>    train_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Training completed in </span><span class="sc">{</span>train_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add vectors to the index</span></span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Adding </span><span class="sc">{</span>nb<span class="sc">:,}</span><span class="ss"> vectors..."</span>)</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>    index.add(xb)</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>    add_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Vectors added in </span><span class="sc">{</span>add_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Index contains </span><span class="sc">{</span>index<span class="sc">.</span>ntotal<span class="sc">:,}</span><span class="ss"> vectors"</span>)</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: Search</span></span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔍 Step 3: Performing search..."</span>)</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set search parameters</span></span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>    index.nprobe <span class="op">=</span> <span class="dv">16</span>  <span class="co"># number of clusters to search (recall/latency trade-off)</span></span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> <span class="dv">10</span>  <span class="co"># return top-10 neighbors</span></span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Search parameters: nprobe=</span><span class="sc">{</span>index<span class="sc">.</span>nprobe<span class="sc">}</span><span class="ss">, k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform search</span></span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a>    scores, indices <span class="op">=</span> index.search(xq, k)</span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a>    search_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb32-86"><a href="#cb32-86" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-87"><a href="#cb32-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Searched </span><span class="sc">{</span>nq<span class="sc">}</span><span class="ss"> queries in </span><span class="sc">{</span>search_time<span class="op">*</span><span class="dv">1000</span><span class="sc">:.2f}</span><span class="ss"> ms"</span>)</span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Throughput: </span><span class="sc">{</span>nq<span class="op">/</span>search_time<span class="sc">:.0f}</span><span class="ss"> QPS"</span>)</span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Average latency: </span><span class="sc">{</span>search_time<span class="op">/</span>nq<span class="op">*</span><span class="dv">1000</span><span class="sc">:.2f}</span><span class="ss"> ms per query"</span>)</span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 4: Display results</span></span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📋 Step 4: Sample results..."</span>)</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First query results:"</span>)</span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Top-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> neighbor IDs: </span><span class="sc">{</span>indices[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Top-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> scores: </span><span class="sc">{</span>scores[<span class="dv">0</span>]<span class="sc">.</span><span class="bu">round</span>(<span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 5: Tune nprobe for recall/latency trade-off</span></span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">⚙️  Step 5: Tuning nprobe parameter..."</span>)</span>
<span id="cb32-103"><a href="#cb32-103" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-104"><a href="#cb32-104" aria-hidden="true" tabindex="-1"></a>    nprobe_values <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>]</span>
<span id="cb32-105"><a href="#cb32-105" aria-hidden="true" tabindex="-1"></a>    latencies <span class="op">=</span> []</span>
<span id="cb32-106"><a href="#cb32-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-107"><a href="#cb32-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> nprobe <span class="kw">in</span> nprobe_values:</span>
<span id="cb32-108"><a href="#cb32-108" aria-hidden="true" tabindex="-1"></a>        index.nprobe <span class="op">=</span> nprobe</span>
<span id="cb32-109"><a href="#cb32-109" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> time.time()</span>
<span id="cb32-110"><a href="#cb32-110" aria-hidden="true" tabindex="-1"></a>        _, _ <span class="op">=</span> index.search(xq[:<span class="dv">10</span>], k)  <span class="co"># Test with 10 queries</span></span>
<span id="cb32-111"><a href="#cb32-111" aria-hidden="true" tabindex="-1"></a>        elapsed <span class="op">=</span> (time.time() <span class="op">-</span> start) <span class="op">/</span> <span class="dv">10</span> <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># ms per query</span></span>
<span id="cb32-112"><a href="#cb32-112" aria-hidden="true" tabindex="-1"></a>        latencies.append(elapsed)</span>
<span id="cb32-113"><a href="#cb32-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-114"><a href="#cb32-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot results</span></span>
<span id="cb32-115"><a href="#cb32-115" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb32-116"><a href="#cb32-116" aria-hidden="true" tabindex="-1"></a>    ax.plot(nprobe_values, latencies, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb32-117"><a href="#cb32-117" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'nprobe (number of clusters searched)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-118"><a href="#cb32-118" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Latency (ms per query)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb32-119"><a href="#cb32-119" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Search Latency vs nprobe'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb32-120"><a href="#cb32-120" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb32-121"><a href="#cb32-121" aria-hidden="true" tabindex="-1"></a>    ax.set_xscale(<span class="st">'log'</span>, base<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb32-122"><a href="#cb32-122" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-123"><a href="#cb32-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Annotate points</span></span>
<span id="cb32-124"><a href="#cb32-124" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (np_val, lat) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(nprobe_values, latencies)):</span>
<span id="cb32-125"><a href="#cb32-125" aria-hidden="true" tabindex="-1"></a>        ax.annotate(<span class="ss">f'</span><span class="sc">{</span>lat<span class="sc">:.2f}</span><span class="ss">ms'</span>, </span>
<span id="cb32-126"><a href="#cb32-126" aria-hidden="true" tabindex="-1"></a>                   xy<span class="op">=</span>(np_val, lat), </span>
<span id="cb32-127"><a href="#cb32-127" aria-hidden="true" tabindex="-1"></a>                   xytext<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>), </span>
<span id="cb32-128"><a href="#cb32-128" aria-hidden="true" tabindex="-1"></a>                   textcoords<span class="op">=</span><span class="st">'offset points'</span>,</span>
<span id="cb32-129"><a href="#cb32-129" aria-hidden="true" tabindex="-1"></a>                   fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb32-130"><a href="#cb32-130" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-131"><a href="#cb32-131" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb32-132"><a href="#cb32-132" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'faiss_nprobe_tuning.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb32-133"><a href="#cb32-133" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb32-134"><a href="#cb32-134" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-135"><a href="#cb32-135" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb32-136"><a href="#cb32-136" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✅ FAISS example completed successfully!"</span>)</span>
<span id="cb32-137"><a href="#cb32-137" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb32-138"><a href="#cb32-138" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-139"><a href="#cb32-139" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb32-140"><a href="#cb32-140" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">⚠️  FAISS not installed. Install with: pip install faiss-cpu"</span>)</span>
<span id="cb32-141"><a href="#cb32-141" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Here's what the code would do:"</span>)</span>
<span id="cb32-142"><a href="#cb32-142" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  1. Create an IVF-PQ index with cosine similarity"</span>)</span>
<span id="cb32-143"><a href="#cb32-143" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  2. Train the index on 100K vectors"</span>)</span>
<span id="cb32-144"><a href="#cb32-144" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  3. Perform fast approximate nearest neighbor search"</span>)</span>
<span id="cb32-145"><a href="#cb32-145" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  4. Demonstrate recall/latency trade-offs"</span>)</span>
<span id="cb32-146"><a href="#cb32-146" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb32-147"><a href="#cb32-147" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">❌ Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-148"><a href="#cb32-148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"This example requires FAISS. Install with: pip install faiss-cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
Vector Database with FAISS: Complete Example
======================================================================

📊 Step 1: Generating synthetic embeddings...
  ✓ Created 100,000 database vectors
  ✓ Created 100 query vectors
  ✓ Dimension: 768
  ✓ Memory footprint: 292.97 MB

🏗️  Step 2: Building IVF-PQ index...
  • Training index with nlist=256, m=64, nbits=8...
  ✓ Created 100,000 database vectors
  ✓ Created 100 query vectors
  ✓ Dimension: 768
  ✓ Memory footprint: 292.97 MB

🏗️  Step 2: Building IVF-PQ index...
  • Training index with nlist=256, m=64, nbits=8...
  ✓ Training completed in 74.89 seconds
  • Adding 100,000 vectors...
  ✓ Training completed in 74.89 seconds
  • Adding 100,000 vectors...
  ✓ Vectors added in 2.02 seconds
  ✓ Index contains 100,000 vectors

🔍 Step 3: Performing search...
  • Search parameters: nprobe=16, k=10
  ✓ Searched 100 queries in 30.00 ms
  ✓ Throughput: 3334 QPS
  ✓ Average latency: 0.30 ms per query

📋 Step 4: Sample results...

First query results:
  Top-10 neighbor IDs: [37887 91949 41194 83788 94566 41790  6916 51013 37990 63991]
  Top-10 scores: [1.347  1.3475 1.3595 1.3597 1.3658 1.3721 1.3754 1.3778 1.3783 1.3784]

⚙️  Step 5: Tuning nprobe parameter...
  ✓ Vectors added in 2.02 seconds
  ✓ Index contains 100,000 vectors

🔍 Step 3: Performing search...
  • Search parameters: nprobe=16, k=10
  ✓ Searched 100 queries in 30.00 ms
  ✓ Throughput: 3334 QPS
  ✓ Average latency: 0.30 ms per query

📋 Step 4: Sample results...

First query results:
  Top-10 neighbor IDs: [37887 91949 41194 83788 94566 41790  6916 51013 37990 63991]
  Top-10 scores: [1.347  1.3475 1.3595 1.3597 1.3658 1.3721 1.3754 1.3778 1.3783 1.3784]

⚙️  Step 5: Tuning nprobe parameter...

======================================================================
✅ FAISS example completed successfully!
======================================================================</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-13-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="notes-on-production-usage" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="notes-on-production-usage"><span class="header-section-number">13.3</span> Notes on Production Usage</h2>
<p><strong>Metadata Filtering:</strong> FAISS doesn’t natively support metadata filters. Common approaches: - Use an external database (PostgreSQL, Redis) for metadata - Filter results after retrieval (post-filtering) - Use wrapper libraries like LanceDB or Qdrant that support filters</p>
<p><strong>Hybrid Search:</strong> Combine FAISS with traditional search engines:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pseudo-code</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>vector_results <span class="op">=</span> faiss_index.search(query_embedding, k<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>keyword_results <span class="op">=</span> elasticsearch.search(query_text, size<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>final_results <span class="op">=</span> reciprocal_rank_fusion([vector_results, keyword_results])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Persistence:</strong></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save index</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>faiss.write_index(index, <span class="st">"vector_index.faiss"</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load index</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> faiss.read_index(<span class="st">"vector_index.faiss"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Cross-Encoder Re-ranking:</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> CrossEncoder</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get candidates from FAISS</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>candidates <span class="op">=</span> index.search(query_vec, k<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-rank with cross-encoder</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>reranker <span class="op">=</span> CrossEncoder(<span class="st">'cross-encoder/ms-marco-MiniLM-L-6-v2'</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> reranker.predict([(query_text, doc_text) <span class="cf">for</span> doc_text <span class="kw">in</span> candidate_docs])</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>final_results <span class="op">=</span> sort_by_scores(candidates, scores)[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="frequently-asked-questions-faq" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> Frequently Asked Questions (FAQ)</h1>
<section id="q1-do-i-always-need-a-vector-database" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="q1-do-i-always-need-a-vector-database"><span class="header-section-number">14.1</span> Q1: Do I always need a vector database?</h2>
<p><strong>A:</strong> Not for small corpora. For datasets with &lt; 10,000 documents: - Exact search or in-memory libraries may suffice - Search libraries with vector support (Elasticsearch/OpenSearch) work well - Scale, latency requirements, filter complexity, and operational needs drive the decision</p>
<p><strong>When you DO need a dedicated vector DB:</strong> - Millions+ of vectors - Strict latency requirements (&lt; 50ms P95) - Complex metadata filtering - High QPS (hundreds to thousands) - Need for advanced features (hybrid search, re-ranking, analytics)</p>
<hr>
</section>
<section id="q2-cosine-vs-inner-product-vs-l2-which-should-i-use" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="q2-cosine-vs-inner-product-vs-l2-which-should-i-use"><span class="header-section-number">14.2</span> Q2: Cosine vs Inner Product vs L2 — which should I use?</h2>
<p><strong>A:</strong> It depends on your embedding model and task:</p>
<p><strong>Cosine Similarity:</strong> - Best for: Text embeddings, semantic search - Requires: Normalized vectors - Properties: Magnitude-invariant, captures direction</p>
<p><strong>Inner Product (MIPS):</strong> - Best for: When you normalize vectors (equivalent to cosine) - Use case: Asymmetric similarity tasks - Note: Faster than cosine if vectors are pre-normalized</p>
<p><strong>L2 Distance:</strong> - Best for: When magnitude carries meaning - Use case: Some vision tasks, specific embedding schemes - Properties: Sensitive to scale</p>
<p><strong>Rule of thumb:</strong> For most NLP/text applications, use cosine (with normalization).</p>
<hr>
</section>
<section id="q3-can-i-mix-different-embedding-models-in-one-index" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="q3-can-i-mix-different-embedding-models-in-one-index"><span class="header-section-number">14.3</span> Q3: Can I mix different embedding models in one index?</h2>
<p><strong>A:</strong> Generally <strong>avoid mixing incompatible embedding spaces</strong>:</p>
<p><strong>Problem:</strong> - Different models create incompatible vector spaces - Distances become meaningless across model boundaries</p>
<p><strong>Solutions:</strong> 1. <strong>Separate indexes per model:</strong> Shard by <code>model_version</code>, merge results in application 2. <strong>Re-embed everything:</strong> When upgrading models, re-process entire corpus 3. <strong>Dual-write pattern:</strong> Maintain both versions during transition</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Separate indexes</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>results_v1 <span class="op">=</span> index_v1.search(query_v1, k<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>results_v2 <span class="op">=</span> index_v2.search(query_v2, k<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>final <span class="op">=</span> merge_and_dedupe(results_v1, results_v2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="q4-how-big-should-text-chunks-be" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="q4-how-big-should-text-chunks-be"><span class="header-section-number">14.4</span> Q4: How big should text chunks be?</h2>
<p><strong>A:</strong> Common practice: <strong>256–1024 tokens with 20–30% overlap</strong></p>
<p><strong>Considerations:</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>Chunk Size</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Small (128-256)</td>
<td>Precise matches, less noise</td>
<td>May lack context</td>
</tr>
<tr class="even">
<td>Medium (512)</td>
<td>Good balance</td>
<td>Standard choice</td>
</tr>
<tr class="odd">
<td>Large (1024+)</td>
<td>Rich context</td>
<td>May be too general</td>
</tr>
</tbody>
</table>
<p><strong>Best practice:</strong> - Experiment with your specific use case - Measure retrieval quality (recall, NDCG) - Consider downstream task (Q&amp;A needs precision, summarization needs context) - Use overlap to prevent information loss at boundaries</p>
<hr>
</section>
<section id="q5-what-about-gpu-vs-cpu-for-vector-search" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="q5-what-about-gpu-vs-cpu-for-vector-search"><span class="header-section-number">14.5</span> Q5: What about GPU vs CPU for vector search?</h2>
<p><strong>A:</strong> Choose based on workload characteristics:</p>
<p><strong>GPU Advantages:</strong> - Massive parallelism for batch queries - Excellent for IVF-PQ indexes - Great for re-ranking large candidate sets - Cost-effective at very high QPS</p>
<p><strong>CPU Advantages:</strong> - HNSW performs well on CPU - Lower latency for single queries - Easier deployment and scaling - More flexible for diverse workloads</p>
<p><strong>Hybrid Approach:</strong> - Use CPU for HNSW-based serving - GPU for batch re-embedding and index building - GPU for re-ranking top-k candidates</p>
<hr>
</section>
<section id="q6-how-do-i-handle-real-time-updates" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="q6-how-do-i-handle-real-time-updates"><span class="header-section-number">14.6</span> Q6: How do I handle real-time updates?</h2>
<p><strong>A:</strong> Multiple strategies depending on freshness requirements:</p>
<p><strong>Streaming Upserts:</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Real-time updates with eventual consistency</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>index.upsert(doc_id, embedding, metadata)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Visible within seconds to minutes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Batch Updates:</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Periodic batch updates (hourly/daily)</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>new_embeddings <span class="op">=</span> process_new_documents()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>index.add_batch(new_embeddings)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Blue-Green Deployment:</strong></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For major rebuilds</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Build new_index offline</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Warm up new_index (cache, test queries)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Switch traffic: old_index → new_index</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> Deprecate old_index</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="q7-whats-the-best-open-source-vector-database" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="q7-whats-the-best-open-source-vector-database"><span class="header-section-number">14.7</span> Q7: What’s the best open-source vector database?</h2>
<p><strong>A:</strong> Depends on your requirements:</p>
<table class="table">
<colgroup>
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Database</th>
<th>Best For</th>
<th>Key Strengths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>FAISS</strong></td>
<td>Research, prototyping</td>
<td>Performance, flexibility, GPU support</td>
</tr>
<tr class="even">
<td><strong>Milvus</strong></td>
<td>Production scale</td>
<td>Distributed, cloud-native, rich features</td>
</tr>
<tr class="odd">
<td><strong>Qdrant</strong></td>
<td>Moderate scale</td>
<td>Easy API, good filtering, Rust performance</td>
</tr>
<tr class="even">
<td><strong>Weaviate</strong></td>
<td>Hybrid search</td>
<td>GraphQL, modules, good docs</td>
</tr>
<tr class="odd">
<td><strong>Chroma</strong></td>
<td>RAG applications</td>
<td>Simple API, embeddings built-in</td>
</tr>
<tr class="even">
<td><strong>Pinecone</strong></td>
<td>Managed service</td>
<td>Serverless, zero-ops, good DX</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="q8-how-do-i-debug-poor-recall" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="q8-how-do-i-debug-poor-recall"><span class="header-section-number">14.8</span> Q8: How do I debug poor recall?</h2>
<p><strong>Checklist:</strong></p>
<ol type="1">
<li>✅ <strong>Check embeddings:</strong> Are they normalized consistently?</li>
<li>✅ <strong>Verify metric:</strong> Cosine vs L2 vs inner product</li>
<li>✅ <strong>Tune parameters:</strong> Increase efSearch/nprobe</li>
<li>✅ <strong>Test with exact search:</strong> Compare ANN vs brute force</li>
<li>✅ <strong>Inspect queries:</strong> Are they in-distribution?</li>
<li>✅ <strong>Check filters:</strong> Post-filtering too aggressive?</li>
<li>✅ <strong>Evaluate embedding model:</strong> Is it appropriate for your domain?</li>
<li>✅ <strong>Look for drift:</strong> Has data distribution changed?</li>
</ol>
<p><strong>Diagnostic code:</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare ANN vs exact search</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>exact_neighbors <span class="op">=</span> exact_index.search(query, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>ann_neighbors <span class="op">=</span> ann_index.search(query, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(exact_neighbors) <span class="op">&amp;</span> <span class="bu">set</span>(ann_neighbors)) <span class="op">/</span> <span class="dv">10</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall@10: </span><span class="sc">{</span>recall<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="tldr---key-takeaways" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> TL;DR - Key Takeaways</h1>
<section id="core-concepts" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="core-concepts"><span class="header-section-number">15.1</span> 🎯 Core Concepts</h2>
<p>✅ <strong>Vector databases</strong> enable semantic search by storing and querying high-dimensional embeddings</p>
<p>✅ <strong>ANN (Approximate Nearest Neighbor)</strong> indexes trade a small accuracy loss for massive speed gains</p>
<p>✅ <strong>Distance metrics matter:</strong> Cosine for text (normalized), L2 when magnitude matters, MIPS for specialized tasks</p>
<hr>
</section>
<section id="index-selection" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="index-selection"><span class="header-section-number">15.2</span> 🏗️ Index Selection</h2>
<table class="table">
<colgroup>
<col style="width: 18%">
<col style="width: 39%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Scale</th>
<th>Recommendation</th>
<th>Key Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>≤ 50M</td>
<td><strong>HNSW</strong></td>
<td>M=16-32, efConstruction=200-400, efSearch=64-200</td>
</tr>
<tr class="even">
<td>50M-1B</td>
<td><strong>IVF-PQ</strong></td>
<td>nlist=√N, nprobe=8-64, PQ 8-16 bits</td>
</tr>
<tr class="odd">
<td>Web-scale</td>
<td><strong>DiskANN</strong> or sharded IVF-PQ</td>
<td>+ tiered storage, caching</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="production-essentials" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="production-essentials"><span class="header-section-number">15.3</span> ⚙️ Production Essentials</h2>
<ol type="1">
<li><strong>Hybrid search:</strong> Combine vector + keyword (BM25) with RRF fusion</li>
<li><strong>Metadata filters:</strong> Pre-partition by common filters or post-filter with larger k</li>
<li><strong>Re-ranking:</strong> Use cross-encoders on top-100 for precision</li>
<li><strong>Monitoring:</strong> Track recall@k, latency (P50/P95), QPS, and business metrics</li>
<li><strong>Versioning:</strong> Dual-write during model transitions, blue-green deployment</li>
</ol>
<hr>
</section>
<section id="evaluation-framework" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="evaluation-framework"><span class="header-section-number">15.4</span> 🔍 Evaluation Framework</h2>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential metrics</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Recall<span class="op">@</span>k (≥ <span class="fl">0.95</span> target)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> NDCG<span class="op">@</span>k (<span class="cf">for</span> ranking quality)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> P95 latency (<span class="op">&lt;</span> <span class="dv">50</span><span class="er">ms</span> typical)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Cost per million vectors</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> User engagement (CTR, task success)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="getting-started" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="getting-started"><span class="header-section-number">15.5</span> 🚀 Getting Started</h2>
<p><strong>Step 1:</strong> Choose your metric (cosine for most text tasks)</p>
<p><strong>Step 2:</strong> Start simple: - Small scale: HNSW with default params - Large scale: IVF-PQ on GPU</p>
<p><strong>Step 3:</strong> Measure baseline (recall, latency, cost)</p>
<p><strong>Step 4:</strong> Iterate: - Tune efSearch/nprobe for recall/latency balance - Add hybrid search if keywords matter - Implement re-ranking for precision</p>
<p><strong>Step 5:</strong> Operationalize: - Monitor key metrics - Set up alerts for recall degradation - Plan for model version migrations - Implement caching and sharding strategies</p>
<hr>
</section>
<section id="common-pitfalls-to-avoid" class="level2" data-number="15.6">
<h2 data-number="15.6" class="anchored" data-anchor-id="common-pitfalls-to-avoid"><span class="header-section-number">15.6</span> 💡 Common Pitfalls to Avoid</h2>
<p>❌ Mixing normalized and unnormalized vectors</p>
<p>❌ Ignoring metadata filters in initial design</p>
<p>❌ Not measuring recall against exact search baseline</p>
<p>❌ Underestimating memory requirements</p>
<p>❌ Forgetting about the cold start problem</p>
<p>❌ No plan for embedding model versioning</p>
<p>❌ Optimizing for accuracy without considering latency</p>
<hr>
</section>
<section id="further-reading" class="level2" data-number="15.7">
<h2 data-number="15.7" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">15.7</span> 📚 Further Reading</h2>
<ul>
<li><strong>FAISS documentation:</strong> Facebook’s high-performance library</li>
<li><strong>HNSW paper:</strong> Malkov &amp; Yashunin (2018)</li>
<li><strong>Vector DB benchmarks:</strong> ann-benchmarks.com</li>
<li><strong>Embedding models:</strong> MTEB leaderboard</li>
<li><strong>Production patterns:</strong> MLOps best practices for vector search</li>
</ul>
<hr>
</section>
<section id="final-thoughts" class="level2" data-number="15.8">
<h2 data-number="15.8" class="anchored" data-anchor-id="final-thoughts"><span class="header-section-number">15.8</span> 🎓 Final Thoughts</h2>
<p>Vector databases are a critical infrastructure component for modern AI applications. Success requires:</p>
<ol type="1">
<li><strong>Understanding the fundamentals:</strong> embeddings, distances, indexes</li>
<li><strong>Making informed trade-offs:</strong> recall vs latency vs cost</li>
<li><strong>Measuring what matters:</strong> establish metrics before optimization</li>
<li><strong>Planning for operations:</strong> versioning, monitoring, scaling</li>
<li><strong>Iterating based on data:</strong> A/B test, measure, improve</li>
</ol>
<p><strong>Start simple, measure everything, scale gradually.</strong></p>
<hr>
</section>
<section id="questions-or-feedback" class="level2" data-number="15.9">
<h2 data-number="15.9" class="anchored" data-anchor-id="questions-or-feedback"><span class="header-section-number">15.9</span> 📬 Questions or Feedback?</h2>
<p>This post covered the essentials of vector databases from theory to production. Key resources:</p>
<ul>
<li>📖 <strong>Code examples:</strong> All examples available in this notebook</li>
<li>🔬 <strong>Benchmarks:</strong> Test different indexes with your data</li>
<li>📊 <strong>Monitoring:</strong> Set up dashboards for key metrics</li>
<li>🚀 <strong>Deployment:</strong> Start with managed solutions, self-host when needed</li>
</ul>
<p><strong>Good luck building your vector search system!</strong> 🎉</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary: Quick reference for vector database operations</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" VECTOR DATABASES DEMYSTIFIED - QUICK REFERENCE "</span>.center(<span class="dv">70</span>))</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a reference table</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>reference_data <span class="op">=</span> {</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Task'</span>: [</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Text embedding'</span>,</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Image embedding'</span>,</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Small scale (&lt;10M)'</span>,</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Large scale (&gt;100M)'</span>,</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Hybrid search'</span>,</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Metadata filtering'</span>,</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Real-time updates'</span>,</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Production monitoring'</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Recommended Approach'</span>: [</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sentence-transformers, OpenAI, Cohere'</span>,</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'CLIP, vision transformers'</span>,</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'HNSW (M=16-32, ef=100-200)'</span>,</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'IVF-PQ (nlist=√N, nprobe=16-64)'</span>,</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'RRF fusion + cross-encoder re-rank'</span>,</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Pre-partition or segment indexes'</span>,</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Streaming upsert + dual-write pattern'</span>,</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall@k, P95 latency, QPS, drift'</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Key Metric'</span>: [</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Embedding quality'</span>,</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Multimodal alignment'</span>,</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall@10 &gt; 0.95'</span>,</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">'QPS &gt; 1000'</span>,</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">'NDCG@10 &gt; 0.85'</span>,</span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Filter selectivity'</span>,</span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Freshness lag &lt; 5min'</span>,</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">'All of the above'</span></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(reference_data)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Key Reminders:"</span>)</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  1. Always normalize vectors for cosine similarity"</span>)</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  2. Measure recall against exact search baseline"</span>)</span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  3. Tune efSearch/nprobe to meet latency SLO"</span>)</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  4. Use hybrid search for production systems"</span>)</span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  5. Monitor, version, and iterate"</span>)</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ You're ready to build production vector search systems!"</span>)</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
            VECTOR DATABASES DEMYSTIFIED - QUICK REFERENCE            
======================================================================


                 Task                  Recommended Approach           Key Metric
       Text embedding sentence-transformers, OpenAI, Cohere    Embedding quality
      Image embedding             CLIP, vision transformers Multimodal alignment
   Small scale (&lt;10M)            HNSW (M=16-32, ef=100-200)     Recall@10 &gt; 0.95
  Large scale (&gt;100M)       IVF-PQ (nlist=√N, nprobe=16-64)           QPS &gt; 1000
        Hybrid search    RRF fusion + cross-encoder re-rank       NDCG@10 &gt; 0.85
   Metadata filtering      Pre-partition or segment indexes   Filter selectivity
    Real-time updates Streaming upsert + dual-write pattern Freshness lag &lt; 5min
Production monitoring     Recall@k, P95 latency, QPS, drift     All of the above

======================================================================

💡 Key Reminders:
  1. Always normalize vectors for cosine similarity
  2. Measure recall against exact search baseline
  3. Tune efSearch/nprobe to meet latency SLO
  4. Use hybrid search for production systems
  5. Monitor, version, and iterate

======================================================================

✅ You're ready to build production vector search systems!
======================================================================
</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">© 2025 Sanjeeva Reddy Dodlapati<br>
AI Research • Computational Biology • Data Science</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/sanjeeva-reddy-dodlapati-ab4ab490/">
      <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:sdodlapa@gmail.com">
      <i class="bi bi-envelope" role="img" aria-label="Email">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>