<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sanjeeva Reddy Dodlapati">
<meta name="dcterms.date" content="2025-10-04">
<meta name="keywords" content="vector database, embeddings, FAISS, HNSW, IVF-PQ, semantic search, ANN, approximate nearest neighbors, hybrid search, production ML, recall tuning">
<meta name="description" content="A practical guide to vector databases: embeddings, HNSW vs IVF-PQ, hybrid search, tuning recall-latency, and FAISS code to ship production semantic search. Includes working examples and benchmarks.">

<title>Sanjeev’s AI Research Blog - Vector Databases, Demystified</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Sanjeeva Reddy Dodlapati">
<meta name="keywords" content="AI, machine learning, computational biology, bioinformatics, genomics, data science">
<script src="custom.js" defer=""></script>
<style>
  body { opacity: 0; transition: opacity 0.3s ease; }
  body.loaded { opacity: 1; }
</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Sanjeev’s AI Research Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target=""><i class="bi bi-file-person" role="img">
</i> 
 <span class="menu-text">CV/Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./projects.html" rel="" target=""><i class="bi bi-collection" role="img">
</i> 
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./ml-blog.html" rel="" target=""><i class="bi bi-cpu" role="img">
</i> 
 <span class="menu-text">Machine Learning</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./genomics-blog.html" rel="" target=""><i class="bi bi-dna" role="img">
</i> 
 <span class="menu-text">AI for Genomics</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./chemistry-blog.html" rel="" target=""><i class="bi bi-flask" role="img">
</i> 
 <span class="menu-text">AI for Chemistry</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/SanjeevaRDodlapati" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/dodlapati_reddy" rel="" target=""><i class="bi bi-twitter" role="img" aria-label="Twitter">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
    <a href="./#" title="Toggle Dark Mode" class="quarto-navigation-tool px-1" aria-label="Toggle Dark Mode"><i class="bi bi-moon"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#vector-databases-demystified-from-embeddings-to-production-grade-search" id="toc-vector-databases-demystified-from-embeddings-to-production-grade-search" class="nav-link active" data-scroll-target="#vector-databases-demystified-from-embeddings-to-production-grade-search"><span class="header-section-number">1</span> Vector Databases, Demystified: From Embeddings to Production-Grade Search</a></li>
  <li><a href="#what-is-a-vector-database" id="toc-what-is-a-vector-database" class="nav-link" data-scroll-target="#what-is-a-vector-database"><span class="header-section-number">2</span> What is a Vector Database?</a>
  <ul class="collapse">
  <li><a href="#why-vectors" id="toc-why-vectors" class="nav-link" data-scroll-target="#why-vectors"><span class="header-section-number">2.1</span> Why vectors?</a></li>
  </ul></li>
  <li><a href="#end-to-end-flow" id="toc-end-to-end-flow" class="nav-link" data-scroll-target="#end-to-end-flow"><span class="header-section-number">3</span> End-to-End Flow</a>
  <ul class="collapse">
  <li><a href="#vectorization" id="toc-vectorization" class="nav-link" data-scroll-target="#vectorization"><span class="header-section-number">3.1</span> Vectorization</a></li>
  <li><a href="#storage-metadata" id="toc-storage-metadata" class="nav-link" data-scroll-target="#storage-metadata"><span class="header-section-number">3.2</span> Storage &amp; Metadata</a></li>
  <li><a href="#indexing" id="toc-indexing" class="nav-link" data-scroll-target="#indexing"><span class="header-section-number">3.3</span> Indexing</a></li>
  <li><a href="#query" id="toc-query" class="nav-link" data-scroll-target="#query"><span class="header-section-number">3.4</span> Query</a></li>
  <li><a href="#ranking-fusion" id="toc-ranking-fusion" class="nav-link" data-scroll-target="#ranking-fusion"><span class="header-section-number">3.5</span> Ranking &amp; Fusion</a></li>
  </ul></li>
  <li><a href="#distance-metrics-their-gotchas" id="toc-distance-metrics-their-gotchas" class="nav-link" data-scroll-target="#distance-metrics-their-gotchas"><span class="header-section-number">4</span> Distance Metrics &amp; Their Gotchas</a>
  <ul class="collapse">
  <li><a href="#cosine-similarity" id="toc-cosine-similarity" class="nav-link" data-scroll-target="#cosine-similarity"><span class="header-section-number">4.1</span> Cosine Similarity</a></li>
  <li><a href="#euclidean-distance-l2" id="toc-euclidean-distance-l2" class="nav-link" data-scroll-target="#euclidean-distance-l2"><span class="header-section-number">4.2</span> Euclidean Distance (L2)</a></li>
  <li><a href="#inner-product-mips---maximum-inner-product-search" id="toc-inner-product-mips---maximum-inner-product-search" class="nav-link" data-scroll-target="#inner-product-mips---maximum-inner-product-search"><span class="header-section-number">4.3</span> Inner Product (MIPS - Maximum Inner Product Search)</a></li>
  <li><a href="#pro-tip-cosine-dot-product-when-normalized" id="toc-pro-tip-cosine-dot-product-when-normalized" class="nav-link" data-scroll-target="#pro-tip-cosine-dot-product-when-normalized"><span class="header-section-number">4.4</span> ⚡ Pro Tip: Cosine ≡ Dot Product (when normalized)</a></li>
  </ul></li>
  <li><a href="#index-families-and-when-to-use-them" id="toc-index-families-and-when-to-use-them" class="nav-link" data-scroll-target="#index-families-and-when-to-use-them"><span class="header-section-number">5</span> Index Families (and When to Use Them)</a>
  <ul class="collapse">
  <li><a href="#graph-based-hnsw---hierarchical-navigable-small-world" id="toc-graph-based-hnsw---hierarchical-navigable-small-world" class="nav-link" data-scroll-target="#graph-based-hnsw---hierarchical-navigable-small-world"><span class="header-section-number">5.1</span> Graph-based (HNSW - Hierarchical Navigable Small World)</a></li>
  <li><a href="#inverted-file-ivf-pqopq" id="toc-inverted-file-ivf-pqopq" class="nav-link" data-scroll-target="#inverted-file-ivf-pqopq"><span class="header-section-number">5.2</span> Inverted File (IVF) + [PQ/OPQ]</a></li>
  <li><a href="#tree-like-annoy" id="toc-tree-like-annoy" class="nav-link" data-scroll-target="#tree-like-annoy"><span class="header-section-number">5.3</span> Tree-like (Annoy)</a></li>
  <li><a href="#specialized-indexes" id="toc-specialized-indexes" class="nav-link" data-scroll-target="#specialized-indexes"><span class="header-section-number">5.4</span> Specialized Indexes</a></li>
  <li><a href="#rule-of-thumb" id="toc-rule-of-thumb" class="nav-link" data-scroll-target="#rule-of-thumb"><span class="header-section-number">5.5</span> Rule of Thumb</a></li>
  </ul></li>
  <li><a href="#deep-dive-how-hnsw-works" id="toc-deep-dive-how-hnsw-works" class="nav-link" data-scroll-target="#deep-dive-how-hnsw-works"><span class="header-section-number">6</span> Deep Dive: How HNSW Works</a>
  <ul class="collapse">
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture"><span class="header-section-number">6.1</span> Architecture</a></li>
  <li><a href="#key-parameters" id="toc-key-parameters" class="nav-link" data-scroll-target="#key-parameters"><span class="header-section-number">6.2</span> Key Parameters</a></li>
  <li><a href="#insertion-process" id="toc-insertion-process" class="nav-link" data-scroll-target="#insertion-process"><span class="header-section-number">6.3</span> Insertion Process</a></li>
  <li><a href="#search-process" id="toc-search-process" class="nav-link" data-scroll-target="#search-process"><span class="header-section-number">6.4</span> Search Process</a></li>
  <li><a href="#intuition" id="toc-intuition" class="nav-link" data-scroll-target="#intuition"><span class="header-section-number">6.5</span> Intuition</a></li>
  <li><a href="#trade-offs" id="toc-trade-offs" class="nav-link" data-scroll-target="#trade-offs"><span class="header-section-number">6.6</span> Trade-offs</a></li>
  </ul></li>
  <li><a href="#beyond-rag-what-else-uses-vector-databases" id="toc-beyond-rag-what-else-uses-vector-databases" class="nav-link" data-scroll-target="#beyond-rag-what-else-uses-vector-databases"><span class="header-section-number">7</span> Beyond RAG: What Else Uses Vector Databases?</a>
  <ul class="collapse">
  <li><a href="#recommendation-personalization" id="toc-recommendation-personalization" class="nav-link" data-scroll-target="#recommendation-personalization"><span class="header-section-number">7.1</span> Recommendation &amp; Personalization</a></li>
  <li><a href="#near-duplicate-plagiarism-detection" id="toc-near-duplicate-plagiarism-detection" class="nav-link" data-scroll-target="#near-duplicate-plagiarism-detection"><span class="header-section-number">7.2</span> Near-Duplicate &amp; Plagiarism Detection</a></li>
  <li><a href="#anomalyoutlier-detection" id="toc-anomalyoutlier-detection" class="nav-link" data-scroll-target="#anomalyoutlier-detection"><span class="header-section-number">7.3</span> Anomaly/Outlier Detection</a></li>
  <li><a href="#semantic-monitoring-alerting" id="toc-semantic-monitoring-alerting" class="nav-link" data-scroll-target="#semantic-monitoring-alerting"><span class="header-section-number">7.4</span> Semantic Monitoring &amp; Alerting</a></li>
  <li><a href="#multimodal-search" id="toc-multimodal-search" class="nav-link" data-scroll-target="#multimodal-search"><span class="header-section-number">7.5</span> Multimodal Search</a></li>
  <li><a href="#code-intelligence" id="toc-code-intelligence" class="nav-link" data-scroll-target="#code-intelligence"><span class="header-section-number">7.6</span> Code Intelligence</a></li>
  <li><a href="#biochem-applications" id="toc-biochem-applications" class="nav-link" data-scroll-target="#biochem-applications"><span class="header-section-number">7.7</span> Bio/Chem Applications</a></li>
  <li><a href="#roboticsslam-mapping" id="toc-roboticsslam-mapping" class="nav-link" data-scroll-target="#roboticsslam-mapping"><span class="header-section-number">7.8</span> Robotics/SLAM &amp; Mapping</a></li>
  <li><a href="#legal-e-discovery" id="toc-legal-e-discovery" class="nav-link" data-scroll-target="#legal-e-discovery"><span class="header-section-number">7.9</span> Legal &amp; E-discovery</a></li>
  <li><a href="#content-moderation" id="toc-content-moderation" class="nav-link" data-scroll-target="#content-moderation"><span class="header-section-number">7.10</span> Content Moderation</a></li>
  </ul></li>
  <li><a href="#hybrid-search-filters-real-world-must-haves" id="toc-hybrid-search-filters-real-world-must-haves" class="nav-link" data-scroll-target="#hybrid-search-filters-real-world-must-haves"><span class="header-section-number">8</span> Hybrid Search &amp; Filters (Real-World Must-Haves)</a>
  <ul class="collapse">
  <li><a href="#metadata-filters-at-retrieval-time" id="toc-metadata-filters-at-retrieval-time" class="nav-link" data-scroll-target="#metadata-filters-at-retrieval-time"><span class="header-section-number">8.1</span> Metadata Filters at Retrieval Time</a></li>
  <li><a href="#hybrid-fusion-strategies" id="toc-hybrid-fusion-strategies" class="nav-link" data-scroll-target="#hybrid-fusion-strategies"><span class="header-section-number">8.2</span> Hybrid Fusion Strategies</a>
  <ul class="collapse">
  <li><a href="#a.-rank-fusion-rrf---reciprocal-rank-fusion" id="toc-a.-rank-fusion-rrf---reciprocal-rank-fusion" class="nav-link" data-scroll-target="#a.-rank-fusion-rrf---reciprocal-rank-fusion"><span class="header-section-number">8.2.1</span> A. Rank Fusion (RRF - Reciprocal Rank Fusion)</a></li>
  <li><a href="#b.-score-fusion" id="toc-b.-score-fusion" class="nav-link" data-scroll-target="#b.-score-fusion"><span class="header-section-number">8.2.2</span> B. Score Fusion</a></li>
  <li><a href="#c.-neural-re-rankers" id="toc-c.-neural-re-rankers" class="nav-link" data-scroll-target="#c.-neural-re-rankers"><span class="header-section-number">8.2.3</span> C. Neural Re-rankers</a></li>
  </ul></li>
  <li><a href="#implementation-considerations" id="toc-implementation-considerations" class="nav-link" data-scroll-target="#implementation-considerations"><span class="header-section-number">8.3</span> Implementation Considerations</a></li>
  <li><a href="#when-to-use-what" id="toc-when-to-use-what" class="nav-link" data-scroll-target="#when-to-use-what"><span class="header-section-number">8.4</span> When to Use What</a></li>
  </ul></li>
  <li><a href="#data-model-concerns" id="toc-data-model-concerns" class="nav-link" data-scroll-target="#data-model-concerns"><span class="header-section-number">9</span> Data &amp; Model Concerns</a>
  <ul class="collapse">
  <li><a href="#embedding-model-selection" id="toc-embedding-model-selection" class="nav-link" data-scroll-target="#embedding-model-selection"><span class="header-section-number">9.1</span> Embedding Model Selection</a></li>
  <li><a href="#normalization-consistency" id="toc-normalization-consistency" class="nav-link" data-scroll-target="#normalization-consistency"><span class="header-section-number">9.2</span> Normalization Consistency</a></li>
  <li><a href="#drift-versioning" id="toc-drift-versioning" class="nav-link" data-scroll-target="#drift-versioning"><span class="header-section-number">9.3</span> Drift &amp; Versioning</a></li>
  <li><a href="#chunking-for-text" id="toc-chunking-for-text" class="nav-link" data-scroll-target="#chunking-for-text"><span class="header-section-number">9.4</span> Chunking for Text</a></li>
  <li><a href="#deduplication-collapse" id="toc-deduplication-collapse" class="nav-link" data-scroll-target="#deduplication-collapse"><span class="header-section-number">9.5</span> Deduplication &amp; Collapse</a></li>
  </ul></li>
  <li><a href="#evaluation-quantify-good" id="toc-evaluation-quantify-good" class="nav-link" data-scroll-target="#evaluation-quantify-good"><span class="header-section-number">10</span> Evaluation: Quantify “Good”</a>
  <ul class="collapse">
  <li><a href="#retrieval-quality-metrics" id="toc-retrieval-quality-metrics" class="nav-link" data-scroll-target="#retrieval-quality-metrics"><span class="header-section-number">10.1</span> Retrieval Quality Metrics</a>
  <ul class="collapse">
  <li><a href="#recallk" id="toc-recallk" class="nav-link" data-scroll-target="#recallk"><span class="header-section-number">10.1.1</span> Recall@k</a></li>
  <li><a href="#ndcg-normalized-discounted-cumulative-gain" id="toc-ndcg-normalized-discounted-cumulative-gain" class="nav-link" data-scroll-target="#ndcg-normalized-discounted-cumulative-gain"><span class="header-section-number">10.1.2</span> NDCG (Normalized Discounted Cumulative Gain)</a></li>
  <li><a href="#mrr-mean-reciprocal-rank" id="toc-mrr-mean-reciprocal-rank" class="nav-link" data-scroll-target="#mrr-mean-reciprocal-rank"><span class="header-section-number">10.1.3</span> MRR (Mean Reciprocal Rank)</a></li>
  </ul></li>
  <li><a href="#performance-metrics" id="toc-performance-metrics" class="nav-link" data-scroll-target="#performance-metrics"><span class="header-section-number">10.2</span> Performance Metrics</a></li>
  <li><a href="#cost-metrics" id="toc-cost-metrics" class="nav-link" data-scroll-target="#cost-metrics"><span class="header-section-number">10.3</span> Cost Metrics</a></li>
  <li><a href="#business-metrics-ab-testing" id="toc-business-metrics-ab-testing" class="nav-link" data-scroll-target="#business-metrics-ab-testing"><span class="header-section-number">10.4</span> Business Metrics (A/B Testing)</a></li>
  <li><a href="#evaluation-best-practices" id="toc-evaluation-best-practices" class="nav-link" data-scroll-target="#evaluation-best-practices"><span class="header-section-number">10.5</span> Evaluation Best Practices</a></li>
  </ul></li>
  <li><a href="#operating-at-scale" id="toc-operating-at-scale" class="nav-link" data-scroll-target="#operating-at-scale"><span class="header-section-number">11</span> Operating at Scale</a>
  <ul class="collapse">
  <li><a href="#index-build-updates" id="toc-index-build-updates" class="nav-link" data-scroll-target="#index-build-updates"><span class="header-section-number">11.1</span> Index Build &amp; Updates</a></li>
  <li><a href="#sharding-strategies" id="toc-sharding-strategies" class="nav-link" data-scroll-target="#sharding-strategies"><span class="header-section-number">11.2</span> Sharding Strategies</a></li>
  <li><a href="#caching-strategies" id="toc-caching-strategies" class="nav-link" data-scroll-target="#caching-strategies"><span class="header-section-number">11.3</span> Caching Strategies</a></li>
  <li><a href="#hardware-considerations" id="toc-hardware-considerations" class="nav-link" data-scroll-target="#hardware-considerations"><span class="header-section-number">11.4</span> Hardware Considerations</a></li>
  <li><a href="#security-compliance" id="toc-security-compliance" class="nav-link" data-scroll-target="#security-compliance"><span class="header-section-number">11.5</span> Security &amp; Compliance</a></li>
  </ul></li>
  <li><a href="#challenges-how-to-handle-them" id="toc-challenges-how-to-handle-them" class="nav-link" data-scroll-target="#challenges-how-to-handle-them"><span class="header-section-number">12</span> Challenges &amp; How to Handle Them</a>
  <ul class="collapse">
  <li><a href="#troubleshooting-guide" id="toc-troubleshooting-guide" class="nav-link" data-scroll-target="#troubleshooting-guide"><span class="header-section-number">12.1</span> Troubleshooting Guide</a></li>
  </ul></li>
  <li><a href="#practical-sizing-tuning-cheatsheet" id="toc-practical-sizing-tuning-cheatsheet" class="nav-link" data-scroll-target="#practical-sizing-tuning-cheatsheet"><span class="header-section-number">13</span> Practical Sizing &amp; Tuning Cheatsheet</a>
  <ul class="collapse">
  <li><a href="#production-defaults-start-here" id="toc-production-defaults-start-here" class="nav-link" data-scroll-target="#production-defaults-start-here"><span class="header-section-number">13.1</span> 🎯 Production Defaults: Start Here</a></li>
  <li><a href="#initial-setup-checklist" id="toc-initial-setup-checklist" class="nav-link" data-scroll-target="#initial-setup-checklist"><span class="header-section-number">13.2</span> Initial Setup Checklist</a></li>
  <li><a href="#tuning-for-latency-slo" id="toc-tuning-for-latency-slo" class="nav-link" data-scroll-target="#tuning-for-latency-slo"><span class="header-section-number">13.3</span> Tuning for Latency SLO</a></li>
  <li><a href="#hybrid-search-setup" id="toc-hybrid-search-setup" class="nav-link" data-scroll-target="#hybrid-search-setup"><span class="header-section-number">13.4</span> Hybrid Search Setup</a></li>
  <li><a href="#filter-configuration" id="toc-filter-configuration" class="nav-link" data-scroll-target="#filter-configuration"><span class="header-section-number">13.5</span> Filter Configuration</a></li>
  <li><a href="#operational-monitoring" id="toc-operational-monitoring" class="nav-link" data-scroll-target="#operational-monitoring"><span class="header-section-number">13.6</span> Operational Monitoring</a></li>
  <li><a href="#blue-green-deployment" id="toc-blue-green-deployment" class="nav-link" data-scroll-target="#blue-green-deployment"><span class="header-section-number">13.7</span> Blue-Green Deployment</a></li>
  </ul></li>
  <li><a href="#minimal-example-with-faiss" id="toc-minimal-example-with-faiss" class="nav-link" data-scroll-target="#minimal-example-with-faiss"><span class="header-section-number">14</span> Minimal Example with FAISS</a>
  <ul class="collapse">
  <li><a href="#installation" id="toc-installation" class="nav-link" data-scroll-target="#installation"><span class="header-section-number">14.1</span> Installation</a></li>
  <li><a href="#complete-ivf-pq-implementation" id="toc-complete-ivf-pq-implementation" class="nav-link" data-scroll-target="#complete-ivf-pq-implementation"><span class="header-section-number">14.2</span> Complete IVF-PQ Implementation</a></li>
  <li><a href="#notes-on-production-usage" id="toc-notes-on-production-usage" class="nav-link" data-scroll-target="#notes-on-production-usage"><span class="header-section-number">14.3</span> Notes on Production Usage</a></li>
  </ul></li>
  <li><a href="#frequently-asked-questions-faq" id="toc-frequently-asked-questions-faq" class="nav-link" data-scroll-target="#frequently-asked-questions-faq"><span class="header-section-number">15</span> Frequently Asked Questions (FAQ)</a>
  <ul class="collapse">
  <li><a href="#q1-do-i-always-need-a-vector-database" id="toc-q1-do-i-always-need-a-vector-database" class="nav-link" data-scroll-target="#q1-do-i-always-need-a-vector-database"><span class="header-section-number">15.1</span> Q1: Do I always need a vector database?</a></li>
  <li><a href="#q2-cosine-vs-inner-product-vs-l2-which-should-i-use" id="toc-q2-cosine-vs-inner-product-vs-l2-which-should-i-use" class="nav-link" data-scroll-target="#q2-cosine-vs-inner-product-vs-l2-which-should-i-use"><span class="header-section-number">15.2</span> Q2: Cosine vs Inner Product vs L2 — which should I use?</a></li>
  <li><a href="#q3-can-i-mix-different-embedding-models-in-one-index" id="toc-q3-can-i-mix-different-embedding-models-in-one-index" class="nav-link" data-scroll-target="#q3-can-i-mix-different-embedding-models-in-one-index"><span class="header-section-number">15.3</span> Q3: Can I mix different embedding models in one index?</a></li>
  <li><a href="#q4-how-big-should-text-chunks-be" id="toc-q4-how-big-should-text-chunks-be" class="nav-link" data-scroll-target="#q4-how-big-should-text-chunks-be"><span class="header-section-number">15.4</span> Q4: How big should text chunks be?</a></li>
  <li><a href="#q5-what-about-gpu-vs-cpu-for-vector-search" id="toc-q5-what-about-gpu-vs-cpu-for-vector-search" class="nav-link" data-scroll-target="#q5-what-about-gpu-vs-cpu-for-vector-search"><span class="header-section-number">15.5</span> Q5: What about GPU vs CPU for vector search?</a></li>
  <li><a href="#q6-how-do-i-handle-real-time-updates" id="toc-q6-how-do-i-handle-real-time-updates" class="nav-link" data-scroll-target="#q6-how-do-i-handle-real-time-updates"><span class="header-section-number">15.6</span> Q6: How do I handle real-time updates?</a></li>
  <li><a href="#q7-whats-the-best-open-source-vector-database" id="toc-q7-whats-the-best-open-source-vector-database" class="nav-link" data-scroll-target="#q7-whats-the-best-open-source-vector-database"><span class="header-section-number">15.7</span> Q7: What’s the best open-source vector database?</a></li>
  <li><a href="#q8-how-do-i-debug-poor-recall" id="toc-q8-how-do-i-debug-poor-recall" class="nav-link" data-scroll-target="#q8-how-do-i-debug-poor-recall"><span class="header-section-number">15.8</span> Q8: How do I debug poor recall?</a></li>
  </ul></li>
  <li><a href="#tldr---key-takeaways" id="toc-tldr---key-takeaways" class="nav-link" data-scroll-target="#tldr---key-takeaways"><span class="header-section-number">16</span> TL;DR - Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#core-concepts" id="toc-core-concepts" class="nav-link" data-scroll-target="#core-concepts"><span class="header-section-number">16.1</span> 🎯 Core Concepts</a></li>
  <li><a href="#index-selection" id="toc-index-selection" class="nav-link" data-scroll-target="#index-selection"><span class="header-section-number">16.2</span> 🏗️ Index Selection</a></li>
  <li><a href="#production-essentials" id="toc-production-essentials" class="nav-link" data-scroll-target="#production-essentials"><span class="header-section-number">16.3</span> ⚙️ Production Essentials</a></li>
  <li><a href="#evaluation-framework" id="toc-evaluation-framework" class="nav-link" data-scroll-target="#evaluation-framework"><span class="header-section-number">16.4</span> 🔍 Evaluation Framework</a></li>
  <li><a href="#getting-started" id="toc-getting-started" class="nav-link" data-scroll-target="#getting-started"><span class="header-section-number">16.5</span> 🚀 Getting Started</a></li>
  <li><a href="#common-pitfalls-to-avoid" id="toc-common-pitfalls-to-avoid" class="nav-link" data-scroll-target="#common-pitfalls-to-avoid"><span class="header-section-number">16.6</span> 💡 Common Pitfalls to Avoid</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">16.7</span> 📚 Further Reading</a></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts"><span class="header-section-number">16.8</span> 🎓 Final Thoughts</a></li>
  <li><a href="#questions-or-feedback" id="toc-questions-or-feedback" class="nav-link" data-scroll-target="#questions-or-feedback"><span class="header-section-number">16.9</span> 📬 Questions or Feedback?</a></li>
  </ul></li>
  <li><a href="#appendix-package-installation-verification" id="toc-appendix-package-installation-verification" class="nav-link" data-scroll-target="#appendix-package-installation-verification"><span class="header-section-number">17</span> Appendix: Package Installation &amp; Verification</a>
  <ul class="collapse">
  <li><a href="#license-attribution" id="toc-license-attribution" class="nav-link" data-scroll-target="#license-attribution"><span class="header-section-number">17.1</span> License &amp; Attribution</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Vector Databases, Demystified</h1>
<p class="subtitle lead">From Embeddings to Production-Grade Search</p>
  <div class="quarto-categories">
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">AI</div>
    <div class="quarto-category">Vector Search</div>
    <div class="quarto-category">Database Systems</div>
    <div class="quarto-category">Production ML</div>
    <div class="quarto-category">FAISS</div>
    <div class="quarto-category">HNSW</div>
    <div class="quarto-category">Semantic Search</div>
  </div>
  </div>

<div>
  <div class="description">
    A practical guide to vector databases: embeddings, HNSW vs IVF-PQ, hybrid search, tuning recall-latency, and FAISS code to ship production semantic search. Includes working examples and benchmarks.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sanjeeva Reddy Dodlapati </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 4, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">October 4, 2025</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="vector-databases-demystified-from-embeddings-to-production-grade-search" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Vector Databases, Demystified: From Embeddings to Production-Grade Search</h1>
<p><strong>Last updated:</strong> October 2025 • <strong>Reading time:</strong> ~15 minutes • <a href="#minimal-example-with-faiss">Jump to code →</a></p>
<hr>
<p><strong>Why your keyword search keeps missing obvious matches:</strong> A user searches for “laptop repair near me”—your system returns “computer fixing services nearby.” Perfect match semantically, but zero keyword overlap. That’s the vector database advantage.</p>
<p>Vector databases power the “semantic” layer of modern AI systems. Instead of matching exact strings, they compare <strong>embeddings</strong>—high-dimensional vectors that capture meaning from text, images, audio, code, molecules, and more.</p>
<p><strong>What you’ll learn:</strong> - 🎯 When you need a vector DB (and when you don’t) - 🏗️ Core indexes: HNSW vs IVF-PQ trade-offs - ⚡ Production tuning: recall-latency optimization - 🔍 Hybrid search: combining semantic + keyword - 📊 Evaluation metrics that actually matter - 💻 Working FAISS code with real benchmarks</p>
<p>This guide takes you from theory to production-ready implementation with practical code examples and tuning heuristics.</p>
</section>
<section id="what-is-a-vector-database" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> What is a Vector Database?</h1>
<p>A <strong>vector database</strong> stores and indexes embeddings—dense vectors (e.g., 384–4096 dimensions) produced by models such as: - Sentence transformers - CLIP (vision-language models) - Whisper (audio) - Multimodal foundation models - Domain-specific encoders</p>
<p>The core task is <strong>nearest neighbor search</strong>: given a query vector, return the most similar stored vectors under a metric (cosine, L2, inner product).</p>
<section id="why-vectors" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="why-vectors"><span class="header-section-number">2.1</span> Why vectors?</h2>
<p>Because similar concepts map to nearby points in embedding space. “puppy on grass” and “dog on lawn” sit close even if they share few keywords.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Creating simple embeddings to demonstrate vector similarity</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated embeddings for demonstration (in reality, these come from models)</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> {</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"puppy on grass"</span>: np.array([<span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>]),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"dog on lawn"</span>: np.array([<span class="fl">0.75</span>, <span class="fl">0.65</span>, <span class="fl">0.35</span>, <span class="fl">0.52</span>]),</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"cat in house"</span>: np.array([<span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.9</span>, <span class="fl">0.1</span>]),</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"car on road"</span>: np.array([<span class="fl">0.1</span>, <span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.95</span>])</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate similarity between "puppy on grass" and other phrases</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> embeddings[<span class="st">"puppy on grass"</span>].reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Similarity scores to 'puppy on grass':</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> phrase, vec <span class="kw">in</span> embeddings.items():</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> phrase <span class="op">!=</span> <span class="st">"puppy on grass"</span>:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        similarity <span class="op">=</span> cosine_similarity(query, vec.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>phrase<span class="sc">:20s}</span><span class="ss">: </span><span class="sc">{</span>similarity<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Similarity scores to 'puppy on grass':

dog on lawn         : 0.9972
cat in house        : 0.6027
car on road         : 0.6168</code></pre>
</div>
</div>
</section>
</section>
<section id="end-to-end-flow" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> End-to-End Flow</h1>
<p>The vector database workflow consists of five key stages:</p>
<section id="vectorization" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="vectorization"><span class="header-section-number">3.1</span> Vectorization</h2>
<p>Unstructured data → embedding model → vector <span class="math inline">\(\mathbf{x} \in \mathbb{R}^d\)</span>.</p>
<p>Often you also normalize: <span class="math inline">\(\mathbf{x} \leftarrow \frac{\mathbf{x}}{\|\mathbf{x}\|}\)</span> if using cosine similarity.</p>
</section>
<section id="storage-metadata" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="storage-metadata"><span class="header-section-number">3.2</span> Storage &amp; Metadata</h2>
<p>Store <code>{id, vector, metadata, payload}</code>. Metadata enables filters (e.g., <code>country=US</code>, <code>doc_type=blog</code>) and post-retrieval ranking.</p>
</section>
<section id="indexing" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="indexing"><span class="header-section-number">3.3</span> Indexing</h2>
<p>Build an <strong>ANN (Approximate Nearest Neighbor)</strong> index so queries don’t scan every vector. Trade speed for a controlled loss vs exact search.</p>
</section>
<section id="query" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="query"><span class="header-section-number">3.4</span> Query</h2>
<p>Query text/image → query vector <span class="math inline">\(\mathbf{q}\)</span>. Perform ANN search with optional metadata filters and hybrid fusion (keyword + vector).</p>
</section>
<section id="ranking-fusion" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="ranking-fusion"><span class="header-section-number">3.5</span> Ranking &amp; Fusion</h2>
<p>Compute similarity scores, apply re-ranking (e.g., LTR, cross-encoder), dedupe near-duplicates, then return references/snippets.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: End-to-end vector database flow simulation</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> normalize</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Vectorization (simulated embeddings)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> [</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Machine learning with neural networks"</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Deep learning for computer vision"</span>,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Natural language processing with transformers"</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Database systems and indexing"</span>,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Vector search and embeddings"</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate embedding generation (in practice, use real models like sentence-transformers)</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>doc_embeddings <span class="op">=</span> np.random.randn(<span class="bu">len</span>(documents), dim).astype(<span class="st">'float32'</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Normalize for cosine similarity</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>doc_embeddings <span class="op">=</span> normalize(doc_embeddings, norm<span class="op">=</span><span class="st">'l2'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Store with metadata</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>metadata <span class="op">=</span> [</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"doc_id"</span>: i, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"year"</span>: <span class="dv">2024</span>} </span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(documents))</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Stored </span><span class="sc">{</span><span class="bu">len</span>(documents)<span class="sc">}</span><span class="ss"> documents with </span><span class="sc">{</span>dim<span class="sc">}</span><span class="ss">-dimensional embeddings"</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Embedding shape: </span><span class="sc">{</span>doc_embeddings<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sample embedding (first 10 dims): </span><span class="sc">{</span>doc_embeddings[<span class="dv">0</span>][:<span class="dv">10</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stored 5 documents with 128-dimensional embeddings
Embedding shape: (5, 128)
Sample embedding (first 10 dims): [ 0.04642567 -0.01292295  0.06053658  0.14235085 -0.02188528 -0.02188374
  0.14760202  0.07172872 -0.04387969  0.05071068]</code></pre>
</div>
</div>
</section>
</section>
<section id="distance-metrics-their-gotchas" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Distance Metrics &amp; Their Gotchas</h1>
<p>Choosing the right distance metric is crucial for vector search performance.</p>
<section id="cosine-similarity" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="cosine-similarity"><span class="header-section-number">4.1</span> Cosine Similarity</h2>
<p><span class="math display">\[s(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\| \|\mathbf{y}\|}\]</span></p>
<p><strong>Properties:</strong> - Invariant to magnitude - Great for text embeddings - Normalize vectors for fast dot-product equivalence</p>
</section>
<section id="euclidean-distance-l2" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="euclidean-distance-l2"><span class="header-section-number">4.2</span> Euclidean Distance (L2)</h2>
<p><span class="math display">\[d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{\sum_{i=1}^{d} (x_i - y_i)^2}\]</span></p>
<p><strong>Properties:</strong> - Sensitive to magnitude - Useful when norms carry signal (e.g., certain vision or embedding regimes)</p>
</section>
<section id="inner-product-mips---maximum-inner-product-search" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="inner-product-mips---maximum-inner-product-search"><span class="header-section-number">4.3</span> Inner Product (MIPS - Maximum Inner Product Search)</h2>
<p><span class="math display">\[\text{MIPS}(\mathbf{x}, \mathbf{y}) = \mathbf{x} \cdot \mathbf{y}\]</span></p>
<p><strong>Properties:</strong> - Equivalent to cosine if vectors are normalized - If not normalized, may use transform tricks (e.g., add a norm-dependent extra dimension) to reuse L2 engines</p>
<hr>
</section>
<section id="pro-tip-cosine-dot-product-when-normalized" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="pro-tip-cosine-dot-product-when-normalized"><span class="header-section-number">4.4</span> ⚡ Pro Tip: Cosine ≡ Dot Product (when normalized)</h2>
<p><strong>Quick proof:</strong> If vectors are L2-normalized (<span class="math inline">\(\|\mathbf{x}\| = \|\mathbf{y}\| = 1\)</span>):</p>
<p><span class="math display">\[\text{cosine}(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\| \|\mathbf{y}\|} = \frac{\mathbf{x} \cdot \mathbf{y}}{1 \times 1} = \mathbf{x} \cdot \mathbf{y}\]</span></p>
<p><strong>Practical benefit:</strong> Use faster inner-product indexes (FAISS <code>IndexFlatIP</code>) instead of cosine distance computation. Just normalize once at ingestion and query time.</p>
<p><strong>⚠️ Common pitfall:</strong> Mixing normalized query vectors with unnormalized index vectors (or vice versa) breaks retrieval completely. Always verify:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># At index time</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>vectors_normalized <span class="op">=</span> vectors <span class="op">/</span> np.linalg.norm(vectors, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>index.add(vectors_normalized)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># At query time</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>query_normalized <span class="op">=</span> query <span class="op">/</span> np.linalg.norm(query)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> index.search(query_normalized, k<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>💡 Tip:</strong> Decide metric before index build; many indexes are metric-specific and cannot be changed after training.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing different distance metrics</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity, euclidean_distances</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create two sample vectors</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>]])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> np.array([[<span class="fl">2.0</span>, <span class="fl">4.0</span>, <span class="fl">6.0</span>]])  <span class="co"># Same direction, different magnitude</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>vec3 <span class="op">=</span> np.array([[<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="op">-</span><span class="fl">3.0</span>]]) <span class="co"># Different direction</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize vectors for cosine</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>vec1_norm <span class="op">=</span> vec1 <span class="op">/</span> np.linalg.norm(vec1)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>vec2_norm <span class="op">=</span> vec2 <span class="op">/</span> np.linalg.norm(vec2)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>vec3_norm <span class="op">=</span> vec3 <span class="op">/</span> np.linalg.norm(vec3)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Distance Metrics Comparison:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Cosine similarity</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>cos_sim_12 <span class="op">=</span> cosine_similarity(vec1, vec2)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>cos_sim_13 <span class="op">=</span> cosine_similarity(vec1, vec3)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cosine Similarity:"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec2 (same direction): </span><span class="sc">{</span>cos_sim_12<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec3 (diff direction): </span><span class="sc">{</span>cos_sim_13<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Euclidean distance</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>l2_dist_12 <span class="op">=</span> euclidean_distances(vec1, vec2)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>l2_dist_13 <span class="op">=</span> euclidean_distances(vec1, vec3)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Euclidean Distance (L2):"</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec2: </span><span class="sc">{</span>l2_dist_12<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec3: </span><span class="sc">{</span>l2_dist_13<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Inner product</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>inner_12 <span class="op">=</span> np.dot(vec1, vec2.T)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>inner_13 <span class="op">=</span> np.dot(vec1, vec3.T)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Inner Product:"</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec2: </span><span class="sc">{</span>inner_12<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  vec1 vs vec3: </span><span class="sc">{</span>inner_13<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Notice: Cosine sees vec1 and vec2 as identical (both 1.0)"</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   because they point in the same direction, despite magnitude difference!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Distance Metrics Comparison:

============================================================
Cosine Similarity:
  vec1 vs vec2 (same direction): 1.0000
  vec1 vs vec3 (diff direction): -0.2857

Euclidean Distance (L2):
  vec1 vs vec2: 3.7417
  vec1 vs vec3: 6.0000

Inner Product:
  vec1 vs vec2: 28.0000
  vec1 vs vec3: -4.0000

============================================================

💡 Notice: Cosine sees vec1 and vec2 as identical (both 1.0)
   because they point in the same direction, despite magnitude difference!</code></pre>
</div>
</div>
</section>
</section>
<section id="index-families-and-when-to-use-them" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Index Families (and When to Use Them)</h1>
<p>Different indexing strategies optimize for various trade-offs between speed, accuracy, and memory.</p>
<section id="graph-based-hnsw---hierarchical-navigable-small-world" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="graph-based-hnsw---hierarchical-navigable-small-world"><span class="header-section-number">5.1</span> Graph-based (HNSW - Hierarchical Navigable Small World)</h2>
<p><strong>Pros:</strong> - Excellent recall/speed trade-off - Dynamic insert capabilities - Strong default for ≤ few hundred million points in RAM</p>
<p><strong>Cons:</strong> - Memory-heavy (stores graph structure) - Deletions are lazy or complicated - Filtering can be non-trivial</p>
</section>
<section id="inverted-file-ivf-pqopq" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="inverted-file-ivf-pqopq"><span class="header-section-number">5.2</span> Inverted File (IVF) + [PQ/OPQ]</h2>
<p>Cluster vectors into <code>nlist</code> centroids (coarse quantizer), search only a few lists (<code>nprobe</code>). Optional <strong>Product Quantization (PQ)</strong> to compress.</p>
<p><strong>Pros:</strong> - Scales well to billions of vectors - Great for GPU acceleration (e.g., FAISS) - Good recall/latency trade-off - Compresses memory usage</p>
<p><strong>Cons:</strong> - Build time can be significant - Requires tuning <code>nlist</code>, <code>nprobe</code>, and PQ bits - Recall loss under heavy compression</p>
</section>
<section id="tree-like-annoy" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="tree-like-annoy"><span class="header-section-number">5.3</span> Tree-like (Annoy)</h2>
<p><strong>Pros:</strong> - Simple implementation - Memory-mapped for efficient disk usage - Good for read-mostly workloads</p>
<p><strong>Cons:</strong> - Slower writes - Less optimal for dynamic updates</p>
</section>
<section id="specialized-indexes" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="specialized-indexes"><span class="header-section-number">5.4</span> Specialized Indexes</h2>
<ul>
<li><strong>ScaNN:</strong> Anisotropic quantization for better compression</li>
<li><strong>DiskANN:</strong> I/O-aware for large-scale cloud disk storage</li>
<li><strong>Flat/Brute-force:</strong> Exact search, costly but useful for small collections or re-ranking</li>
</ul>
</section>
<section id="rule-of-thumb" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="rule-of-thumb"><span class="header-section-number">5.5</span> Rule of Thumb</h2>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th>Scale</th>
<th>Recommendation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Up to tens of millions in RAM</td>
<td><strong>HNSW</strong></td>
</tr>
<tr class="even">
<td>Hundreds of millions / GPU</td>
<td><strong>IVF-PQ</strong> with FAISS or vendor GPU index</td>
</tr>
<tr class="odd">
<td>On disk at web scale</td>
<td><strong>DiskANN</strong>-style or sharded IVF-PQ + caching</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing index performance characteristics</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated performance characteristics</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>index_types <span class="op">=</span> [<span class="st">'HNSW'</span>, <span class="st">'IVF-PQ'</span>, <span class="st">'Annoy'</span>, <span class="st">'Flat'</span>]</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> [<span class="fl">0.95</span>, <span class="fl">0.92</span>, <span class="fl">0.88</span>, <span class="fl">1.0</span>]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>speed <span class="op">=</span> [<span class="fl">0.85</span>, <span class="fl">0.90</span>, <span class="fl">0.75</span>, <span class="fl">0.20</span>]  <span class="co"># queries per second (normalized)</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>memory <span class="op">=</span> [<span class="fl">0.70</span>, <span class="fl">0.85</span>, <span class="fl">0.80</span>, <span class="fl">0.30</span>]  <span class="co"># memory efficiency (lower is better for memory)</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>))</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Recall comparison</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].bar(index_types, recall, color<span class="op">=</span>[<span class="st">'#2ecc71'</span>, <span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>, <span class="st">'#95a5a6'</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Recall@10'</span>)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Recall Performance'</span>)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axhline(y<span class="op">=</span><span class="fl">0.95</span>, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Target: 0.95'</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Speed comparison</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].bar(index_types, speed, color<span class="op">=</span>[<span class="st">'#2ecc71'</span>, <span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>, <span class="st">'#95a5a6'</span>])</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Relative Speed'</span>)</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Query Speed (Higher is Better)'</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Memory efficiency</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].bar(index_types, memory, color<span class="op">=</span>[<span class="st">'#2ecc71'</span>, <span class="st">'#3498db'</span>, <span class="st">'#e74c3c'</span>, <span class="st">'#95a5a6'</span>])</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Memory Usage'</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Memory Footprint (Lower is Better)'</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'index_comparison.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Index Performance Summary:"</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(index_types):</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>idx<span class="sc">:10s}</span><span class="ss"> | Recall: </span><span class="sc">{</span>recall[i]<span class="sc">:.2f}</span><span class="ss"> | Speed: </span><span class="sc">{</span>speed[i]<span class="sc">:.2f}</span><span class="ss"> | Memory: </span><span class="sc">{</span>memory[i]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
📊 Index Performance Summary:
============================================================
HNSW       | Recall: 0.95 | Speed: 0.85 | Memory: 0.70
IVF-PQ     | Recall: 0.92 | Speed: 0.90 | Memory: 0.85
Annoy      | Recall: 0.88 | Speed: 0.75 | Memory: 0.80
Flat       | Recall: 1.00 | Speed: 0.20 | Memory: 0.30
============================================================</code></pre>
</div>
</div>
</section>
</section>
<section id="deep-dive-how-hnsw-works" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Deep Dive: How HNSW Works</h1>
<p><strong>Hierarchical Navigable Small World (HNSW)</strong> builds a multi-layer graph for efficient approximate nearest neighbor search.</p>
<section id="architecture" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="architecture"><span class="header-section-number">6.1</span> Architecture</h2>
<ul>
<li>Each vector is a node</li>
<li>At the <strong>top layers</strong>, only a few nodes exist (sparse)</li>
<li>At the <strong>bottom layer</strong>, all nodes exist (dense)</li>
<li>Multiple layers create a hierarchical structure for fast navigation</li>
</ul>
</section>
<section id="key-parameters" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="key-parameters"><span class="header-section-number">6.2</span> Key Parameters</h2>
<table class="table">
<colgroup>
<col style="width: 34%">
<col style="width: 40%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>M</strong></td>
<td>Max neighbors per node</td>
<td>Controls graph degree, recall, memory</td>
</tr>
<tr class="even">
<td><strong>efConstruction</strong></td>
<td>Candidate list during build</td>
<td>Higher = better recall, slower build, more memory</td>
</tr>
<tr class="odd">
<td><strong>efSearch</strong></td>
<td>Candidate list during query</td>
<td>Higher = better recall, higher latency</td>
</tr>
</tbody>
</table>
</section>
<section id="insertion-process" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="insertion-process"><span class="header-section-number">6.3</span> Insertion Process</h2>
<ol type="1">
<li><strong>Assign layer</strong>: Random maximum layer to the new node (geometric distribution)</li>
<li><strong>Start descent</strong>: Begin from entry point in the top layer</li>
<li><strong>Greedy descent</strong>: At each layer, move to neighbors closer to the new vector</li>
<li><strong>Link nodes</strong>: At target layer, link the node to its nearest neighbors using diversification heuristic (prune overly redundant edges)</li>
<li><strong>Repeat down</strong>: Continue process down through all layers</li>
</ol>
</section>
<section id="search-process" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="search-process"><span class="header-section-number">6.4</span> Search Process</h2>
<ol type="1">
<li><strong>Start at top</strong>: Begin at the top entry point</li>
<li><strong>Greedy search per layer</strong>: Move to the neighbor closest to query <span class="math inline">\(\mathbf{q}\)</span> until no improvement</li>
<li><strong>Descend</strong>: Move down one layer</li>
<li><strong>Refine at bottom</strong>: At the bottom layer, perform best-first search with bounded candidate set size <code>efSearch</code></li>
<li><strong>Return top-k</strong>: Return the k nearest neighbors</li>
</ol>
</section>
<section id="intuition" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="intuition"><span class="header-section-number">6.5</span> Intuition</h2>
<ul>
<li><strong>Upper layers</strong> “teleport” you near the right region (coarse navigation)</li>
<li><strong>Bottom layer</strong> refines the search (fine-grained precision)</li>
</ul>
</section>
<section id="trade-offs" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="trade-offs"><span class="header-section-number">6.6</span> Trade-offs</h2>
<ul>
<li>Larger <code>M</code>, <code>efConstruction</code>, <code>efSearch</code> → <strong>higher recall &amp; memory/latency</strong></li>
<li><strong>Complexity</strong>: Near log-like behavior empirically</li>
<li><strong>Memory</strong>: <span class="math inline">\(\approx O(N \times M)\)</span> edges + vectors</li>
</ul>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing HNSW layer structure</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.patches <span class="im">as</span> mpatches</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define layers</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>layers <span class="op">=</span> [</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Layer 2 (Top)"</span>, <span class="st">"y"</span>: <span class="dv">7</span>, <span class="st">"nodes"</span>: <span class="dv">3</span>, <span class="st">"color"</span>: <span class="st">"#e74c3c"</span>},</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Layer 1"</span>, <span class="st">"y"</span>: <span class="fl">4.5</span>, <span class="st">"nodes"</span>: <span class="dv">10</span>, <span class="st">"color"</span>: <span class="st">"#3498db"</span>},</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"name"</span>: <span class="st">"Layer 0 (Bottom)"</span>, <span class="st">"y"</span>: <span class="dv">2</span>, <span class="st">"nodes"</span>: <span class="dv">25</span>, <span class="st">"color"</span>: <span class="st">"#2ecc71"</span>}</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw layers</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> layers:</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw nodes</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    x_positions <span class="op">=</span> np.linspace(<span class="dv">1</span>, <span class="dv">11</span>, layer[<span class="st">"nodes"</span>])</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    y_pos <span class="op">=</span> layer[<span class="st">"y"</span>]</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x <span class="kw">in</span> x_positions:</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        circle <span class="op">=</span> plt.Circle((x, y_pos), <span class="fl">0.15</span>, color<span class="op">=</span>layer[<span class="st">"color"</span>], alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>        ax.add_patch(circle)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Draw some connections (simplified)</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> layer[<span class="st">"nodes"</span>] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x_positions) <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> <span class="bu">len</span>(x_positions):</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>                ax.plot([x_positions[i], x_positions[i<span class="op">+</span><span class="dv">1</span>]], [y_pos, y_pos], </span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>                       <span class="st">'k-'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Label layer</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    ax.text(<span class="op">-</span><span class="fl">0.5</span>, y_pos, layer[<span class="st">"name"</span>], fontsize<span class="op">=</span><span class="dv">11</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, </span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>            va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw vertical connections between layers</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>ax.annotate(<span class="st">''</span>, xy<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">4.5</span>), xytext<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">7</span>),</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>            arrowprops<span class="op">=</span><span class="bu">dict</span>(arrowstyle<span class="op">=</span><span class="st">'-&gt;'</span>, color<span class="op">=</span><span class="st">'gray'</span>, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>ax.annotate(<span class="st">''</span>, xy<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">2</span>), xytext<span class="op">=</span>(<span class="dv">6</span>, <span class="fl">4.5</span>),</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>            arrowprops<span class="op">=</span><span class="bu">dict</span>(arrowstyle<span class="op">=</span><span class="st">'-&gt;'</span>, color<span class="op">=</span><span class="st">'gray'</span>, lw<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Add annotations</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="dv">6</span>, <span class="fl">8.5</span>, <span class="st">'Sparse Layer</span><span class="ch">\n</span><span class="st">(Fast Navigation)'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>        bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">'round'</span>, facecolor<span class="op">=</span><span class="st">'wheat'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>ax.text(<span class="dv">6</span>, <span class="fl">0.5</span>, <span class="st">'Dense Layer</span><span class="ch">\n</span><span class="st">(Precise Search)'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>        bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">'round'</span>, facecolor<span class="op">=</span><span class="st">'lightblue'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>))</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Add search path illustration</span></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>search_path_x <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="fl">5.5</span>, <span class="dv">6</span>, <span class="fl">6.2</span>]</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>search_path_y <span class="op">=</span> [<span class="dv">7</span>, <span class="fl">4.5</span>, <span class="fl">4.5</span>, <span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>ax.plot(search_path_x, search_path_y, <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, </span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>        marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'Example Search Path'</span>)</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="op">-</span><span class="dv">1</span>, <span class="dv">12</span>)</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="dv">0</span>, <span class="dv">9</span>)</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>ax.axis(<span class="st">'off'</span>)</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">'upper right'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'HNSW Hierarchical Structure'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'hnsw_structure.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🏗️ HNSW Structure Explained:"</span>)</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Top layers: Few nodes, long-distance hops (coarse search)"</span>)</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Bottom layer: All nodes, short hops (fine-grained search)"</span>)</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Search starts at top and descends layer by layer"</span>)</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"• Each layer acts as a 'highway' to quickly reach the target region"</span>)</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
🏗️ HNSW Structure Explained:
============================================================
• Top layers: Few nodes, long-distance hops (coarse search)
• Bottom layer: All nodes, short hops (fine-grained search)
• Search starts at top and descends layer by layer
• Each layer acts as a 'highway' to quickly reach the target region
============================================================</code></pre>
</div>
</div>
</section>
</section>
<section id="beyond-rag-what-else-uses-vector-databases" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Beyond RAG: What Else Uses Vector Databases?</h1>
<p>Vector databases power far more than just Retrieval-Augmented Generation. Here are key application areas:</p>
<section id="recommendation-personalization" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="recommendation-personalization"><span class="header-section-number">7.1</span> Recommendation &amp; Personalization</h2>
<p>Retrieve similar users/items, complementing traditional collaborative filtering approaches.</p>
</section>
<section id="near-duplicate-plagiarism-detection" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="near-duplicate-plagiarism-detection"><span class="header-section-number">7.2</span> Near-Duplicate &amp; Plagiarism Detection</h2>
<p>Deduplicate large corpora (news articles, code repositories, scientific preprints).</p>
</section>
<section id="anomalyoutlier-detection" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="anomalyoutlier-detection"><span class="header-section-number">7.3</span> Anomaly/Outlier Detection</h2>
<p>“Distance from manifold” heuristics for fraud detection, abuse prevention, or quality control.</p>
</section>
<section id="semantic-monitoring-alerting" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="semantic-monitoring-alerting"><span class="header-section-number">7.4</span> Semantic Monitoring &amp; Alerting</h2>
<p>Watch streams (logs, support tickets) for semantically similar incidents to trigger alerts.</p>
</section>
<section id="multimodal-search" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="multimodal-search"><span class="header-section-number">7.5</span> Multimodal Search</h2>
<ul>
<li>Image ↔︎ Text (CLIP-based)</li>
<li>Audio snippet search</li>
<li>Video moment retrieval</li>
</ul>
</section>
<section id="code-intelligence" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="code-intelligence"><span class="header-section-number">7.6</span> Code Intelligence</h2>
<ul>
<li>Similar function lookup</li>
<li>Cross-repository code search</li>
<li>Code clone detection</li>
</ul>
</section>
<section id="biochem-applications" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="biochem-applications"><span class="header-section-number">7.7</span> Bio/Chem Applications</h2>
<ul>
<li>Protein/compound embeddings for virtual screening</li>
<li>Scaffold hopping in drug discovery</li>
<li>Molecular similarity search</li>
</ul>
</section>
<section id="roboticsslam-mapping" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="roboticsslam-mapping"><span class="header-section-number">7.8</span> Robotics/SLAM &amp; Mapping</h2>
<p>Place recognition via local feature embeddings for autonomous navigation.</p>
</section>
<section id="legal-e-discovery" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="legal-e-discovery"><span class="header-section-number">7.9</span> Legal &amp; E-discovery</h2>
<p>Concept clustering and semantic curation of legal documents.</p>
</section>
<section id="content-moderation" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="content-moderation"><span class="header-section-number">7.10</span> Content Moderation</h2>
<p>Identify similar policy-violating content across platforms.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Anomaly detection using vector distances</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> normalize</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate normal data (cluster)</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>normal_data <span class="op">=</span> np.random.randn(<span class="dv">200</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.5</span> <span class="op">+</span> np.array([<span class="dv">2</span>, <span class="dv">2</span>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate anomalies (outliers)</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>anomalies <span class="op">=</span> np.array([</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">5</span>],</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">5</span>],</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">5</span>, <span class="dv">0</span>],</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate distances from cluster center</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>center <span class="op">=</span> np.mean(normal_data, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>distances_normal <span class="op">=</span> np.linalg.norm(normal_data <span class="op">-</span> center, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>distances_anomaly <span class="op">=</span> np.linalg.norm(anomalies <span class="op">-</span> center, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Set threshold (e.g., 95th percentile of normal distances)</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> np.percentile(distances_normal, <span class="dv">95</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Scatter plot</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>ax1.scatter(normal_data[:, <span class="dv">0</span>], normal_data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, </span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'Normal'</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>ax1.scatter(anomalies[:, <span class="dv">0</span>], anomalies[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'Anomalies'</span>, marker<span class="op">=</span><span class="st">'X'</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>ax1.scatter(center[<span class="dv">0</span>], center[<span class="dv">1</span>], c<span class="op">=</span><span class="st">'green'</span>, s<span class="op">=</span><span class="dv">200</span>, marker<span class="op">=</span><span class="st">'*'</span>, </span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'Cluster Center'</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>circle <span class="op">=</span> plt.Circle(center, threshold, color<span class="op">=</span><span class="st">'orange'</span>, fill<span class="op">=</span><span class="va">False</span>, </span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>                   linewidth<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="ss">f'Threshold (</span><span class="sc">{</span>threshold<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>ax1.add_patch(circle)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Dimension 1'</span>)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Dimension 2'</span>)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Anomaly Detection via Vector Distance'</span>)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Distance distribution</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>ax2.hist(distances_normal, bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Normal Data'</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>ax2.axvline(threshold, color<span class="op">=</span><span class="st">'orange'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Threshold (95th %ile)'</span>)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>ax2.scatter(distances_anomaly, [<span class="dv">5</span>]<span class="op">*</span><span class="bu">len</span>(distances_anomaly), c<span class="op">=</span><span class="st">'red'</span>, </span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>           s<span class="op">=</span><span class="dv">100</span>, marker<span class="op">=</span><span class="st">'X'</span>, label<span class="op">=</span><span class="st">'Anomalies'</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Distance from Center'</span>)</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Distance Distribution'</span>)</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'anomaly_detection.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔍 Anomaly Detection Results:"</span>)</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cluster center: </span><span class="sc">{</span>center<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Distance threshold: </span><span class="sc">{</span>threshold<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Normal data distances (mean ± std): </span><span class="sc">{</span>distances_normal<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss"> ± </span><span class="sc">{</span>distances_normal<span class="sc">.</span>std()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Anomaly distances: </span><span class="sc">{</span>distances_anomaly<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Detected </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(distances_anomaly <span class="op">&gt;</span> threshold)<span class="sc">}</span><span class="ss"> anomalies out of </span><span class="sc">{</span><span class="bu">len</span>(distances_anomaly)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔍 Anomaly Detection Results:
============================================================
Cluster center: [2.00317112 2.01937749]
Distance threshold: 1.1167

Normal data distances (mean ± std): 0.5999 ± 0.3162
Anomaly distances: [4.22671195 3.5912122  3.61370569 4.25860038]

Detected 4 anomalies out of 4
============================================================</code></pre>
</div>
</div>
</section>
</section>
<section id="hybrid-search-filters-real-world-must-haves" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Hybrid Search &amp; Filters (Real-World Must-Haves)</h1>
<p>Pure vector scores are powerful, but structured filters and keywords are essential for production systems.</p>
<section id="metadata-filters-at-retrieval-time" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="metadata-filters-at-retrieval-time"><span class="header-section-number">8.1</span> Metadata Filters at Retrieval Time</h2>
<p>Filter results based on structured attributes:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>filters <span class="op">=</span> {</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lang"</span>: <span class="st">"en"</span>,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"published_after"</span>: <span class="st">"2024-01-01"</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"category"</span>: [<span class="st">"ML"</span>, <span class="st">"AI"</span>],</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"verified"</span>: <span class="va">True</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="hybrid-fusion-strategies" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="hybrid-fusion-strategies"><span class="header-section-number">8.2</span> Hybrid Fusion Strategies</h2>
<section id="a.-rank-fusion-rrf---reciprocal-rank-fusion" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="a.-rank-fusion-rrf---reciprocal-rank-fusion"><span class="header-section-number">8.2.1</span> A. Rank Fusion (RRF - Reciprocal Rank Fusion)</h3>
<p>Combine BM25 (keyword) and vector top-k lists:</p>
<p><span class="math display">\[\text{RRF}(d) = \sum_{r \in R} \frac{1}{k + r(d)}\]</span></p>
<p>where <span class="math inline">\(r(d)\)</span> is the rank of document <span class="math inline">\(d\)</span> in ranking <span class="math inline">\(r\)</span>, and <span class="math inline">\(k\)</span> is typically 60.</p>
</section>
<section id="b.-score-fusion" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="b.-score-fusion"><span class="header-section-number">8.2.2</span> B. Score Fusion</h3>
<p>Weighted sum after re-scaling:</p>
<p><span class="math display">\[\text{score}_{\text{final}} = \alpha \cdot \text{score}_{\text{vector}} + (1 - \alpha) \cdot \text{score}_{\text{keyword}}\]</span></p>
</section>
<section id="c.-neural-re-rankers" class="level3" data-number="8.2.3">
<h3 data-number="8.2.3" class="anchored" data-anchor-id="c.-neural-re-rankers"><span class="header-section-number">8.2.3</span> C. Neural Re-rankers</h3>
<p>Cross-encoders (e.g., MS MARCO–style) on the top 100 to boost precision@k.</p>
</section>
</section>
<section id="implementation-considerations" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="implementation-considerations"><span class="header-section-number">8.3</span> Implementation Considerations</h2>
<p><strong>Caveat:</strong> Some ANN structures don’t natively support filters. Common approaches:</p>
<ul>
<li><strong>Pre-filtering:</strong> Filter candidates before ANN search (may reduce recall)</li>
<li><strong>Post-filtering:</strong> Search larger candidate set, then filter (increases latency)</li>
<li><strong>Filter-aware IVF lists:</strong> Maintain per-segment indexes</li>
<li><strong>Partitioned indexes:</strong> Separate indexes per common filter values</li>
</ul>
</section>
<section id="when-to-use-what" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="when-to-use-what"><span class="header-section-number">8.4</span> When to Use What</h2>
<table class="table">
<thead>
<tr class="header">
<th>Use Case</th>
<th>Strategy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Few filters, high selectivity</td>
<td>Pre-filtering</td>
</tr>
<tr class="even">
<td>Many filters, low selectivity</td>
<td>Post-filtering with larger k</td>
</tr>
<tr class="odd">
<td>Common filter patterns</td>
<td>Partitioned indexes</td>
</tr>
<tr class="even">
<td>Strict latency requirements</td>
<td>Filter-aware indexes + caching</td>
</tr>
</tbody>
</table>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Reciprocal Rank Fusion (RRF)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> reciprocal_rank_fusion(rankings_list, k<span class="op">=</span><span class="dv">60</span>):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Combine multiple rankings using Reciprocal Rank Fusion.</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">        rankings_list: List of rankings, where each ranking is a list of doc IDs</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">        k: Constant (typically 60)</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Combined ranking with RRF scores</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> {}</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ranking <span class="kw">in</span> rankings_list:</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rank, doc_id <span class="kw">in</span> <span class="bu">enumerate</span>(ranking, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> doc_id <span class="kw">not</span> <span class="kw">in</span> scores:</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>                scores[doc_id] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>            scores[doc_id] <span class="op">+=</span> <span class="dv">1</span> <span class="op">/</span> (k <span class="op">+</span> rank)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sort by score descending</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    sorted_docs <span class="op">=</span> <span class="bu">sorted</span>(scores.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sorted_docs</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate two different ranking systems</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="co"># BM25 (keyword-based) ranking</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>bm25_ranking <span class="op">=</span> [<span class="st">'doc3'</span>, <span class="st">'doc1'</span>, <span class="st">'doc5'</span>, <span class="st">'doc2'</span>, <span class="st">'doc7'</span>, <span class="st">'doc4'</span>, <span class="st">'doc6'</span>]</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector similarity ranking</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>vector_ranking <span class="op">=</span> [<span class="st">'doc1'</span>, <span class="st">'doc2'</span>, <span class="st">'doc3'</span>, <span class="st">'doc4'</span>, <span class="st">'doc5'</span>, <span class="st">'doc8'</span>, <span class="st">'doc9'</span>]</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply RRF</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>fused_results <span class="op">=</span> reciprocal_rank_fusion([bm25_ranking, vector_ranking], k<span class="op">=</span><span class="dv">60</span>)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔍 Hybrid Search: Reciprocal Rank Fusion</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">BM25 Ranking (Keyword-based):"</span>)</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(bm25_ranking)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Vector Ranking (Semantic):"</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(vector_ranking)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Fused Ranking (RRF):</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a nice table</span></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame(fused_results, columns<span class="op">=</span>[<span class="st">'Document'</span>, <span class="st">'RRF Score'</span>])</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>results_df.index <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(results_df) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>results_df[<span class="st">'RRF Score'</span>] <span class="op">=</span> results_df[<span class="st">'RRF Score'</span>].<span class="bu">round</span>(<span class="dv">6</span>)</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df.to_string())</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Notice how documents appearing in both rankings get boosted!"</span>)</span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   doc1, doc2, doc3 all rank higher in the fused results."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔍 Hybrid Search: Reciprocal Rank Fusion

======================================================================

BM25 Ranking (Keyword-based):
  doc3, doc1, doc5, doc2, doc7, doc4, doc6

Vector Ranking (Semantic):
  doc1, doc2, doc3, doc4, doc5, doc8, doc9

======================================================================

Fused Ranking (RRF):

  Document  RRF Score
1     doc1   0.032522
2     doc3   0.032266
3     doc2   0.031754
4     doc5   0.031258
5     doc4   0.030777
6     doc7   0.015385
7     doc8   0.015152
8     doc6   0.014925
9     doc9   0.014925

======================================================================

💡 Notice how documents appearing in both rankings get boosted!
   doc1, doc2, doc3 all rank higher in the fused results.</code></pre>
</div>
</div>
</section>
</section>
<section id="data-model-concerns" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Data &amp; Model Concerns</h1>
<p>Getting embeddings right is crucial for vector database performance.</p>
<section id="embedding-model-selection" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="embedding-model-selection"><span class="header-section-number">9.1</span> Embedding Model Selection</h2>
<p><strong>Domain-specific encoders beat generic models:</strong> - Scientific papers: SciBERT, PubMedBERT - Code: CodeBERT, GraphCodeBERT - Legal: LegalBERT - Multilingual: mBERT, XLM-RoBERTa</p>
</section>
<section id="normalization-consistency" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="normalization-consistency"><span class="header-section-number">9.2</span> Normalization Consistency</h2>
<p><strong>Critical:</strong> Be consistent across index &amp; query - Cosine similarity requires normalized vectors - MIPS equivalence depends on normalization - Mixing normalized and unnormalized vectors breaks retrieval</p>
</section>
<section id="drift-versioning" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="drift-versioning"><span class="header-section-number">9.3</span> Drift &amp; Versioning</h2>
<p><strong>Challenge:</strong> New models produce incompatible embeddings</p>
<p><strong>Solutions:</strong> - Keep vector schema version metadata - Maintain multiple indexes during transition - Re-index incrementally (dual-write pattern) - A/B test new embeddings before full rollout</p>
</section>
<section id="chunking-for-text" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="chunking-for-text"><span class="header-section-number">9.4</span> Chunking for Text</h2>
<p><strong>Key considerations:</strong> - <strong>Window size:</strong> 256–1024 tokens common - <strong>Stride/Overlap:</strong> 20–30% overlap prevents information loss at boundaries - <strong>Chunk re-assembly:</strong> Maintain document relationships - <strong>Context preservation:</strong> Include surrounding context in metadata</p>
</section>
<section id="deduplication-collapse" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="deduplication-collapse"><span class="header-section-number">9.5</span> Deduplication &amp; Collapse</h2>
<p><strong>Prevent duplicate retrieval:</strong> - Store fingerprints (SimHash/MinHash) - Cluster near-duplicates - Post-process to remove redundant results - Maintain canonical document IDs</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Text chunking strategies</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chunk_text_with_overlap(text, chunk_size<span class="op">=</span><span class="dv">100</span>, overlap<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Split text into overlapping chunks.</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">        text: Input text string</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">        chunk_size: Size of each chunk in characters</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">        overlap: Overlap between consecutive chunks</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">        List of text chunks</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    chunks <span class="op">=</span> []</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> start <span class="op">&lt;</span> <span class="bu">len</span>(text):</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        end <span class="op">=</span> start <span class="op">+</span> chunk_size</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        chunk <span class="op">=</span> text[start:end]</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        chunks.append({</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">'chunk_id'</span>: <span class="bu">len</span>(chunks),</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text'</span>: chunk,</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">'start_pos'</span>: start,</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>            <span class="st">'end_pos'</span>: <span class="bu">min</span>(end, <span class="bu">len</span>(text)),</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>            <span class="st">'length'</span>: <span class="bu">len</span>(chunk)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>        start <span class="op">+=</span> (chunk_size <span class="op">-</span> overlap)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> chunks</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Example text</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>sample_text <span class="op">=</span> <span class="st">"""Vector databases are specialized systems designed to store and query </span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="st">high-dimensional vectors efficiently. These vectors, or embeddings, are dense numerical </span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="st">representations of data such as text, images, or audio. The key advantage of vector </span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="st">databases is their ability to perform semantic search, finding similar items based on </span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="st">meaning rather than exact keyword matches. This makes them essential for modern AI </span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="st">applications including recommendation systems, similarity search, and retrieval-augmented </span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="st">generation (RAG) systems."""</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Create chunks with different strategies</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>chunks_no_overlap <span class="op">=</span> chunk_text_with_overlap(sample_text, chunk_size<span class="op">=</span><span class="dv">100</span>, overlap<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>chunks_with_overlap <span class="op">=</span> chunk_text_with_overlap(sample_text, chunk_size<span class="op">=</span><span class="dv">100</span>, overlap<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📄 Text Chunking Strategies</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Original text length: </span><span class="sc">{</span><span class="bu">len</span>(sample_text)<span class="sc">}</span><span class="ss"> characters</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Strategy 1: No Overlap"</span>)</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  → </span><span class="sc">{</span><span class="bu">len</span>(chunks_no_overlap)<span class="sc">}</span><span class="ss"> chunks created"</span>)</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, chunk <span class="kw">in</span> <span class="bu">enumerate</span>(chunks_no_overlap[:<span class="dv">3</span>], <span class="dv">1</span>):</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Chunk </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (chars </span><span class="sc">{</span>chunk[<span class="st">'start_pos'</span>]<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>chunk[<span class="st">'end_pos'</span>]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>chunk[<span class="st">'text'</span>][:<span class="dv">50</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\n</span><span class="st">Strategy 2: With 20% Overlap"</span>)</span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  → </span><span class="sc">{</span><span class="bu">len</span>(chunks_with_overlap)<span class="sc">}</span><span class="ss"> chunks created"</span>)</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, chunk <span class="kw">in</span> <span class="bu">enumerate</span>(chunks_with_overlap[:<span class="dv">3</span>], <span class="dv">1</span>):</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Chunk </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (chars </span><span class="sc">{</span>chunk[<span class="st">'start_pos'</span>]<span class="sc">}</span><span class="ss">-</span><span class="sc">{</span>chunk[<span class="st">'end_pos'</span>]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>chunk[<span class="st">'text'</span>][:<span class="dv">50</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Benefits of overlap:"</span>)</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Prevents information loss at chunk boundaries"</span>)</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Maintains context across chunks"</span>)</span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Improves retrieval recall for cross-boundary concepts"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
📄 Text Chunking Strategies

======================================================================

Original text length: 531 characters

Strategy 1: No Overlap
  → 6 chunks created

Chunk 1 (chars 0-100):
  Vector databases are specialized systems designed ...

Chunk 2 (chars 100-200):
  iently. These vectors, or embeddings, are dense nu...

Chunk 3 (chars 200-300):
  ges, or audio. The key advantage of vector 
databa...

----------------------------------------------------------------------


Strategy 2: With 20% Overlap
  → 7 chunks created

Chunk 1 (chars 0-100):
  Vector databases are specialized systems designed ...

Chunk 2 (chars 80-180):
  sional vectors efficiently. These vectors, or embe...

Chunk 3 (chars 160-260):
  epresentations of data such as text, images, or au...

======================================================================

💡 Benefits of overlap:
  • Prevents information loss at chunk boundaries
  • Maintains context across chunks
  • Improves retrieval recall for cross-boundary concepts</code></pre>
</div>
</div>
</section>
</section>
<section id="evaluation-quantify-good" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Evaluation: Quantify “Good”</h1>
<p>Measuring vector database performance requires multiple metrics across different dimensions.</p>
<section id="retrieval-quality-metrics" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="retrieval-quality-metrics"><span class="header-section-number">10.1</span> Retrieval Quality Metrics</h2>
<section id="recallk" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="recallk"><span class="header-section-number">10.1.1</span> Recall@k</h3>
<p><span class="math display">\[\text{Recall@k} = \frac{\text{# relevant items in top-k}}{\text{total # relevant items}}\]</span></p>
<p>Measures what fraction of relevant items are retrieved in top-k results. Compare against exact search or high-ef baseline.</p>
</section>
<section id="ndcg-normalized-discounted-cumulative-gain" class="level3" data-number="10.1.2">
<h3 data-number="10.1.2" class="anchored" data-anchor-id="ndcg-normalized-discounted-cumulative-gain"><span class="header-section-number">10.1.2</span> NDCG (Normalized Discounted Cumulative Gain)</h3>
<p><span class="math display">\[\text{NDCG@k} = \frac{\text{DCG@k}}{\text{IDCG@k}}\]</span></p>
<p>where <span class="math inline">\(\text{DCG@k} = \sum_{i=1}^{k} \frac{2^{rel_i} - 1}{\log_2(i + 1)}\)</span></p>
<p>Accounts for position and relevance grades (not just binary relevant/irrelevant).</p>
</section>
<section id="mrr-mean-reciprocal-rank" class="level3" data-number="10.1.3">
<h3 data-number="10.1.3" class="anchored" data-anchor-id="mrr-mean-reciprocal-rank"><span class="header-section-number">10.1.3</span> MRR (Mean Reciprocal Rank)</h3>
<p><span class="math display">\[\text{MRR} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\text{rank}_i}\]</span></p>
<p>Measures the average inverse rank of the first relevant result.</p>
</section>
</section>
<section id="performance-metrics" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="performance-metrics"><span class="header-section-number">10.2</span> Performance Metrics</h2>
<ul>
<li><strong>Latency:</strong> P50/P95/P99 under production load</li>
<li><strong>QPS (Queries Per Second):</strong> Throughput capacity</li>
<li><strong>Index build time:</strong> Time to build/rebuild indexes</li>
<li><strong>Memory footprint:</strong> RAM/GPU per million vectors</li>
</ul>
</section>
<section id="cost-metrics" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="cost-metrics"><span class="header-section-number">10.3</span> Cost Metrics</h2>
<ul>
<li><strong>Infrastructure cost:</strong> $/query or $/million vectors</li>
<li><strong>Operational overhead:</strong> Maintenance, monitoring, updates</li>
<li><strong>Storage cost:</strong> Disk, RAM, GPU requirements</li>
</ul>
</section>
<section id="business-metrics-ab-testing" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="business-metrics-ab-testing"><span class="header-section-number">10.4</span> Business Metrics (A/B Testing)</h2>
<ul>
<li><strong>Click-through rate (CTR):</strong> User engagement with results</li>
<li><strong>Success rate:</strong> Task completion percentage</li>
<li><strong>Dwell time:</strong> Time spent with retrieved content</li>
<li><strong>User satisfaction:</strong> Direct feedback or NPS scores</li>
</ul>
</section>
<section id="evaluation-best-practices" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="evaluation-best-practices"><span class="header-section-number">10.5</span> Evaluation Best Practices</h2>
<ol type="1">
<li><strong>Establish baselines:</strong> Always compare against exact search</li>
<li><strong>Use holdout sets:</strong> Avoid overfitting to test queries</li>
<li><strong>Monitor in production:</strong> Online metrics often differ from offline</li>
<li><strong>Track over time:</strong> Detect drift and degradation</li>
<li><strong>Segment analysis:</strong> Different query types may have different performance</li>
</ol>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Computing evaluation metrics</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> recall_at_k(retrieved, relevant, k):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate Recall@k"""</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    retrieved_k <span class="op">=</span> <span class="bu">set</span>(retrieved[:k])</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    relevant_set <span class="op">=</span> <span class="bu">set</span>(relevant)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(retrieved_k <span class="op">&amp;</span> relevant_set) <span class="op">/</span> <span class="bu">len</span>(relevant_set) <span class="cf">if</span> relevant_set <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dcg_at_k(relevance_scores, k):</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate DCG@k"""</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    relevance_scores <span class="op">=</span> np.array(relevance_scores[:k])</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    gains <span class="op">=</span> <span class="dv">2</span><span class="op">**</span>relevance_scores <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    discounts <span class="op">=</span> np.log2(np.arange(<span class="dv">2</span>, <span class="bu">len</span>(relevance_scores) <span class="op">+</span> <span class="dv">2</span>))</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>(gains <span class="op">/</span> discounts)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ndcg_at_k(retrieved_relevance, ideal_relevance, k):</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate NDCG@k"""</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    dcg <span class="op">=</span> dcg_at_k(retrieved_relevance, k)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    idcg <span class="op">=</span> dcg_at_k(<span class="bu">sorted</span>(ideal_relevance, reverse<span class="op">=</span><span class="va">True</span>), k)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dcg <span class="op">/</span> idcg <span class="cf">if</span> idcg <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mrr(retrieved_lists, relevant_lists):</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate Mean Reciprocal Rank"""</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    reciprocal_ranks <span class="op">=</span> []</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> retrieved, relevant <span class="kw">in</span> <span class="bu">zip</span>(retrieved_lists, relevant_lists):</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        relevant_set <span class="op">=</span> <span class="bu">set</span>(relevant)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rank, item <span class="kw">in</span> <span class="bu">enumerate</span>(retrieved, <span class="dv">1</span>):</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> item <span class="kw">in</span> relevant_set:</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>                reciprocal_ranks.append(<span class="dv">1</span> <span class="op">/</span> rank)</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>            reciprocal_ranks.append(<span class="dv">0</span>)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.mean(reciprocal_ranks)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Example data</span></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Query 1</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>retrieved_1 <span class="op">=</span> [<span class="st">'doc3'</span>, <span class="st">'doc1'</span>, <span class="st">'doc5'</span>, <span class="st">'doc2'</span>, <span class="st">'doc7'</span>, <span class="st">'doc4'</span>]</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>relevant_1 <span class="op">=</span> [<span class="st">'doc1'</span>, <span class="st">'doc2'</span>, <span class="st">'doc4'</span>]</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>relevance_scores_1 <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>]  <span class="co"># Graded relevance (0-3 scale)</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Query 2</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>retrieved_2 <span class="op">=</span> [<span class="st">'doc8'</span>, <span class="st">'doc6'</span>, <span class="st">'doc9'</span>, <span class="st">'doc2'</span>, <span class="st">'doc1'</span>]</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>relevant_2 <span class="op">=</span> [<span class="st">'doc1'</span>, <span class="st">'doc2'</span>]</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>relevance_scores_2 <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">2</span>]</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Evaluation Metrics Examples</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics for Query 1</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Query 1:"</span>)</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Retrieved: </span><span class="sc">{</span>retrieved_1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Relevant:  </span><span class="sc">{</span>relevant_1<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@3:  </span><span class="sc">{</span>recall_at_k(retrieved_1, relevant_1, <span class="dv">3</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@5:  </span><span class="sc">{</span>recall_at_k(retrieved_1, relevant_1, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  NDCG@5:    </span><span class="sc">{</span>ndcg_at_k(relevance_scores_1, relevance_scores_1, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Query 2:"</span>)</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Retrieved: </span><span class="sc">{</span>retrieved_2<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Relevant:  </span><span class="sc">{</span>relevant_2<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@3:  </span><span class="sc">{</span>recall_at_k(retrieved_2, relevant_2, <span class="dv">3</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Recall@5:  </span><span class="sc">{</span>recall_at_k(retrieved_2, relevant_2, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  NDCG@5:    </span><span class="sc">{</span>ndcg_at_k(relevance_scores_2, relevance_scores_2, <span class="dv">5</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a><span class="co"># MRR across both queries</span></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>mrr_score <span class="op">=</span> mrr([retrieved_1, retrieved_2], [relevant_1, relevant_2])</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Mean Reciprocal Rank (MRR): </span><span class="sc">{</span>mrr_score<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize recall@k</span></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>k_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a>recall_1 <span class="op">=</span> [recall_at_k(retrieved_1, relevant_1, k) <span class="cf">for</span> k <span class="kw">in</span> k_values]</span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a>recall_2 <span class="op">=</span> [recall_at_k(retrieved_2, relevant_2, k) <span class="cf">for</span> k <span class="kw">in</span> k_values]</span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, recall_1, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Query 1'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a>plt.plot(k_values, recall_2, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Query 2'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'k (number of results)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Recall@k'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Recall@k for Two Sample Queries'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a>plt.xticks(k_values)</span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="dv">0</span>, <span class="fl">1.1</span>])</span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'recall_at_k.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
📊 Evaluation Metrics Examples

======================================================================

Query 1:
  Retrieved: ['doc3', 'doc1', 'doc5', 'doc2', 'doc7', 'doc4']
  Relevant:  ['doc1', 'doc2', 'doc4']
  Recall@3:  0.3333
  Recall@5:  0.6667
  NDCG@5:    0.6078

Query 2:
  Retrieved: ['doc8', 'doc6', 'doc9', 'doc2', 'doc1']
  Relevant:  ['doc1', 'doc2']
  Recall@3:  0.0000
  Recall@5:  1.0000
  NDCG@5:    0.4695

Mean Reciprocal Rank (MRR): 0.3750

======================================================================</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="operating-at-scale" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Operating at Scale</h1>
<p>Production vector databases require careful operational planning.</p>
<section id="index-build-updates" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="index-build-updates"><span class="header-section-number">11.1</span> Index Build &amp; Updates</h2>
<p><strong>Batch Operations:</strong> - Offline batch build for major changes - Schedule during low-traffic periods - Use distributed build for large datasets</p>
<p><strong>Streaming Updates:</strong> - Real-time upserts for freshness requirements - Balance throughput vs consistency - Monitor lag between write and searchability</p>
<p><strong>Delete Handling:</strong> - Lazy deletes with tombstone markers - Background consolidation/compaction - Plan for periodic full rebuilds</p>
<p><strong>Deployment Strategy:</strong> - Keep read replicas for zero-downtime updates - Blue/green deployment for index version changes - Gradual rollout with traffic splitting</p>
</section>
<section id="sharding-strategies" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="sharding-strategies"><span class="header-section-number">11.2</span> Sharding Strategies</h2>
<p><strong>Hash Sharding:</strong> - Uniform distribution by document ID - Simple routing logic - Good for load balancing</p>
<p><strong>Semantic Sharding:</strong> - Partition by domain/topic/category - Improves cache locality - Enables targeted search</p>
<p><strong>Query Routing:</strong> - Coarse hash for uniform shards - Routing model for semantic shards - Fan-out to multiple shards when needed</p>
</section>
<section id="caching-strategies" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="caching-strategies"><span class="header-section-number">11.3</span> Caching Strategies</h2>
<p><strong>Query Vector Cache:</strong> - Cache embeddings for popular queries - LRU eviction policy - Shared across replicas</p>
<p><strong>Result Cache:</strong> - Cache complete search results - Short TTL for dynamic data - Invalidate on updates</p>
<p><strong>Precomputation:</strong> - Pre-embed frequent query patterns - Materialize popular aggregations - Scheduled refresh</p>
</section>
<section id="hardware-considerations" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="hardware-considerations"><span class="header-section-number">11.4</span> Hardware Considerations</h2>
<p><strong>GPU vs CPU:</strong> - <strong>GPU:</strong> Excellent for IVF-PQ, flat re-rank, large batch queries - <strong>CPU:</strong> Fine for HNSW, lower QPS, memory-optimized workloads</p>
<p><strong>Memory Architecture:</strong> - Watch NUMA placement for multi-socket systems - Leverage SIMD instructions (AVX-512, NEON) - Monitor memory bandwidth bottlenecks</p>
<p><strong>Storage Tiers:</strong> - Hot data in RAM/GPU memory - Warm data on NVMe SSD - Cold data on HDD or object storage</p>
</section>
<section id="security-compliance" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="security-compliance"><span class="header-section-number">11.5</span> Security &amp; Compliance</h2>
<p><strong>Data Protection:</strong> - Encryption at rest and in transit - Field-level encryption for sensitive data - Secure key management</p>
<p><strong>Access Control:</strong> - Row-level ACLs for multi-tenancy - Attribute-based access control (ABAC) - API key rotation policies</p>
<p><strong>Compliance:</strong> - Right-to-be-forgotten requires true deletion - Audit logs for all access - Data residency requirements - GDPR, CCPA, HIPAA considerations</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Simulating sharding strategies</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hashlib</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hash_shard(doc_id, num_shards):</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Hash-based sharding"""</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    hash_val <span class="op">=</span> <span class="bu">int</span>(hashlib.md5(doc_id.encode()).hexdigest(), <span class="dv">16</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> hash_val <span class="op">%</span> num_shards</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> semantic_shard(doc_category, category_to_shard):</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Semantic/category-based sharding"""</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> category_to_shard.get(doc_category, <span class="dv">0</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample documents</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>documents <span class="op">=</span> [</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc1"</span>, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"title"</span>: <span class="st">"Neural Networks"</span>},</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc2"</span>, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"title"</span>: <span class="st">"Deep Learning"</span>},</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc3"</span>, <span class="st">"category"</span>: <span class="st">"DB"</span>, <span class="st">"title"</span>: <span class="st">"Vector Databases"</span>},</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc4"</span>, <span class="st">"category"</span>: <span class="st">"DB"</span>, <span class="st">"title"</span>: <span class="st">"Indexing Strategies"</span>},</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc5"</span>, <span class="st">"category"</span>: <span class="st">"NLP"</span>, <span class="st">"title"</span>: <span class="st">"Transformers"</span>},</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc6"</span>, <span class="st">"category"</span>: <span class="st">"NLP"</span>, <span class="st">"title"</span>: <span class="st">"Text Embeddings"</span>},</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc7"</span>, <span class="st">"category"</span>: <span class="st">"ML"</span>, <span class="st">"title"</span>: <span class="st">"CNNs"</span>},</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"id"</span>: <span class="st">"doc8"</span>, <span class="st">"category"</span>: <span class="st">"DB"</span>, <span class="st">"title"</span>: <span class="st">"Query Optimization"</span>},</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>num_shards <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>category_to_shard <span class="op">=</span> {<span class="st">"ML"</span>: <span class="dv">0</span>, <span class="st">"DB"</span>: <span class="dv">1</span>, <span class="st">"NLP"</span>: <span class="dv">2</span>}</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔀 Sharding Strategies Comparison</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Hash sharding</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Hash-based Sharding:"</span>)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>hash_shards <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)}</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> documents:</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    shard <span class="op">=</span> hash_shard(doc[<span class="st">"id"</span>], num_shards)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    hash_shards[shard].append(doc[<span class="st">"id"</span>])</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> shard_id, docs <span class="kw">in</span> hash_shards.items():</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Shard </span><span class="sc">{</span>shard_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>docs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Semantic sharding</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Semantic Sharding (by category):"</span>)</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>semantic_shards <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)}</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> documents:</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>    shard <span class="op">=</span> semantic_shard(doc[<span class="st">"category"</span>], category_to_shard)</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>    semantic_shards[shard].append(<span class="ss">f"</span><span class="sc">{</span>doc[<span class="st">'id'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>doc[<span class="st">'category'</span>]<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> shard_id, docs <span class="kw">in</span> semantic_shards.items():</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>    categories <span class="op">=</span> [<span class="st">"ML"</span>, <span class="st">"DB"</span>, <span class="st">"NLP"</span>]</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Shard </span><span class="sc">{</span>shard_id<span class="sc">}</span><span class="ss"> [</span><span class="sc">{</span>categories[shard_id]<span class="sc">}</span><span class="ss">]: </span><span class="sc">{</span>docs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Trade-offs:"</span>)</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Hash sharding: Uniform load, requires fan-out for category queries"</span>)</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Semantic sharding: Targeted queries, but potential load imbalance"</span>)</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  • Hybrid: Use semantic for common patterns, hash for others"</span>)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize distribution</span></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Hash sharding distribution</span></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>hash_counts <span class="op">=</span> [<span class="bu">len</span>(hash_shards[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)]</span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>ax1.bar(<span class="bu">range</span>(num_shards), hash_counts, color<span class="op">=</span><span class="st">'steelblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Shard ID'</span>)</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Number of Documents'</span>)</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Hash-based Sharding</span><span class="ch">\n</span><span class="st">(Uniform Distribution)'</span>)</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>ax1.set_xticks(<span class="bu">range</span>(num_shards))</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Semantic sharding distribution</span></span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>semantic_counts <span class="op">=</span> [<span class="bu">len</span>(semantic_shards[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_shards)]</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'#e74c3c'</span>, <span class="st">'#3498db'</span>, <span class="st">'#2ecc71'</span>]</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>ax2.bar(<span class="bu">range</span>(num_shards), semantic_counts, color<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Shard ID'</span>)</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Number of Documents'</span>)</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Semantic Sharding</span><span class="ch">\n</span><span class="st">(Category-based)'</span>)</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>ax2.set_xticks(<span class="bu">range</span>(num_shards))</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>ax2.set_xticklabels([<span class="st">'ML'</span>, <span class="st">'DB'</span>, <span class="st">'NLP'</span>])</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>ax2.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'sharding_strategies.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
🔀 Sharding Strategies Comparison

======================================================================

Hash-based Sharding:
  Shard 0: ['doc5', 'doc6', 'doc7']
  Shard 1: ['doc2', 'doc4']
  Shard 2: ['doc1', 'doc3', 'doc8']

Semantic Sharding (by category):
  Shard 0 [ML]: ['doc1 (ML)', 'doc2 (ML)', 'doc7 (ML)']
  Shard 1 [DB]: ['doc3 (DB)', 'doc4 (DB)', 'doc8 (DB)']
  Shard 2 [NLP]: ['doc5 (NLP)', 'doc6 (NLP)']

======================================================================

💡 Trade-offs:
  • Hash sharding: Uniform load, requires fan-out for category queries
  • Semantic sharding: Targeted queries, but potential load imbalance
  • Hybrid: Use semantic for common patterns, hash for others</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-11-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="challenges-how-to-handle-them" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Challenges &amp; How to Handle Them</h1>
<table class="table">
<colgroup>
<col style="width: 29%">
<col style="width: 37%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Challenge</th>
<th>Why it hurts</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Recall–latency trade-off</strong></td>
<td>Higher efSearch/nprobe → slower queries</td>
<td>Tune per route (mobile vs internal tool); two-stage ranking with fast first-pass</td>
</tr>
<tr class="even">
<td><strong>Filters with ANN</strong></td>
<td>Index isn’t filter-aware, breaks assumptions</td>
<td>Pre-partition by key filters; maintain per-segment indexes; post-filter with larger candidate lists</td>
</tr>
<tr class="odd">
<td><strong>Drift / re-embeddings</strong></td>
<td>Embedding versions incompatible, breaks search</td>
<td>Versioned vector fields; dual-write during transition; gradual cutover with monitoring</td>
</tr>
<tr class="even">
<td><strong>Quantization error</strong></td>
<td>PQ shrinks vectors, may lose nuance</td>
<td>Use OPQ (learned rotation); mixed precision (PQ for recall@100, float for re-rank)</td>
</tr>
<tr class="odd">
<td><strong>Deletions</strong></td>
<td>HNSW lazy deletes leave “ghost” nodes</td>
<td>Periodic rebuild/compaction; tombstone pruning; maintain delete bitmap</td>
</tr>
</tbody>
</table>
<section id="troubleshooting-guide" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="troubleshooting-guide"><span class="header-section-number">12.1</span> Troubleshooting Guide</h2>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 35%">
<col style="width: 30%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Symptom</th>
<th>Likely Cause</th>
<th>Quick Test</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Good recall offline, poor in production</strong></td>
<td>Keyword mismatch or different data distribution</td>
<td>Compare query distribution: offline vs live</td>
<td>Enable hybrid BM25+vector search</td>
</tr>
<tr class="even">
<td><strong>High recall, low business metrics (CTR/conversion)</strong></td>
<td>Chunking too large or wrong granularity</td>
<td>Test 256 vs 512 vs 1024 token chunks</td>
<td>Pick size that maximizes downstream metric</td>
</tr>
<tr class="odd">
<td><strong>Recall degrades over time</strong></td>
<td>Model drift or data distribution shift</td>
<td>Compare current vs baseline recall@k weekly</td>
<td>Re-index with updated embeddings; A/B test new model</td>
</tr>
<tr class="even">
<td><strong>Fast offline, slow in production</strong></td>
<td>Cold cache or network latency</td>
<td>Profile with/without warm cache</td>
<td>Add query result caching; pre-warm frequently-accessed vectors</td>
</tr>
<tr class="odd">
<td><strong>Good vector scores, irrelevant results</strong></td>
<td>Embedding model not domain-specific</td>
<td>Test domain-specific vs generic embeddings</td>
<td>Fine-tune or switch to domain-adapted model (SciBERT, CodeBERT, etc.)</td>
</tr>
<tr class="even">
<td><strong>High memory usage</strong></td>
<td>Large M/efConstruction or no quantization</td>
<td>Measure memory per million vectors</td>
<td>Use PQ compression; reduce M; consider IVF-PQ instead of HNSW</td>
</tr>
<tr class="odd">
<td><strong>Filters return too few results</strong></td>
<td>Post-filtering after low-k ANN search</td>
<td>Increase k before filtering (e.g., 100→500)</td>
<td>Pre-partition index by common filters or increase candidate k</td>
</tr>
<tr class="even">
<td><strong>Inconsistent recall across queries</strong></td>
<td>Some queries OOD (out-of-distribution)</td>
<td>Cluster queries, measure recall per cluster</td>
<td>Identify weak clusters; add training data; use query reformulation</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="practical-sizing-tuning-cheatsheet" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> Practical Sizing &amp; Tuning Cheatsheet</h1>
<p>A quick reference guide for getting started with vector database configuration.</p>
<hr>
<section id="production-defaults-start-here" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="production-defaults-start-here"><span class="header-section-number">13.1</span> 🎯 Production Defaults: Start Here</h2>
<blockquote class="blockquote">
<p><strong>Copy-paste these settings for a working baseline:</strong></p>
</blockquote>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 17%">
<col style="width: 56%">
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th>Index</th>
<th>Starting Configuration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Small scale</strong> (≤50M vectors, RAM)</td>
<td>HNSW</td>
<td><code>M=16</code>, <code>efConstruction=200</code>, <code>efSearch=64</code></td>
</tr>
<tr class="even">
<td><strong>Large scale</strong> (50M-1B, GPU)</td>
<td>IVF-PQ</td>
<td><code>nlist=√N</code>, <code>nprobe=16</code>, <code>m=64</code>, <code>nbits=8</code></td>
</tr>
<tr class="odd">
<td><strong>Metric</strong></td>
<td>Most text/NLP tasks</td>
<td><strong>Cosine</strong> (normalize vectors!)</td>
</tr>
<tr class="even">
<td><strong>Target SLA</strong></td>
<td>Production search</td>
<td><code>recall@10 ≥ 0.95</code>, <code>P95 latency ≤ 50ms</code></td>
</tr>
</tbody>
</table>
<p><strong>Quick sanity check:</strong> After indexing, run 100 test queries. If recall@10 &lt; 0.90, increase <code>efSearch</code> or <code>nprobe</code> by 2x and remeasure.</p>
<hr>
</section>
<section id="initial-setup-checklist" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="initial-setup-checklist"><span class="header-section-number">13.2</span> Initial Setup Checklist</h2>
<p>✅ <strong>Pick metric early</strong> (cosine vs L2 vs MIPS) - Cosine: Most common for text/semantic search - L2: When magnitude matters - MIPS: For asymmetric similarity tasks</p>
<p>✅ <strong>Choose index based on scale:</strong></p>
<p><strong>≤ 50M vectors, RAM-based:</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HNSW configuration</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> HNSWIndex(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">768</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    M<span class="op">=</span><span class="dv">16</span>,                    <span class="co"># Start with 16-32</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    efConstruction<span class="op">=</span><span class="dv">200</span>,      <span class="co"># 200-400 for good recall</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    efSearch<span class="op">=</span><span class="dv">64</span>,             <span class="co"># Tune based on latency SLO</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">'cosine'</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>50M–1B vectors or GPU:</strong></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># IVF-PQ configuration</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>nlist <span class="op">=</span> <span class="bu">int</span>(np.sqrt(n_vectors))  <span class="co"># e.g., 31,623 for 1B vectors</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> IVFPQIndex(</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">768</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    nlist<span class="op">=</span>nlist,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    nprobe<span class="op">=</span><span class="dv">16</span>,               <span class="co"># Start with 8-64</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    m<span class="op">=</span><span class="dv">64</span>,                    <span class="co"># PQ subvectors</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    nbits<span class="op">=</span><span class="dv">8</span>,                 <span class="co"># bits per subvector</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">'cosine'</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="tuning-for-latency-slo" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="tuning-for-latency-slo"><span class="header-section-number">13.3</span> Tuning for Latency SLO</h2>
<p><strong>Target: 95% recall@k with P95 latency &lt; threshold</strong></p>
<ol type="1">
<li><strong>Baseline:</strong> Start with conservative params</li>
<li><strong>Measure:</strong> Run benchmark queries, measure recall &amp; latency</li>
<li><strong>Iterate:</strong> Gradually increase efSearch/nprobe</li>
<li><strong>Monitor:</strong> Stop when latency SLO is met or recall plateaus</li>
</ol>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example tuning loop</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">512</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ef <span class="kw">in</span> params:</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    index.efSearch <span class="op">=</span> ef</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    recall, p95_latency <span class="op">=</span> benchmark(index, test_queries)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"ef=</span><span class="sc">{</span>ef<span class="sc">}</span><span class="ss">: recall=</span><span class="sc">{</span>recall<span class="sc">:.3f}</span><span class="ss">, P95=</span><span class="sc">{</span>p95_latency<span class="sc">:.1f}</span><span class="ss">ms"</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> recall <span class="op">&gt;=</span> <span class="fl">0.95</span> <span class="kw">and</span> p95_latency <span class="op">&lt;=</span> target_latency:</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="hybrid-search-setup" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="hybrid-search-setup"><span class="header-section-number">13.4</span> Hybrid Search Setup</h2>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Enable both vector and keyword search</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> {</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vector_search'</span>: {</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'enabled'</span>: <span class="va">True</span>,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'weight'</span>: <span class="fl">0.7</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'keyword_search'</span>: {</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'enabled'</span>: <span class="va">True</span>,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'algorithm'</span>: <span class="st">'BM25'</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'weight'</span>: <span class="fl">0.3</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fusion_method'</span>: <span class="st">'RRF'</span>,  <span class="co"># or 'weighted_sum'</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reranker'</span>: {</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'model'</span>: <span class="st">'cross-encoder/ms-marco-MiniLM-L-6-v2'</span>,</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'top_k'</span>: <span class="dv">100</span>  <span class="co"># Re-rank top 100 from fusion</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="filter-configuration" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="filter-configuration"><span class="header-section-number">13.5</span> Filter Configuration</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Segment by common filters</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>filter_strategy <span class="op">=</span> {</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tenant_id'</span>: <span class="st">'pre_partition'</span>,     <span class="co"># High cardinality</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'language'</span>: <span class="st">'segment_index'</span>,      <span class="co"># Low cardinality (10-20 values)</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'publish_date'</span>: <span class="st">'post_filter'</span>,    <span class="co"># Range filter</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'category'</span>: <span class="st">'segment_index'</span>       <span class="co"># Common query pattern</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="operational-monitoring" class="level2" data-number="13.6">
<h2 data-number="13.6" class="anchored" data-anchor-id="operational-monitoring"><span class="header-section-number">13.6</span> Operational Monitoring</h2>
<p><strong>Key metrics to track:</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> {</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Quality</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'recall_at_10'</span>: target <span class="op">&gt;=</span> <span class="fl">0.95</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ndcg_at_10'</span>: target <span class="op">&gt;=</span> <span class="fl">0.85</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Performance</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p50_latency_ms'</span>: target <span class="op">&lt;=</span> <span class="dv">20</span>,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p95_latency_ms'</span>: target <span class="op">&lt;=</span> <span class="dv">50</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p99_latency_ms'</span>: target <span class="op">&lt;=</span> <span class="dv">100</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'qps'</span>: target <span class="op">&gt;=</span> <span class="dv">1000</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resource</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'memory_per_million_vectors_gb'</span>: monitor,</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gpu_utilization_%'</span>: target <span class="op">&gt;=</span> <span class="dv">70</span>,</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'cache_hit_rate_%'</span>: target <span class="op">&gt;=</span> <span class="dv">80</span>,</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Operations</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'index_freshness_lag_seconds'</span>: target <span class="op">&lt;=</span> <span class="dv">300</span>,</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'failed_query_rate_%'</span>: target <span class="op">&lt;=</span> <span class="fl">0.1</span>,</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="blue-green-deployment" class="level2" data-number="13.7">
<h2 data-number="13.7" class="anchored" data-anchor-id="blue-green-deployment"><span class="header-section-number">13.7</span> Blue-Green Deployment</h2>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Version transition workflow</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>deployment <span class="op">=</span> {</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_1_dual_write'</span>: {</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'duration'</span>: <span class="st">'1 week'</span>,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'write_to'</span>: [<span class="st">'index_v1'</span>, <span class="st">'index_v2'</span>],</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'read_from'</span>: <span class="st">'index_v1'</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">100</span>, <span class="st">'v2'</span>: <span class="dv">0</span>}</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_2_canary'</span>: {</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'duration'</span>: <span class="st">'3 days'</span>,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">95</span>, <span class="st">'v2'</span>: <span class="dv">5</span>},</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'monitor'</span>: [<span class="st">'recall'</span>, <span class="st">'latency'</span>, <span class="st">'error_rate'</span>]</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_3_ramp'</span>: {</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'duration'</span>: <span class="st">'1 week'</span>,</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">50</span>, <span class="st">'v2'</span>: <span class="dv">50</span>},</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'phase_4_cutover'</span>: {</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'traffic_split'</span>: {<span class="st">'v1'</span>: <span class="dv">0</span>, <span class="st">'v2'</span>: <span class="dv">100</span>},</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'deprecate'</span>: <span class="st">'index_v1'</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="minimal-example-with-faiss" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> Minimal Example with FAISS</h1>
<p>Let’s build a complete working example using FAISS, one of the most popular vector search libraries.</p>
<section id="installation" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="installation"><span class="header-section-number">14.1</span> Installation</h2>
<div class="sourceCode" id="cb30"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># CPU version</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install faiss-cpu</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># GPU version (if CUDA is available)</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install faiss-gpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="complete-ivf-pq-implementation" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="complete-ivf-pq-implementation"><span class="header-section-number">14.2</span> Complete IVF-PQ Implementation</h2>
<p>Below is a production-style implementation using FAISS with IVF-PQ indexing.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Complete FAISS example with IVF-PQ indexing</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: Install faiss-cpu first: pip install faiss-cpu numpy</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># For visualization</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vector Database with FAISS: Complete Example"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Generate synthetic embeddings</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📊 Step 1: Generating synthetic embeddings..."</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">768</span>  <span class="co"># embedding dimension (typical for sentence transformers)</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> <span class="dv">100000</span>  <span class="co"># number of vectors in the database</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>nq <span class="op">=</span> <span class="dv">100</span>  <span class="co"># number of queries</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic embeddings (in practice, use real embedding models)</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>xb <span class="op">=</span> np.random.randn(nb, d).astype(<span class="st">'float32'</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>xq <span class="op">=</span> np.random.randn(nq, d).astype(<span class="st">'float32'</span>)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize for cosine similarity (important!)</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>xb <span class="op">=</span> xb <span class="op">/</span> np.linalg.norm(xb, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>xq <span class="op">=</span> xq <span class="op">/</span> np.linalg.norm(xq, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Created </span><span class="sc">{</span>nb<span class="sc">:,}</span><span class="ss"> database vectors"</span>)</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Created </span><span class="sc">{</span>nq<span class="sc">:,}</span><span class="ss"> query vectors"</span>)</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Dimension: </span><span class="sc">{</span>d<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  ✓ Memory footprint: </span><span class="sc">{</span>xb<span class="sc">.</span>nbytes <span class="op">/</span> <span class="dv">1024</span><span class="op">**</span><span class="dv">2</span><span class="sc">:.2f}</span><span class="ss"> MB"</span>)</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Build the index</span></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="co"># ============================================================================</span></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🏗️  Step 2: Building IVF-PQ index..."</span>)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> faiss</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># IVF-PQ parameters</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>    nlist <span class="op">=</span> <span class="dv">256</span>  <span class="co"># number of clusters (cells)</span></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> <span class="dv">64</span>       <span class="co"># number of subquantizers (must divide d evenly)</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>    nbits <span class="op">=</span> <span class="dv">8</span>    <span class="co"># bits per subquantizer</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create quantizer (for coarse search)</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>    quantizer <span class="op">=</span> faiss.IndexFlatIP(d)  <span class="co"># Inner Product = cosine for normalized vectors</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create IVF-PQ index</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> faiss.IndexIVFPQ(quantizer, d, nlist, m, nbits)</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train the index (k-means + PQ training)</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Training index with nlist=</span><span class="sc">{</span>nlist<span class="sc">}</span><span class="ss">, m=</span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">, nbits=</span><span class="sc">{</span>nbits<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>    index.train(xb)</span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>    train_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Training completed in </span><span class="sc">{</span>train_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add vectors to the index</span></span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Adding </span><span class="sc">{</span>nb<span class="sc">:,}</span><span class="ss"> vectors..."</span>)</span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>    index.add(xb)</span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>    add_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Vectors added in </span><span class="sc">{</span>add_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Index contains </span><span class="sc">{</span>index<span class="sc">.</span>ntotal<span class="sc">:,}</span><span class="ss"> vectors"</span>)</span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: Search</span></span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">🔍 Step 3: Performing search..."</span>)</span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set search parameters</span></span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>    index.nprobe <span class="op">=</span> <span class="dv">16</span>  <span class="co"># number of clusters to search (recall/latency trade-off)</span></span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> <span class="dv">10</span>  <span class="co"># return top-10 neighbors</span></span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  • Search parameters: nprobe=</span><span class="sc">{</span>index<span class="sc">.</span>nprobe<span class="sc">}</span><span class="ss">, k=</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Perform search</span></span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>    scores, indices <span class="op">=</span> index.search(xq, k)</span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>    search_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Searched </span><span class="sc">{</span>nq<span class="sc">}</span><span class="ss"> queries in </span><span class="sc">{</span>search_time<span class="op">*</span><span class="dv">1000</span><span class="sc">:.2f}</span><span class="ss"> ms"</span>)</span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Throughput: </span><span class="sc">{</span>nq<span class="op">/</span>search_time<span class="sc">:.0f}</span><span class="ss"> QPS"</span>)</span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  ✓ Average latency: </span><span class="sc">{</span>search_time<span class="op">/</span>nq<span class="op">*</span><span class="dv">1000</span><span class="sc">:.2f}</span><span class="ss"> ms per query"</span>)</span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 4: Display results</span></span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">📋 Step 4: Sample results..."</span>)</span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First query results:"</span>)</span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Top-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> neighbor IDs: </span><span class="sc">{</span>indices[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Top-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> scores: </span><span class="sc">{</span>scores[<span class="dv">0</span>]<span class="sc">.</span><span class="bu">round</span>(<span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 5: Tune nprobe for recall/latency trade-off</span></span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============================================================================</span></span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">⚙️  Step 5: Tuning nprobe parameter..."</span>)</span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a>    nprobe_values <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">64</span>]</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a>    latencies <span class="op">=</span> []</span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> nprobe <span class="kw">in</span> nprobe_values:</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a>        index.nprobe <span class="op">=</span> nprobe</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> time.time()</span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a>        _, _ <span class="op">=</span> index.search(xq[:<span class="dv">10</span>], k)  <span class="co"># Test with 10 queries</span></span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a>        elapsed <span class="op">=</span> (time.time() <span class="op">-</span> start) <span class="op">/</span> <span class="dv">10</span> <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># ms per query</span></span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a>        latencies.append(elapsed)</span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot results</span></span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a>    ax.plot(nprobe_values, latencies, marker<span class="op">=</span><span class="st">'o'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb31-117"><a href="#cb31-117" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'nprobe (number of clusters searched)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb31-118"><a href="#cb31-118" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Latency (ms per query)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb31-119"><a href="#cb31-119" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Search Latency vs nprobe'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-120"><a href="#cb31-120" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb31-121"><a href="#cb31-121" aria-hidden="true" tabindex="-1"></a>    ax.set_xscale(<span class="st">'log'</span>, base<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-122"><a href="#cb31-122" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-123"><a href="#cb31-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Annotate points</span></span>
<span id="cb31-124"><a href="#cb31-124" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (np_val, lat) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(nprobe_values, latencies)):</span>
<span id="cb31-125"><a href="#cb31-125" aria-hidden="true" tabindex="-1"></a>        ax.annotate(<span class="ss">f'</span><span class="sc">{</span>lat<span class="sc">:.2f}</span><span class="ss">ms'</span>, </span>
<span id="cb31-126"><a href="#cb31-126" aria-hidden="true" tabindex="-1"></a>                   xy<span class="op">=</span>(np_val, lat), </span>
<span id="cb31-127"><a href="#cb31-127" aria-hidden="true" tabindex="-1"></a>                   xytext<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>), </span>
<span id="cb31-128"><a href="#cb31-128" aria-hidden="true" tabindex="-1"></a>                   textcoords<span class="op">=</span><span class="st">'offset points'</span>,</span>
<span id="cb31-129"><a href="#cb31-129" aria-hidden="true" tabindex="-1"></a>                   fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb31-130"><a href="#cb31-130" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-131"><a href="#cb31-131" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb31-132"><a href="#cb31-132" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">'faiss_nprobe_tuning.png'</span>, dpi<span class="op">=</span><span class="dv">100</span>, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb31-133"><a href="#cb31-133" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb31-134"><a href="#cb31-134" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-135"><a href="#cb31-135" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb31-136"><a href="#cb31-136" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✅ FAISS example completed successfully!"</span>)</span>
<span id="cb31-137"><a href="#cb31-137" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb31-138"><a href="#cb31-138" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-139"><a href="#cb31-139" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb31-140"><a href="#cb31-140" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">⚠️  FAISS not installed. Install with: pip install faiss-cpu"</span>)</span>
<span id="cb31-141"><a href="#cb31-141" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Here's what the code would do:"</span>)</span>
<span id="cb31-142"><a href="#cb31-142" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  1. Create an IVF-PQ index with cosine similarity"</span>)</span>
<span id="cb31-143"><a href="#cb31-143" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  2. Train the index on 100K vectors"</span>)</span>
<span id="cb31-144"><a href="#cb31-144" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  3. Perform fast approximate nearest neighbor search"</span>)</span>
<span id="cb31-145"><a href="#cb31-145" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  4. Demonstrate recall/latency trade-offs"</span>)</span>
<span id="cb31-146"><a href="#cb31-146" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb31-147"><a href="#cb31-147" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">❌ Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-148"><a href="#cb31-148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"This example requires FAISS. Install with: pip install faiss-cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
Vector Database with FAISS: Complete Example
======================================================================

📊 Step 1: Generating synthetic embeddings...
  ✓ Created 100,000 database vectors
  ✓ Created 100 query vectors
  ✓ Dimension: 768
  ✓ Memory footprint: 292.97 MB

🏗️  Step 2: Building IVF-PQ index...
  • Training index with nlist=256, m=64, nbits=8...
  ✓ Created 100,000 database vectors
  ✓ Created 100 query vectors
  ✓ Dimension: 768
  ✓ Memory footprint: 292.97 MB

🏗️  Step 2: Building IVF-PQ index...
  • Training index with nlist=256, m=64, nbits=8...
  ✓ Training completed in 74.89 seconds
  • Adding 100,000 vectors...
  ✓ Training completed in 74.89 seconds
  • Adding 100,000 vectors...
  ✓ Vectors added in 2.02 seconds
  ✓ Index contains 100,000 vectors

🔍 Step 3: Performing search...
  • Search parameters: nprobe=16, k=10
  ✓ Searched 100 queries in 30.00 ms
  ✓ Throughput: 3334 QPS
  ✓ Average latency: 0.30 ms per query

📋 Step 4: Sample results...

First query results:
  Top-10 neighbor IDs: [37887 91949 41194 83788 94566 41790  6916 51013 37990 63991]
  Top-10 scores: [1.347  1.3475 1.3595 1.3597 1.3658 1.3721 1.3754 1.3778 1.3783 1.3784]

⚙️  Step 5: Tuning nprobe parameter...
  ✓ Vectors added in 2.02 seconds
  ✓ Index contains 100,000 vectors

🔍 Step 3: Performing search...
  • Search parameters: nprobe=16, k=10
  ✓ Searched 100 queries in 30.00 ms
  ✓ Throughput: 3334 QPS
  ✓ Average latency: 0.30 ms per query

📋 Step 4: Sample results...

First query results:
  Top-10 neighbor IDs: [37887 91949 41194 83788 94566 41790  6916 51013 37990 63991]
  Top-10 scores: [1.347  1.3475 1.3595 1.3597 1.3658 1.3721 1.3754 1.3778 1.3783 1.3784]

⚙️  Step 5: Tuning nprobe parameter...

======================================================================
✅ FAISS example completed successfully!
======================================================================</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="vector-databases-demystified_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="notes-on-production-usage" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="notes-on-production-usage"><span class="header-section-number">14.3</span> Notes on Production Usage</h2>
<p><strong>Metadata Filtering:</strong> FAISS doesn’t natively support metadata filters. Common approaches: - Use an external database (PostgreSQL, Redis) for metadata - Filter results after retrieval (post-filtering) - Use wrapper libraries like LanceDB or Qdrant that support filters</p>
<p><strong>Hybrid Search:</strong> Combine FAISS with traditional search engines:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pseudo-code</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>vector_results <span class="op">=</span> faiss_index.search(query_embedding, k<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>keyword_results <span class="op">=</span> elasticsearch.search(query_text, size<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>final_results <span class="op">=</span> reciprocal_rank_fusion([vector_results, keyword_results])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Persistence:</strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save index</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>faiss.write_index(index, <span class="st">"vector_index.faiss"</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load index</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> faiss.read_index(<span class="st">"vector_index.faiss"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Cross-Encoder Re-ranking:</strong></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> CrossEncoder</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get candidates from FAISS</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>candidates <span class="op">=</span> index.search(query_vec, k<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-rank with cross-encoder</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>reranker <span class="op">=</span> CrossEncoder(<span class="st">'cross-encoder/ms-marco-MiniLM-L-6-v2'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> reranker.predict([(query_text, doc_text) <span class="cf">for</span> doc_text <span class="kw">in</span> candidate_docs])</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>final_results <span class="op">=</span> sort_by_scores(candidates, scores)[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="frequently-asked-questions-faq" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> Frequently Asked Questions (FAQ)</h1>
<section id="q1-do-i-always-need-a-vector-database" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="q1-do-i-always-need-a-vector-database"><span class="header-section-number">15.1</span> Q1: Do I always need a vector database?</h2>
<p><strong>A:</strong> Not for small corpora. For datasets with &lt; 10,000 documents: - Exact search or in-memory libraries may suffice - Search libraries with vector support (Elasticsearch/OpenSearch) work well - Scale, latency requirements, filter complexity, and operational needs drive the decision</p>
<p><strong>When you DO need a dedicated vector DB:</strong> - Millions+ of vectors - Strict latency requirements (&lt; 50ms P95) - Complex metadata filtering - High QPS (hundreds to thousands) - Need for advanced features (hybrid search, re-ranking, analytics)</p>
<hr>
</section>
<section id="q2-cosine-vs-inner-product-vs-l2-which-should-i-use" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="q2-cosine-vs-inner-product-vs-l2-which-should-i-use"><span class="header-section-number">15.2</span> Q2: Cosine vs Inner Product vs L2 — which should I use?</h2>
<p><strong>A:</strong> It depends on your embedding model and task:</p>
<p><strong>Cosine Similarity:</strong> - Best for: Text embeddings, semantic search - Requires: Normalized vectors - Properties: Magnitude-invariant, captures direction</p>
<p><strong>Inner Product (MIPS):</strong> - Best for: When you normalize vectors (equivalent to cosine) - Use case: Asymmetric similarity tasks - Note: Faster than cosine if vectors are pre-normalized</p>
<p><strong>L2 Distance:</strong> - Best for: When magnitude carries meaning - Use case: Some vision tasks, specific embedding schemes - Properties: Sensitive to scale</p>
<p><strong>Rule of thumb:</strong> For most NLP/text applications, use cosine (with normalization).</p>
<hr>
</section>
<section id="q3-can-i-mix-different-embedding-models-in-one-index" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="q3-can-i-mix-different-embedding-models-in-one-index"><span class="header-section-number">15.3</span> Q3: Can I mix different embedding models in one index?</h2>
<p><strong>A:</strong> Generally <strong>avoid mixing incompatible embedding spaces</strong>:</p>
<p><strong>Problem:</strong> - Different models create incompatible vector spaces - Distances become meaningless across model boundaries</p>
<p><strong>Solutions:</strong> 1. <strong>Separate indexes per model:</strong> Shard by <code>model_version</code>, merge results in application 2. <strong>Re-embed everything:</strong> When upgrading models, re-process entire corpus 3. <strong>Dual-write pattern:</strong> Maintain both versions during transition</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Separate indexes</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>results_v1 <span class="op">=</span> index_v1.search(query_v1, k<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>results_v2 <span class="op">=</span> index_v2.search(query_v2, k<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>final <span class="op">=</span> merge_and_dedupe(results_v1, results_v2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="q4-how-big-should-text-chunks-be" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="q4-how-big-should-text-chunks-be"><span class="header-section-number">15.4</span> Q4: How big should text chunks be?</h2>
<p><strong>A:</strong> Common practice: <strong>256–1024 tokens with 20–30% overlap</strong></p>
<p><strong>Considerations:</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>Chunk Size</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Small (128-256)</td>
<td>Precise matches, less noise</td>
<td>May lack context</td>
</tr>
<tr class="even">
<td>Medium (512)</td>
<td>Good balance</td>
<td>Standard choice</td>
</tr>
<tr class="odd">
<td>Large (1024+)</td>
<td>Rich context</td>
<td>May be too general</td>
</tr>
</tbody>
</table>
<p><strong>Best practice:</strong> - Experiment with your specific use case - Measure retrieval quality (recall, NDCG) - Consider downstream task (Q&amp;A needs precision, summarization needs context) - Use overlap to prevent information loss at boundaries</p>
<hr>
</section>
<section id="q5-what-about-gpu-vs-cpu-for-vector-search" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="q5-what-about-gpu-vs-cpu-for-vector-search"><span class="header-section-number">15.5</span> Q5: What about GPU vs CPU for vector search?</h2>
<p><strong>A:</strong> Choose based on workload characteristics:</p>
<p><strong>GPU Advantages:</strong> - Massive parallelism for batch queries - Excellent for IVF-PQ indexes - Great for re-ranking large candidate sets - Cost-effective at very high QPS</p>
<p><strong>CPU Advantages:</strong> - HNSW performs well on CPU - Lower latency for single queries - Easier deployment and scaling - More flexible for diverse workloads</p>
<p><strong>Hybrid Approach:</strong> - Use CPU for HNSW-based serving - GPU for batch re-embedding and index building - GPU for re-ranking top-k candidates</p>
<hr>
</section>
<section id="q6-how-do-i-handle-real-time-updates" class="level2" data-number="15.6">
<h2 data-number="15.6" class="anchored" data-anchor-id="q6-how-do-i-handle-real-time-updates"><span class="header-section-number">15.6</span> Q6: How do I handle real-time updates?</h2>
<p><strong>A:</strong> Multiple strategies depending on freshness requirements:</p>
<p><strong>Streaming Upserts:</strong></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Real-time updates with eventual consistency</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>index.upsert(doc_id, embedding, metadata)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Visible within seconds to minutes</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Batch Updates:</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Periodic batch updates (hourly/daily)</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>new_embeddings <span class="op">=</span> process_new_documents()</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>index.add_batch(new_embeddings)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Blue-Green Deployment:</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For major rebuilds</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fl">1.</span> Build new_index offline</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fl">2.</span> Warm up new_index (cache, test queries)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fl">3.</span> Switch traffic: old_index → new_index</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="fl">4.</span> Deprecate old_index</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="q7-whats-the-best-open-source-vector-database" class="level2" data-number="15.7">
<h2 data-number="15.7" class="anchored" data-anchor-id="q7-whats-the-best-open-source-vector-database"><span class="header-section-number">15.7</span> Q7: What’s the best open-source vector database?</h2>
<p><strong>A:</strong> Depends on your requirements:</p>
<table class="table">
<colgroup>
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Database</th>
<th>Best For</th>
<th>Key Strengths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>FAISS</strong></td>
<td>Research, prototyping</td>
<td>Performance, flexibility, GPU support</td>
</tr>
<tr class="even">
<td><strong>Milvus</strong></td>
<td>Production scale</td>
<td>Distributed, cloud-native, rich features</td>
</tr>
<tr class="odd">
<td><strong>Qdrant</strong></td>
<td>Moderate scale</td>
<td>Easy API, good filtering, Rust performance</td>
</tr>
<tr class="even">
<td><strong>Weaviate</strong></td>
<td>Hybrid search</td>
<td>GraphQL, modules, good docs</td>
</tr>
<tr class="odd">
<td><strong>Chroma</strong></td>
<td>RAG applications</td>
<td>Simple API, embeddings built-in</td>
</tr>
<tr class="even">
<td><strong>Pinecone</strong></td>
<td>Managed service</td>
<td>Serverless, zero-ops, good DX</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="q8-how-do-i-debug-poor-recall" class="level2" data-number="15.8">
<h2 data-number="15.8" class="anchored" data-anchor-id="q8-how-do-i-debug-poor-recall"><span class="header-section-number">15.8</span> Q8: How do I debug poor recall?</h2>
<p><strong>Checklist:</strong></p>
<ol type="1">
<li>✅ <strong>Check embeddings:</strong> Are they normalized consistently?</li>
<li>✅ <strong>Verify metric:</strong> Cosine vs L2 vs inner product</li>
<li>✅ <strong>Tune parameters:</strong> Increase efSearch/nprobe</li>
<li>✅ <strong>Test with exact search:</strong> Compare ANN vs brute force</li>
<li>✅ <strong>Inspect queries:</strong> Are they in-distribution?</li>
<li>✅ <strong>Check filters:</strong> Post-filtering too aggressive?</li>
<li>✅ <strong>Evaluate embedding model:</strong> Is it appropriate for your domain?</li>
<li>✅ <strong>Look for drift:</strong> Has data distribution changed?</li>
</ol>
<p><strong>Diagnostic code:</strong></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare ANN vs exact search</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>exact_neighbors <span class="op">=</span> exact_index.search(query, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>ann_neighbors <span class="op">=</span> ann_index.search(query, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(exact_neighbors) <span class="op">&amp;</span> <span class="bu">set</span>(ann_neighbors)) <span class="op">/</span> <span class="dv">10</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall@10: </span><span class="sc">{</span>recall<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="tldr---key-takeaways" class="level1" data-number="16">
<h1 data-number="16"><span class="header-section-number">16</span> TL;DR - Key Takeaways</h1>
<section id="core-concepts" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="core-concepts"><span class="header-section-number">16.1</span> 🎯 Core Concepts</h2>
<p>✅ <strong>Vector databases</strong> enable semantic search by storing and querying high-dimensional embeddings</p>
<p>✅ <strong>ANN (Approximate Nearest Neighbor)</strong> indexes trade a small accuracy loss for massive speed gains</p>
<p>✅ <strong>Distance metrics matter:</strong> Cosine for text (normalized), L2 when magnitude matters, MIPS for specialized tasks</p>
<hr>
</section>
<section id="index-selection" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="index-selection"><span class="header-section-number">16.2</span> 🏗️ Index Selection</h2>
<table class="table">
<colgroup>
<col style="width: 18%">
<col style="width: 39%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Scale</th>
<th>Recommendation</th>
<th>Key Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>≤ 50M</td>
<td><strong>HNSW</strong></td>
<td>M=16-32, efConstruction=200-400, efSearch=64-200</td>
</tr>
<tr class="even">
<td>50M-1B</td>
<td><strong>IVF-PQ</strong></td>
<td>nlist=√N, nprobe=8-64, PQ 8-16 bits</td>
</tr>
<tr class="odd">
<td>Web-scale</td>
<td><strong>DiskANN</strong> or sharded IVF-PQ</td>
<td>+ tiered storage, caching</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="production-essentials" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="production-essentials"><span class="header-section-number">16.3</span> ⚙️ Production Essentials</h2>
<ol type="1">
<li><strong>Hybrid search:</strong> Combine vector + keyword (BM25) with RRF fusion</li>
<li><strong>Metadata filters:</strong> Pre-partition by common filters or post-filter with larger k</li>
<li><strong>Re-ranking:</strong> Use cross-encoders on top-100 for precision</li>
<li><strong>Monitoring:</strong> Track recall@k, latency (P50/P95), QPS, and business metrics</li>
<li><strong>Versioning:</strong> Dual-write during model transitions, blue-green deployment</li>
</ol>
<hr>
</section>
<section id="evaluation-framework" class="level2" data-number="16.4">
<h2 data-number="16.4" class="anchored" data-anchor-id="evaluation-framework"><span class="header-section-number">16.4</span> 🔍 Evaluation Framework</h2>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential metrics</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Recall<span class="op">@</span>k (≥ <span class="fl">0.95</span> target)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> NDCG<span class="op">@</span>k (<span class="cf">for</span> ranking quality)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> P95 latency (<span class="op">&lt;</span> <span class="dv">50</span><span class="er">ms</span> typical)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> Cost per million vectors</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> User engagement (CTR, task success)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="getting-started" class="level2" data-number="16.5">
<h2 data-number="16.5" class="anchored" data-anchor-id="getting-started"><span class="header-section-number">16.5</span> 🚀 Getting Started</h2>
<p><strong>Step 1:</strong> Choose your metric (cosine for most text tasks)</p>
<p><strong>Step 2:</strong> Start simple: - Small scale: HNSW with default params - Large scale: IVF-PQ on GPU</p>
<p><strong>Step 3:</strong> Measure baseline (recall, latency, cost)</p>
<p><strong>Step 4:</strong> Iterate: - Tune efSearch/nprobe for recall/latency balance - Add hybrid search if keywords matter - Implement re-ranking for precision</p>
<p><strong>Step 5:</strong> Operationalize: - Monitor key metrics - Set up alerts for recall degradation - Plan for model version migrations - Implement caching and sharding strategies</p>
<hr>
</section>
<section id="common-pitfalls-to-avoid" class="level2" data-number="16.6">
<h2 data-number="16.6" class="anchored" data-anchor-id="common-pitfalls-to-avoid"><span class="header-section-number">16.6</span> 💡 Common Pitfalls to Avoid</h2>
<p>❌ Mixing normalized and unnormalized vectors</p>
<p>❌ Ignoring metadata filters in initial design</p>
<p>❌ Not measuring recall against exact search baseline</p>
<p>❌ Underestimating memory requirements</p>
<p>❌ Forgetting about the cold start problem</p>
<p>❌ No plan for embedding model versioning</p>
<p>❌ Optimizing for accuracy without considering latency</p>
<hr>
</section>
<section id="further-reading" class="level2" data-number="16.7">
<h2 data-number="16.7" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">16.7</span> 📚 Further Reading</h2>
<ul>
<li><strong>FAISS documentation:</strong> Facebook’s high-performance library</li>
<li><strong>HNSW paper:</strong> Malkov &amp; Yashunin (2018)</li>
<li><strong>Vector DB benchmarks:</strong> ann-benchmarks.com</li>
<li><strong>Embedding models:</strong> MTEB leaderboard</li>
<li><strong>Production patterns:</strong> MLOps best practices for vector search</li>
</ul>
<hr>
</section>
<section id="final-thoughts" class="level2" data-number="16.8">
<h2 data-number="16.8" class="anchored" data-anchor-id="final-thoughts"><span class="header-section-number">16.8</span> 🎓 Final Thoughts</h2>
<p>Vector databases are a critical infrastructure component for modern AI applications. Success requires:</p>
<ol type="1">
<li><strong>Understanding the fundamentals:</strong> embeddings, distances, indexes</li>
<li><strong>Making informed trade-offs:</strong> recall vs latency vs cost</li>
<li><strong>Measuring what matters:</strong> establish metrics before optimization</li>
<li><strong>Planning for operations:</strong> versioning, monitoring, scaling</li>
<li><strong>Iterating based on data:</strong> A/B test, measure, improve</li>
</ol>
<p><strong>Start simple, measure everything, scale gradually.</strong></p>
<hr>
</section>
<section id="questions-or-feedback" class="level2" data-number="16.9">
<h2 data-number="16.9" class="anchored" data-anchor-id="questions-or-feedback"><span class="header-section-number">16.9</span> 📬 Questions or Feedback?</h2>
<p>This post covered the essentials of vector databases from theory to production. Key resources:</p>
<ul>
<li>📖 <strong>Code examples:</strong> All examples available in this notebook</li>
<li>🔬 <strong>Benchmarks:</strong> Test different indexes with your data</li>
<li>📊 <strong>Monitoring:</strong> Set up dashboards for key metrics</li>
<li>🚀 <strong>Deployment:</strong> Start with managed solutions, self-host when needed</li>
</ul>
<p><strong>Good luck building your vector search system!</strong> 🎉</p>
</section>
</section>
<section id="appendix-package-installation-verification" class="level1" data-number="17">
<h1 data-number="17"><span class="header-section-number">17</span> Appendix: Package Installation &amp; Verification</h1>
<p>If you want to run the code examples in this guide, you’ll need the following packages:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install numpy pandas matplotlib scikit-learn faiss-cpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The cell below verifies all required packages are installed correctly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Package verification - collapse this output after confirming everything works</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Python version: </span><span class="sc">{</span>sys<span class="sc">.</span>version<span class="sc">.</span>split()[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Checking required packages..."</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>required_packages <span class="op">=</span> {</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'numpy'</span>: <span class="st">'Core numerical computing'</span>,</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'pandas'</span>: <span class="st">'Data manipulation'</span>,</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'matplotlib'</span>: <span class="st">'Visualization'</span>,</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'sklearn'</span>: <span class="st">'Machine learning utilities'</span>,</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'faiss'</span>: <span class="st">'Vector search library'</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>optional_packages <span class="op">=</span> {</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'torch'</span>: <span class="st">'Deep learning (optional)'</span>,</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'sentence_transformers'</span>: <span class="st">'Embedding models (optional)'</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>all_good <span class="op">=</span> <span class="va">True</span></span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> package, description <span class="kw">in</span> required_packages.items():</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> package <span class="op">==</span> <span class="st">'sklearn'</span>:</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>            <span class="im">import</span> sklearn</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>            version <span class="op">=</span> sklearn.__version__</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>            mod <span class="op">=</span> <span class="bu">__import__</span>(package)</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>            version <span class="op">=</span> mod.__version__</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"✓ </span><span class="sc">{</span>package<span class="sc">:20s}</span><span class="ss"> </span><span class="sc">{</span>version<span class="sc">:12s}</span><span class="ss"> - </span><span class="sc">{</span>description<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"✗ </span><span class="sc">{</span>package<span class="sc">:20s}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'NOT FOUND'</span><span class="sc">:12s}</span><span class="ss"> - </span><span class="sc">{</span>description<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>        all_good <span class="op">=</span> <span class="va">False</span></span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> all_good:</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"✅ All required packages installed successfully!"</span>)</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"❌ Some packages missing. Install with:"</span>)</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"   pip install numpy pandas matplotlib scikit-learn faiss-cpu"</span>)</span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<section id="license-attribution" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="license-attribution"><span class="header-section-number">17.1</span> License &amp; Attribution</h2>
<p><strong>Code examples:</strong> MIT License - Feel free to use in your projects.</p>
<p><strong>Citation:</strong> If you found this guide useful, please link back to: <code>https://www.reddydodlapati.com/vector-databases-demystified</code></p>
<p><strong>Feedback welcome:</strong> Found an error or have suggestions? <a href="https://github.com/SanjeevaRDodlapati/mysite/issues">Open an issue</a> or reach out via email.</p>
<hr>
<p><strong>Last updated:</strong> October 4, 2025 • <strong>Version:</strong> 1.0</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary: Quick reference for vector database operations</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" VECTOR DATABASES DEMYSTIFIED - QUICK REFERENCE "</span>.center(<span class="dv">70</span>))</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a reference table</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>reference_data <span class="op">=</span> {</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Task'</span>: [</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Text embedding'</span>,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Image embedding'</span>,</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Small scale (&lt;10M)'</span>,</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Large scale (&gt;100M)'</span>,</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Hybrid search'</span>,</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Metadata filtering'</span>,</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Real-time updates'</span>,</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Production monitoring'</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Recommended Approach'</span>: [</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sentence-transformers, OpenAI, Cohere'</span>,</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'CLIP, vision transformers'</span>,</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'HNSW (M=16-32, ef=100-200)'</span>,</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'IVF-PQ (nlist=√N, nprobe=16-64)'</span>,</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'RRF fusion + cross-encoder re-rank'</span>,</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Pre-partition or segment indexes'</span>,</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Streaming upsert + dual-write pattern'</span>,</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall@k, P95 latency, QPS, drift'</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Key Metric'</span>: [</span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Embedding quality'</span>,</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Multimodal alignment'</span>,</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall@10 &gt; 0.95'</span>,</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">'QPS &gt; 1000'</span>,</span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">'NDCG@10 &gt; 0.85'</span>,</span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Filter selectivity'</span>,</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Freshness lag &lt; 5min'</span>,</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">'All of the above'</span></span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(reference_data)</span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">💡 Key Reminders:"</span>)</span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  1. Always normalize vectors for cosine similarity"</span>)</span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  2. Measure recall against exact search baseline"</span>)</span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  3. Tune efSearch/nprobe to meet latency SLO"</span>)</span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  4. Use hybrid search for production systems"</span>)</span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  5. Monitor, version, and iterate"</span>)</span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✅ You're ready to build production vector search systems!"</span>)</span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
            VECTOR DATABASES DEMYSTIFIED - QUICK REFERENCE            
======================================================================


                 Task                  Recommended Approach           Key Metric
       Text embedding sentence-transformers, OpenAI, Cohere    Embedding quality
      Image embedding             CLIP, vision transformers Multimodal alignment
   Small scale (&lt;10M)            HNSW (M=16-32, ef=100-200)     Recall@10 &gt; 0.95
  Large scale (&gt;100M)       IVF-PQ (nlist=√N, nprobe=16-64)           QPS &gt; 1000
        Hybrid search    RRF fusion + cross-encoder re-rank       NDCG@10 &gt; 0.85
   Metadata filtering      Pre-partition or segment indexes   Filter selectivity
    Real-time updates Streaming upsert + dual-write pattern Freshness lag &lt; 5min
Production monitoring     Recall@k, P95 latency, QPS, drift     All of the above

======================================================================

💡 Key Reminders:
  1. Always normalize vectors for cosine similarity
  2. Measure recall against exact search baseline
  3. Tune efSearch/nprobe to meet latency SLO
  4. Use hybrid search for production systems
  5. Monitor, version, and iterate

======================================================================

✅ You're ready to build production vector search systems!
======================================================================
</code></pre>
</div>
</div>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div>MIT</div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{reddy dodlapati2025,
  author = {Reddy Dodlapati, Sanjeeva},
  title = {Vector {Databases,} {Demystified:} {From} {Embeddings} to
    {Production-Grade} {Search}},
  date = {2025-10-04},
  url = {https://www.reddydodlapati.com/vector-databases-demystified},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-reddy dodlapati2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Reddy Dodlapati, Sanjeeva. 2025. <span>“Vector Databases, Demystified:
From Embeddings to Production-Grade Search,”</span> October. <a href="https://www.reddydodlapati.com/vector-databases-demystified">https://www.reddydodlapati.com/vector-databases-demystified</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">© 2025 Sanjeeva Reddy Dodlapati<br>
AI Research • Computational Biology • Data Science</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/sanjeeva-reddy-dodlapati-ab4ab490/">
      <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:sdodlapa@gmail.com">
      <i class="bi bi-envelope" role="img" aria-label="Email">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>