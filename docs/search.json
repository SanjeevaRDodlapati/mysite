[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "",
    "text": "This is my personal website where I am going to post my blog articles"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "Education",
    "text": "Education\n\nPhD in Computer Science, Old Dominion University, Norfolk, VA, 23508\nMS Chemistry, University of New Orleans, LA"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "Experience",
    "text": "Experience\n\nResearch\n\nIntern, BI, CT Jun 2018 - Aug 2018\nProject Lead, Indian Institute of Chemical Technology, Hyderabad.\n\n\n\nTeaching\n\nTeaching Assistant, Department of Computer Science, ODU, Norfolk, VA, 23508"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "Projects",
    "text": "Projects\n\nDNA methylation imputation via Transfer Learning.\nSample complexity study of DNA methylation prediction by DNA sequence-based deep learning\nDrug-Drug interaction prediction\nSynthesis of macrocyclic glycosamines by click reaction"
  },
  {
    "objectID": "index.html#publications",
    "href": "index.html#publications",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "Publications",
    "text": "Publications\n\nSanjeeva Dodlapati, ZC Jiang, J Sun, Completing Single-Cell DNA Methylome Profiles via Transfer Learning together with KL-Divergence. Frotiers in Genetics 2022\nLoss of Acta2 in cardiac fibroblasts does not prevent the myofibroblast differentiation or affect the cardiac repair after myocardial infarction. Journal of Molecular and Cellular Cardiology 171, 117-132.\nThe landscape of accessible chromatin in quiescent cardiac fibroblasts and cardiac fibroblasts activated after myocardial infarction.. Epigenetics 2021."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "",
    "text": "* Deep Learning\n* Graph Learning\n* Transfer Learning\n* Multi-task Learning\n* Contrastive Learning\n* Drug Designing & Discovery\n* DNA methylation prediction"
  },
  {
    "objectID": "KGCN.html",
    "href": "KGCN.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport argparse\nimport random\nfrom model import KGCN\nfrom data_loader import DataLoader\nimport torch\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\n\n\n\n\n\n\n\nCode\n# prepare arguments (hyperparameters)\nparser = argparse.ArgumentParser()\n\nparser.add_argument('--dataset', type=str, default='music', help='which dataset to use')\nparser.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')\nparser.add_argument('--n_epochs', type=int, default=20, help='the number of epochs')\nparser.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')\nparser.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')\nparser.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')\nparser.add_argument('--batch_size', type=int, default=32, help='batch size')\nparser.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')\nparser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\nparser.add_argument('--ratio', type=float, default=0.8, help='size of training dataset')\n\nargs = parser.parse_args(['--l2_weight', '1e-4'])\n\n\n\n\n\n\n\nCode\n# build dataset and knowledge graph\ndata_loader = DataLoader(args.dataset)\nkg = data_loader.load_kg()\ndf_dataset = data_loader.load_dataset()\ndf_dataset\n\n\nConstruct knowledge graph ... Done\nBuild dataset dataframe ... \n\n\n/Users/sanjeev/Downloads/Repos/KGCN-pytorch/data_loader.py:86: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n  for user, group in df_dataset.groupby(['userID']):\n\n\nDone\n\n\n\n\n\n  \n    \n      \n      userID\n      itemID\n      label\n    \n  \n  \n    \n      0\n      1217\n      289\n      1\n    \n    \n      1\n      1648\n      3810\n      0\n    \n    \n      2\n      596\n      2333\n      0\n    \n    \n      3\n      475\n      57\n      1\n    \n    \n      4\n      1450\n      9264\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      42341\n      1778\n      8317\n      0\n    \n    \n      42342\n      519\n      4\n      1\n    \n    \n      42343\n      1487\n      2879\n      1\n    \n    \n      42344\n      1115\n      36\n      1\n    \n    \n      42345\n      793\n      3655\n      0\n    \n  \n\n42346 rows Ã— 3 columns\n\n\n\n\n\n\n\n\nCode\n# Dataset class\nclass KGCNDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.df = df\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        user_id = np.array(self.df.iloc[idx]['userID'])\n        item_id = np.array(self.df.iloc[idx]['itemID'])\n        label = np.array(self.df.iloc[idx]['label'], dtype=np.float32)\n        return user_id, item_id, label\n\n\n\n\n\n\n\nCode\n# train test split\nx_train, x_test, y_train, y_test = train_test_split(df_dataset, df_dataset['label'], test_size=1 - args.ratio, shuffle=False, random_state=999)\ntrain_dataset = KGCNDataset(x_train)\ntest_dataset = KGCNDataset(x_test)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size)\n\n\n\n\n\n\n\nCode\n# prepare network, loss function, optimizer\nnum_user, num_entity, num_relation = data_loader.get_num()\nuser_encoder, entity_encoder, relation_encoder = data_loader.get_encoders()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nnet = KGCN(num_user, num_entity, num_relation, kg, args, device).to(device)\ncriterion = torch.nn.BCELoss()\noptimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2_weight)\nprint('device: ', device)\n\n\ndevice:  cpu\n\n\n\n\n\n\n\nCode\n# train\nloss_list = []\ntest_loss_list = []\nauc_score_list = []\n\nfor epoch in range(args.n_epochs):\n    running_loss = 0.0\n    for i, (user_ids, item_ids, labels) in enumerate(train_loader):\n        user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = net(user_ids, item_ids)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        \n        optimizer.step()\n\n        running_loss += loss.item()\n    \n    # print train loss per every epoch\n    print('[Epoch {}]train_loss: '.format(epoch+1), running_loss / len(train_loader))\n    loss_list.append(running_loss / len(train_loader))\n        \n    # evaluate per every epoch\n    with torch.no_grad():\n        test_loss = 0\n        total_roc = 0\n        for user_ids, item_ids, labels in test_loader:\n            user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n            outputs = net(user_ids, item_ids)\n            test_loss += criterion(outputs, labels).item()\n            total_roc += roc_auc_score(labels.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n        print('[Epoch {}]test_loss: '.format(epoch+1), test_loss / len(test_loader))\n        test_loss_list.append(test_loss / len(test_loader))\n        auc_score_list.append(total_roc / len(test_loader))\n\n\n[Epoch 1]train_loss:  1.0006579118477386\n[Epoch 1]test_loss:  0.8893653685191892\n[Epoch 2]train_loss:  0.797622429075052\n[Epoch 2]test_loss:  0.7451721688486496\n[Epoch 3]train_loss:  0.7099895417633993\n[Epoch 3]test_loss:  0.7056801096448359\n[Epoch 4]train_loss:  0.6925263987384505\n[Epoch 4]test_loss:  0.6984908924912506\n[Epoch 5]train_loss:  0.6887075713043285\n[Epoch 5]test_loss:  0.6963376231913296\n[Epoch 6]train_loss:  0.6864752684481533\n[Epoch 6]test_loss:  0.6951152374159615\n[Epoch 7]train_loss:  0.6841747608243349\n[Epoch 7]test_loss:  0.6940336123952325\n[Epoch 8]train_loss:  0.6809721414045526\n[Epoch 8]test_loss:  0.6923793970413927\n[Epoch 9]train_loss:  0.6749813177880529\n[Epoch 9]test_loss:  0.6882064553926576\n[Epoch 10]train_loss:  0.6610501028097835\n[Epoch 10]test_loss:  0.6750262923960416\n[Epoch 11]train_loss:  0.6269802276653653\n[Epoch 11]test_loss:  0.6377323098902432\n[Epoch 12]train_loss:  0.5613479613132134\n[Epoch 12]test_loss:  0.5762754341341415\n[Epoch 13]train_loss:  0.48752794111529196\n[Epoch 13]test_loss:  0.5281977321741715\n[Epoch 14]train_loss:  0.43498319829264487\n[Epoch 14]test_loss:  0.5022194322550072\n[Epoch 15]train_loss:  0.40202890122634716\n[Epoch 15]test_loss:  0.4895982358815535\n[Epoch 16]train_loss:  0.3804858219831816\n[Epoch 16]test_loss:  0.4837832122478845\n[Epoch 17]train_loss:  0.36510224249196344\n[Epoch 17]test_loss:  0.48116923621240654\n[Epoch 18]train_loss:  0.35307079774518413\n[Epoch 18]test_loss:  0.4796772748231888\n[Epoch 19]train_loss:  0.3423397296914748\n[Epoch 19]test_loss:  0.4766093622401076\n[Epoch 20]train_loss:  0.3317471455019302\n[Epoch 20]test_loss:  0.474617142103753\n\n\n\n\n\n\n\nCode\n# plot losses / scores\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,4))  # 1 row, 2 columns\nax1.plot(loss_list)\nax1.plot(test_loss_list)\nax2.plot(auc_score_list)\n\nplt.tight_layout()"
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see FigureÂ 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigureÂ 1: A line plot on a polar axis"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Sanjeeva Reddy Dodlapati",
    "section": "",
    "text": "Pandas Tutorial\nDemonstration of Jupyter Notebook\nImplementation of Knowledge Graph Convolutional Network with Pytorch"
  }
]